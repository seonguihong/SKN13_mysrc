{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cc31ad21",
   "metadata": {},
   "source": [
    "# Access Token 생성\n",
    "- 학습된 모델을 Huggingface hub에 올리기 위해서는 access token이 필요하다.\n",
    "  \n",
    "![huggingface_create_apikey.png](figures/huggingface_accesstoken.png)\n",
    "![huggingface_create_apikey.png](figures/huggingface_accesstoken2.png)\n",
    "\n",
    "- 1. 로그인 -> 2. Profile -> 3. Access Tokens 선택\n",
    "- 생성할 때 `write` 권한을 선택한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d63f6b83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# working directory 아래 \".env\" 파일을 생성\n",
    "# .gitignore 파일에 .env 을 등록해서 github에 등록하지 않도록 설정.\n",
    "# 이름 = 값 형식으로 환경변수를 설정.\n",
    "# HUGGINGFACE_API_KEY = \"받은 Access Token\"\n",
    "# 추후에 api사용할시에 같은 방식으로 작업."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eac3cc5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "# working directory에서 환경변수 파일 (defalut = \".env\")를 찾아서 \n",
    "# 그 파일에 설정된 값을 O/S의 환경변수로 등록해준다.\n",
    "# 임시적으로 사용하는 것이기 때문에 프로그램 종료시 삭제."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f1b347ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\tjddm\\\\Documents\\\\jdk-24.0.1'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 환경 변수 값을 읽기\n",
    "import os\n",
    "os.getenv(\"JAVA_HOME\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "457fe75f",
   "metadata": {},
   "outputs": [],
   "source": [
    "hf_api_key = os.getenv(\"HUGGINGFACE_API_KEY\")\n",
    "# os.environ[\"HUGGINGFACE_API_KEY\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4a2b3c4-8539-466d-ad52-da953f97498f",
   "metadata": {},
   "source": [
    "# Naver 영화댓글 분류"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfca8d80-d72b-4c50-8225-16a06f17c731",
   "metadata": {},
   "source": [
    "# Huggingface Dataset 패키지\n",
    "- 허깅페이스 허브에 공유된 데이터셋을  다운로드해서 전처리 및 관리할 수있도록 돕는 라이브러리. \n",
    "- 많은 공개데이터셋을 동일한 인터페이스로 사용할 수있다.\n",
    "- 설치\n",
    "    - `pip install datasets`\n",
    "- https://huggingface.co/datasets\n",
    "- https://github.com/huggingface/datasets\n",
    "      \n",
    "## Huggingface Dataset loading\n",
    "- datasets 로딩\n",
    "    - `load_data('dataset name')`\n",
    "        - huggingface datasets에 등록된 Dataset 이름 넣어 Loading한다.\n",
    "          \n",
    "![img](figures/huggingface_dataset.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "32bf57c5-8fb9-4da6-b74d-6db47842e597",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a7f1797894c641a08dd93b9d84fb8f98",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/3.74k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\tjddm\\miniconda3\\envs\\dl\\Lib\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\tjddm\\.cache\\huggingface\\hub\\datasets--e9t--nsmc. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c90741d5ee34027adac80229e3293e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "nsmc.py:   0%|          | 0.00/3.18k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ac53e312bd34441901571c01186400c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/14.6M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e4519c54e4b6437eb6d8583ce347d2b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/4.89M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3448e209ca6c4e658ab1c21a2c964d76",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/150000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "71436de171824f0f9cf254674d0f38de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/50000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# NSMC 데이터셋 로딩\n",
    "import datasets\n",
    "from datasets import load_dataset\n",
    "# dataset download시에 데이터를 올려놓거나 / 다운로드받는 코드를 올려둠.(악성코드등이 같이 실행될수있음.)\n",
    "\n",
    "nsmc = load_dataset(\"e9t/nsmc\", trust_remote_code=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94ae86b0-062f-43cd-bd66-3e6b0a500a4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset : 데이터 셋\n",
    "# Datasetdict : Dataset들을 모아놓은 dict기반의 자료구조. \n",
    "# -> train/valid/test set들을 모아서 제공할 때 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f0015341",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['train', 'test'])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nsmc.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be754805",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset이 표데이터일 경우 features는 칼럼명.\n",
    "trainset = nsmc[\"train\"]\n",
    "testset = nsmc[\"test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00b03071",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['9976970', '3819312', '10265843', '9045019', '6483659']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# feature 조회\n",
    "trainset['document'][:5] # 댓글내용\n",
    "trainset['label'][:5] # 긍정 / 부정\n",
    "trainset['id'][:5] # 댓글 id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2050eb7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>document</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9976970</td>\n",
       "      <td>아 더빙.. 진짜 짜증나네요 목소리</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3819312</td>\n",
       "      <td>흠...포스터보고 초딩영화줄....오버연기조차 가볍지 않구나</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10265843</td>\n",
       "      <td>너무재밓었다그래서보는것을추천한다</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9045019</td>\n",
       "      <td>교도소 이야기구먼 ..솔직히 재미는 없다..평점 조정</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6483659</td>\n",
       "      <td>사이몬페그의 익살스런 연기가 돋보였던 영화!스파이더맨에서 늙어보이기만 했던 커스틴 ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id                                           document  label\n",
       "0   9976970                                아 더빙.. 진짜 짜증나네요 목소리      0\n",
       "1   3819312                  흠...포스터보고 초딩영화줄....오버연기조차 가볍지 않구나      1\n",
       "2  10265843                                  너무재밓었다그래서보는것을추천한다      0\n",
       "3   9045019                      교도소 이야기구먼 ..솔직히 재미는 없다..평점 조정      0\n",
       "4   6483659  사이몬페그의 익살스런 연기가 돋보였던 영화!스파이더맨에서 늙어보이기만 했던 커스틴 ...      1"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dataset.Datasets를 다른 형식으로 변환\n",
    "# dataset객체.to_xxxx()\n",
    "\n",
    "df = trainset.to_pandas()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "35571a68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['id', 'document', 'label'],\n",
       "    num_rows: 100\n",
       "})"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 다른 형식으로 저장된 data들을 dataset.Datasets로 변환\n",
    "# dataset객체.from_xxxx()\n",
    "\n",
    "d = datasets.Dataset.from_pandas(df.head(100))\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "850fde43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sampling - train : 10000, test : 5000\n",
    "\n",
    "# dataset.shuffle() -> 섞어줌. select([조회할 index들])\n",
    "sample_train = trainset.shuffle().select(range(10000))\n",
    "sample_test = testset.shuffle().select(range(5000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "3da9d192",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['id', 'document', 'label'],\n",
      "    num_rows: 10000\n",
      "})\n",
      "Dataset({\n",
      "    features: ['id', 'document', 'label'],\n",
      "    num_rows: 5000\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "print(sample_train)\n",
    "print(sample_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd956109-6f8f-4412-a159-4c9c4cdb0ef8",
   "metadata": {},
   "source": [
    "## 모델, 토크나이저 loading\n",
    "\n",
    "- 모델 별 Model 클래스를 이용하거나 Auto class를 이용해 모델, 전처리기(tokenizer, ImageProcessor 등)을 로딩한다.\n",
    "    - Huggingface에 저장된 model name을 입력해서 pretrained 모델을 loading 한다.\n",
    "    - fine tuning 한 경우 모델 저장 디렉토리 경로를 넣어 pretrained 모델을 loading한다.\n",
    "- AutoModel은 model name을 주면 그 모델이 학습한 base 모델에 맞는 객체를 생성해서 반환한다.\n",
    "    - Auto Model은 task 별로 다양한 클래스들이 있다.\n",
    "        - 클래스 이름 형식: AutoModelFor{Task형식}\n",
    "        - ex) `AutoModelForObjectDetection`, `AutoModelForSequenceClassification`\n",
    "    - https://huggingface.co/docs/transformers/model_doc/auto\n",
    "    - 전처리기(tokenzier)는 사용하려는 모델이 사용한 전처리기를 사용해야 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "c02f7b81-3eb6-4d4b-9031-d38010e13c43",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at beomi/kcbert-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "model_id = \"beomi/kcbert-base\"\n",
    "# 토크나이저, 분류 모델 loading\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_id, num_labels = 2) \n",
    "# num_labels : 분류할 클래스의 개수 (긍정, 부정) -> 학습안된 분류기 추가해서 학습시키기.\n",
    "# model_id : kcbert-base - pretrainde 된 Feature Extractor\n",
    "# model : Estimator는 학습 안된 layer로 구성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66b22541-3ad5-4d18-ad53-9dbdbe6682c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_id = \"beomi/kcbert-base\" -> 문장의 특성을 추출하는 모델. (분류 모델 X)\n",
    "# pretrained된 모델 파인튜닝 + 모델에서 추출된 feature을 토대로 초기화된 분류기를 학습시켜서 결과 추출하기."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5eb52259-f139-4db7-9314-c3496e52ab31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BertForSequenceClassification(\n",
      "  (bert): BertModel(\n",
      "    (embeddings): BertEmbeddings(\n",
      "      (word_embeddings): Embedding(30000, 768, padding_idx=0)\n",
      "      (position_embeddings): Embedding(300, 768)\n",
      "      (token_type_embeddings): Embedding(2, 768)\n",
      "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (encoder): BertEncoder(\n",
      "      (layer): ModuleList(\n",
      "        (0-11): 12 x BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSdpaSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (pooler): BertPooler(\n",
      "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "      (activation): Tanh()\n",
      "    )\n",
      "  )\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7ab74ab-3349-49fa-9626-3f2f28e52754",
   "metadata": {},
   "source": [
    "## pytorch Dataset 생성\n",
    "모델 입력으로 다음 4개 항목을 dictionary로 묶어서 제공하도록 구현한다.\n",
    "1. input_ids: 입력 text 토큰을 id로 변환한 값\n",
    "2. token_type_ids: 문자쌍 구분시 사용. 단일 문장: 0, 문자쌍-첫문장: 0, 두 번째 문장: 1\n",
    "3. attention_mask: 실제 토큰값과 패딩구분값\n",
    "4. labels: 정답 class index\n",
    "\n",
    "1 ~ 3은 위의 train_encoding, test_encoding으로 만듬. labels은 train_data/test_data의 label 키 값 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "df630535",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = sample_train['document'] # sample_trian -> trainset(전체)\n",
    "train_y = sample_train['label']\n",
    "\n",
    "test_X = sample_test['document'] # sample_test -> testset(전체)\n",
    "test_y = sample_test['label']\n",
    "# trainset/testset 사용하지 않는 이유는 전체 데이터를 사용하지 않기 위함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "c4d02679",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X(댓글)을 토큰화\n",
    "train_encoding = tokenizer(train_X, return_tensors=\"pt\", padding=True) # trian_X에서 가장 긴 문장을 기준으로 [PAD] 추가.\n",
    "test_encoding = tokenizer(test_X, return_tensors=\"pt\", padding=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "8581bc72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10000, 110])"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_encoding.keys()\n",
    "train_encoding['input_ids'].shape # [10000:문서수, 142:토큰수]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "fbd8866c",
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################\n",
    "# Pytorch의 Dataset을 정의, 생성\n",
    "##################################\n",
    "\n",
    "from torch.utils.data import Dataset\n",
    "import torch\n",
    "\n",
    "class NSMCDataset(Dataset):\n",
    "\n",
    "    def __init__(self, comments, labels):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            comments(dict) : tokenizer로 토큰화한 input data들\n",
    "            labels(list) : 정답 라벨들\n",
    "        \"\"\"\n",
    "        self.comments = comments\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.comments['input_ids'])\n",
    "\n",
    "    def __getitem__(self,index):\n",
    "        \"\"\"\n",
    "        index번째 데이터를 반환.\n",
    "        BERT 모델 입력 형식에 맞춰서 반환. input_ids, token_type_ids, attention_mask + label\n",
    "\n",
    "        Args:\n",
    "            index(int) :\n",
    "        Returns:\n",
    "            directory - input_ids, token_type_ids, attention_mask + label\n",
    "            입력 데이터와 정답 label을 딕셔너리에 묶어서 반환.\n",
    "        \"\"\"\n",
    "        data = {key:value[index] for key, value in self.comments.items()}\n",
    "        # comments.items -> (key, [value1, value2, ... value10000])\n",
    "        data['labels'] = torch.tensor([self.labels[index]], dtype=torch.int64)\n",
    "\n",
    "        return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "e902033f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = NSMCDataset(train_encoding, train_y)\n",
    "test_set = NSMCDataset(test_encoding, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "e5ddb080",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 5000)"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_set), len(test_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d19f905f-3f53-480b-8e70-1e76f8479555",
   "metadata": {},
   "source": [
    "# 학습\n",
    "- Transformers는 model 학습을 위해 TrainingArguments, Trainer 클래스를 제공한다.\n",
    "- TrainingArguments는 Trainer를 위한 설정을 하는 클래스\n",
    "- TrainingArguments, Trainer를 이용하면 training option, logging, gradient accumulation, mixed precision등을 쉽게 설정해 학습, 평가를 모두 진행할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82a80239-306a-4574-ae6b-5603ae161a96",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments, Trainer\n",
    "\n",
    "N_EPOCHS = 1\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "# 어떻게 학습할지에 대한 설정.\n",
    "train_args = TrainingArguments(\n",
    "    output_dir=\"models/nsmc\", # train 모델을 저장할 디렉토리 경로.\n",
    "    num_train_epochs=N_EPOCHS, # 학습 에폭수.\n",
    "    per_device_train_batch_size=BATCH_SIZE, # 학습할때 batch size.\n",
    "    per_device_eval_batch_size=BATCH_SIZE, # 검증시 batch size.\n",
    "    \n",
    "    eval_strategy=\"epoch\", # 평가 전략. - \"no\", \"step\", \"epoch\" -> step 단위별로 평가.\n",
    "    save_strategy=\"epoch\", # 저장 전략. -> epoch단위별로 저장. / \"no\" -> 아무것도 안함.\n",
    "\n",
    "    save_total_limit=1, # 저장할 모델의 최대 개수. -> 마지막것만 저장.\n",
    "    load_best_model_at_end=True, # 학습 종료 후 검증결과가 가장 좋은 모델을 저장 + load.\n",
    "                                 # True : eval_strategy, save_strategy가 같아야함.\n",
    "\n",
    "    metric_for_best_model=\"eval_loss\", # best model을 선정할 검증 기준이 될 평가 지표.\n",
    "    greater_is_better=False, # 검증 평가지표값이 높아야 좋은지 낮아야 좋은지. / False -> 낮을때 사용\n",
    "\n",
    "    report_to=\"none\"\n",
    "\n",
    "    # huggingface-hub에 올리는 설정\n",
    "    # push_to_hub=True,\n",
    "    # hub_model_id=\"kcbert-nsmc-10000\" # 모델_id\n",
    "    # hub_token = \"Access Token\"\n",
    "    # -> 학습이 끝나면 자동으로 huggingface 업로드\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "5378b3e7-803b-41dd-9456-1d03288c7f39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 평가 함수 정의 - evaluate 패키지를 이용.\n",
    "# huggingface에서 제공하는 라이브러리. / 다양한 평가 함수들을 제공."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "1df7ea65-606c-4572-8e6f-a253cefadb9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import evaluate\n",
    "\n",
    "# 정확도 평가 함수.\n",
    "acc_fn = evaluate.load(\"accuracy\") # f1, recall, precision ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0f8a289",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.75}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 사용 예시\n",
    "\n",
    "pred = torch.tensor([0,1,0,1])\n",
    "ref = torch.tensor([0,1,0,0])\n",
    "\n",
    "acc_fn.compute(predictions=pred, references=ref)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "133a63e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(pred):\n",
    "    \"\"\"\n",
    "    모델이 학습하는 도중 예측값을 받아서 평가 점수를 계산하는 함수.\n",
    "    Trainer에 의해서 호출될 함수.\n",
    "    Args:\n",
    "        pred(EvalPrediction) - 모델의 예측값, 정답을 묶어서 제공.\n",
    "    Return:\n",
    "        dictionary - key : 평가지표이름, value : 평가점수\n",
    "    \"\"\"\n",
    "    labels = pred.label_ids # 정답\n",
    "    preds = pred.predictions.argmax(axis=-1) # 모델의 예측값.\n",
    "    metrics1 = evaluate.load(\"accuracy\")\n",
    "    metrics2 = evaluate.load(\"f1\")\n",
    "\n",
    "    acc = metrics1.compute(predictions=preds, references=labels)\n",
    "    f1 = metrics2.compute(predictions=preds, references=labels)\n",
    "\n",
    "    return {\"accuracy\" :acc, \"f1 score\":f1}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "2b1db4a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trainer 객체\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model, # 학습 대상 모델\n",
    "    args=train_args, #TrainingArguments\n",
    "    train_dataset=train_set, # 학습 데이터셋, pytorch의 Dataset객체 - trianer.train()\n",
    "    eval_dataset=test_set, # 검증 데이터셋 trainer.evaluate()\n",
    "    compute_metrics=compute_metrics # loss 이외에 검증/평가시 확인할 지표를 계산하는 함수.\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "320ccbe2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\tjddm\\miniconda3\\envs\\dl\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:665: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='57' max='157' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 57/157 1:01:04 < 1:51:02, 0.02 it/s, Epoch 0.36/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[121]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# 학습\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[43mtrainer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\tjddm\\miniconda3\\envs\\dl\\Lib\\site-packages\\transformers\\trainer.py:2240\u001b[39m, in \u001b[36mTrainer.train\u001b[39m\u001b[34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[39m\n\u001b[32m   2238\u001b[39m         hf_hub_utils.enable_progress_bars()\n\u001b[32m   2239\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m2240\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2241\u001b[39m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[43m=\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2242\u001b[39m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2243\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2244\u001b[39m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m=\u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2245\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\tjddm\\miniconda3\\envs\\dl\\Lib\\site-packages\\transformers\\trainer.py:2555\u001b[39m, in \u001b[36mTrainer._inner_training_loop\u001b[39m\u001b[34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[39m\n\u001b[32m   2548\u001b[39m context = (\n\u001b[32m   2549\u001b[39m     functools.partial(\u001b[38;5;28mself\u001b[39m.accelerator.no_sync, model=model)\n\u001b[32m   2550\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m i != \u001b[38;5;28mlen\u001b[39m(batch_samples) - \u001b[32m1\u001b[39m\n\u001b[32m   2551\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m.accelerator.distributed_type != DistributedType.DEEPSPEED\n\u001b[32m   2552\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m contextlib.nullcontext\n\u001b[32m   2553\u001b[39m )\n\u001b[32m   2554\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m context():\n\u001b[32m-> \u001b[39m\u001b[32m2555\u001b[39m     tr_loss_step = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtraining_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_items_in_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2557\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m   2558\u001b[39m     args.logging_nan_inf_filter\n\u001b[32m   2559\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torch_xla_available()\n\u001b[32m   2560\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m (torch.isnan(tr_loss_step) \u001b[38;5;129;01mor\u001b[39;00m torch.isinf(tr_loss_step))\n\u001b[32m   2561\u001b[39m ):\n\u001b[32m   2562\u001b[39m     \u001b[38;5;66;03m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[32m   2563\u001b[39m     tr_loss = tr_loss + tr_loss / (\u001b[32m1\u001b[39m + \u001b[38;5;28mself\u001b[39m.state.global_step - \u001b[38;5;28mself\u001b[39m._globalstep_last_logged)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\tjddm\\miniconda3\\envs\\dl\\Lib\\site-packages\\transformers\\trainer.py:3791\u001b[39m, in \u001b[36mTrainer.training_step\u001b[39m\u001b[34m(***failed resolving arguments***)\u001b[39m\n\u001b[32m   3788\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.accelerator.distributed_type == DistributedType.DEEPSPEED:\n\u001b[32m   3789\u001b[39m     kwargs[\u001b[33m\"\u001b[39m\u001b[33mscale_wrt_gas\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m3791\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43maccelerator\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3793\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m loss.detach()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\tjddm\\miniconda3\\envs\\dl\\Lib\\site-packages\\accelerate\\accelerator.py:2473\u001b[39m, in \u001b[36mAccelerator.backward\u001b[39m\u001b[34m(self, loss, **kwargs)\u001b[39m\n\u001b[32m   2471\u001b[39m     \u001b[38;5;28mself\u001b[39m.lomo_backward(loss, learning_rate)\n\u001b[32m   2472\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m2473\u001b[39m     \u001b[43mloss\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\tjddm\\miniconda3\\envs\\dl\\Lib\\site-packages\\torch\\_tensor.py:648\u001b[39m, in \u001b[36mTensor.backward\u001b[39m\u001b[34m(self, gradient, retain_graph, create_graph, inputs)\u001b[39m\n\u001b[32m    638\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    639\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[32m    640\u001b[39m         Tensor.backward,\n\u001b[32m    641\u001b[39m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[32m   (...)\u001b[39m\u001b[32m    646\u001b[39m         inputs=inputs,\n\u001b[32m    647\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m648\u001b[39m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mautograd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    649\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43minputs\u001b[49m\n\u001b[32m    650\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\tjddm\\miniconda3\\envs\\dl\\Lib\\site-packages\\torch\\autograd\\__init__.py:353\u001b[39m, in \u001b[36mbackward\u001b[39m\u001b[34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[39m\n\u001b[32m    348\u001b[39m     retain_graph = create_graph\n\u001b[32m    350\u001b[39m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[32m    351\u001b[39m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[32m    352\u001b[39m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m353\u001b[39m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    354\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    355\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    356\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    357\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    358\u001b[39m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    359\u001b[39m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    360\u001b[39m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    361\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\tjddm\\miniconda3\\envs\\dl\\Lib\\site-packages\\torch\\autograd\\graph.py:824\u001b[39m, in \u001b[36m_engine_run_backward\u001b[39m\u001b[34m(t_outputs, *args, **kwargs)\u001b[39m\n\u001b[32m    822\u001b[39m     unregister_hooks = _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[32m    823\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m824\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_execution_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[32m    825\u001b[39m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m    826\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[32m    827\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    828\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# 학습\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8dd196a",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "c206a91e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 저장 - local directory\n",
    "# tokenizer와 model을 같은 경로에 저장.\n",
    "\n",
    "save_path = \"models/nsmc\"\n",
    "tokenizer.save_pretrained(save_path)\n",
    "model.save_pretrained(save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f6e490a-4d3e-454d-a7dd-15b052cee797",
   "metadata": {},
   "source": [
    "## 모델 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "74f7113d-d452-4016-b689-11f6f587e94c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "load_tokenizer = AutoTokenizer.from_pretrained(save_path)\n",
    "load_model = AutoModelForSequenceClassification.from_pretrained(save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6e0f780-a07d-45d4-af5b-43af910adc5c",
   "metadata": {},
   "source": [
    "# 추론"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "b1abb813-88ca-41b3-8be6-7ff47eef5624",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = [\"이걸 영화라고 만든 거냐?\", \"아무 기대 없이 봤는데 재미있네.\", \"내가 감독이어도 이것보다 재미있게 만들겠다.\", \"시간이 어떻게 가는 줄 모르고 봤다.\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "81194e5f-9197-46b7-9074-c54ca04ebdee",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "pipe = pipeline(task=\"text-classification\", tokenizer=load_tokenizer, model=load_model)\n",
    "result = pipe(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "e3d50cca-be78-4fb9-bb8c-9a3a0ff02b9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'LABEL_0', 'score': 0.9500664472579956},\n",
       " {'label': 'LABEL_1', 'score': 0.869631290435791},\n",
       " {'label': 'LABEL_0', 'score': 0.526900053024292},\n",
       " {'label': 'LABEL_1', 'score': 0.5647743344306946}]"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "6168441b-4ca7-4a46-bf02-e5eb6030d846",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 학습한 모델, 토크나이저를 huggingface hub에 업로드.\n",
    "# 1. TrainingArguments에 설정해서 학습 도중 / 끝나면 자동으로 업로드 되게 설정.\n",
    "# 2. model/tokenizer.push_to_hub(\"계정/모델id\")를 통해서 수동으로 올린다.\n",
    "\n",
    "# 로그인\n",
    "from huggingface_hub import login\n",
    "from dotenv import load_dotenv\n",
    "# login() # Token에 Access Token 입력 후 Login 클릭\n",
    "# login(\"Huggingface Access Token\") # 바로 입력\n",
    "load_dotenv() # .env에 환경 변수들을 로드."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acc7f10b-f61f-4f3d-abb0-29c00fdc679a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "hf_api_key = os.getenv(\"HUGGINGFACE_API_KEY\")\n",
    "login(hf_api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "41f3c75f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59a1facb402449a9a1c34ed81ea7e752",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/5.17k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\tjddm\\miniconda3\\envs\\dl\\Lib\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\tjddm\\.cache\\huggingface\\hub\\models--seongui--kcbert-nsmc-10000. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a8cfac4c42a494f9c21bfeb4b7f8971",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/436M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/seongui/kcbert-nsmc-10000/commit/1ca40c97bab03e090a6ae93a56f3b87179d477ae', commit_message='Upload BertForSequenceClassification', commit_description='', oid='1ca40c97bab03e090a6ae93a56f3b87179d477ae', pr_url=None, repo_url=RepoUrl('https://huggingface.co/seongui/kcbert-nsmc-10000', endpoint='https://huggingface.co', repo_type='model', repo_id='seongui/kcbert-nsmc-10000'), pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_id = \"kcbert-nsmc-10000\"\n",
    "load_tokenizer.push_to_hub(model_id)\n",
    "load_model.push_to_hub(model_id)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "3d98d8ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eecc4d023b8b46d08f4c1fcd678b4fea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/843 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\tjddm\\miniconda3\\envs\\dl\\Lib\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\tjddm\\.cache\\huggingface\\hub\\models--kgmyh--kcbert-nsmc-10000. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6aedb6f0ef54d2fa26c2d565799e9f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/436M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bfcece5e0a3b470d97ed8feb814287c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/1.37k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "475d47dddaa74c9ab03a5791ecac670b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/250k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58a85b7cf9e6493085f0597603db2785",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/721k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ddeb85d005aa4cf0a9f44ff593e9f984",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/695 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    }
   ],
   "source": [
    "# hugging face에 push한 모델 사용.\n",
    "model_id = \"kgmyh/kcbert-nsmc-10000\"\n",
    "pipe = pipeline(task=\"text-classification\", tokenizer=model_id, model=model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "f0ad50b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'LABEL_1', 'score': 0.9964871406555176},\n",
       " {'label': 'LABEL_0', 'score': 0.9996107220649719}]"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe([\"영화 너무 재미있어요\", \"시간이 아깝다.\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
