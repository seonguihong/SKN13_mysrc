{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "907e923a-af5e-48c3-9664-58bd640efb20",
   "metadata": {},
   "source": [
    "# Embedding\n",
    "![rag_embedding](figures/rag_embedding.png)\n",
    "\n",
    "- 분할된 텍스트를 벡터 표현(임베딩 벡터)으로 변환한다.\n",
    "- LangChain은 OpenAI, HuggingFace 등 다양한 임베딩 모델을 지원하며, 동일한 인터페이스로 사용할 수 있다.\n",
    "- [임베딩모델의 메서드](https://api.python.langchain.com/en/latest/embeddings/langchain_core.embeddings.embeddings.Embeddings.html#langchain_core.embeddings.embeddings.Embeddings)\n",
    "\n",
    "    - **`embed_documents(texts: List[str])`**\n",
    "        - 여러 문서를 받아 벡터화(임베딩)한다.\n",
    "        - Context를 벡터화 할 때 사용한다.\n",
    "    - **`embed_query(text: str)`**\n",
    "        - 하나의 문자열(문서)을 받아 벡터화한다.\n",
    "        - Query를 벡터화 할 때 사용한다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ff941301-56f5-4219-89e8-6b54d5afd7f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = [\n",
    "        \"나는 고양이와 개 중 반려동물로 개를 키우고 싶습니다.\",\n",
    "        \"이 강아지 품종은 진도개 입니다. 국제 표준으로 중대형견으로 분류되며 다리가 길어 체고가 높은 편에 속합니다.\",\n",
    "        \"日本の市内バスの運賃は主に距離によって決まり、地域やバス会社によって異なる場合があります\",                  # 일본의 시내버스 요금은 주로 거리에 따라 결정되며, 지역 및 버스 회사에 따라 다를 수 있습니다.\n",
    "        \"Bus fares in the United States vary from city to city, but are generally around $2.90 for a regular bus.\",  # 미국의 버스 요금은 도시마다 다르지만, 일반적으로 정기 버스의 경우 2.90달러 정도입니다.\n",
    "        \"광역버스 요금은 일반 3000원, 청소년은 1800원, 어린이 1500원 입니다.\", \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2cc2dfdd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "465811fa-32dd-44f3-96f9-c6193cb414ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#####################################\n",
    "# OpenAI의 Embedding 모델.\n",
    "#####################################\n",
    "\n",
    "import numpy as np\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "# e_model_id = \"text-embedding-3-small\" # \"text-embedding-3-large\"\n",
    "e_model_id = \"text-embedding-3-large\"\n",
    "embedding_model = OpenAIEmbeddings(model=e_model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "e4524fd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#####################################\n",
    "# Ollama Embedding 모델\n",
    "#####################################\n",
    "\n",
    "from langchain_ollama import OllamaEmbeddings\n",
    "\n",
    "e_model_id = \"bge-m3\"\n",
    "embedding_model = OllamaEmbeddings(model=e_model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "6f477a5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b94efc2bdcbb4e14bab4b96a4b755021",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/387 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\tjddm\\miniconda3\\envs\\lang_env\\Lib\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\tjddm\\.cache\\huggingface\\hub\\models--intfloat--multilingual-e5-large. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b6c9fbcdf0e347b6b0691e532f95f053",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/160k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a509d8e30284553be3422e1fa9c1125",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentence_bert_config.json:   0%|          | 0.00/57.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81ecb14948444370850567134cb52a3e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/690 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e1c6e22757744ad812fb8e4f58c4f2c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/2.24G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f7703597e33427e9c6e66d14a84f965",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/418 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f73f2730a2ab46c4b72738220674f8c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentencepiece.bpe.model:   0%|          | 0.00/5.07M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "65c9f01a759f4f0f87c7c98c97fa7602",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/17.1M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "106d7dd02a1f461ebf32aa4753343c54",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/280 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b162de2f95a48adb860ab1a988b72bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/201 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#####################################\n",
    "# Hungging_face Embedding 모델\n",
    "#####################################\n",
    "# Hugging_face : Model -> task - NLP -> Feature Extraction\n",
    "\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "\n",
    "e_model_id = \"intfloat/multilingual-e5-large\"\n",
    "embedding_model = HuggingFaceEmbeddings(model=e_model_id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "702aae4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 문서들을 embedding\n",
    "embedded_docs = embedding_model.embed_documents(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "42eabfde",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((5, 1024), list)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import numpy as np\n",
    "\n",
    "np.shape(embedded_docs), type(embedded_docs)\n",
    "# # (5 : 문서 개수, 1536 : 개별 문서의 Embedding 차원)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "cef51677",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1024,), list)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# query = \"당신이 좋아하는 동물은 무엇인가요?\"\n",
    "query = \"성인 버스요금은 얼마인가요?\"\n",
    "embedded_query = embedding_model.embed_query(query)\n",
    "np.shape(embedded_query), type(embedded_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "8c65d8f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def cosine_similarity(v1 : np.ndarray | list, v2 : np.ndarray | list) -> float:\n",
    "    # v1과 v2의 코사인 유사도 계산.\n",
    "    v1 = np.array(v1)\n",
    "    v2 = np.array(v2)\n",
    "    return (v1 @ v2) / (np.linalg.norm(v1) * np.linalg.norm(v2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "31551314",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. 0.7523771420277428\n",
      "2. 0.7313870736100034\n",
      "3. 0.767811236946179\n",
      "4. 0.7869861337661619\n",
      "5. 0.8564513211760618\n"
     ]
    }
   ],
   "source": [
    "# embedded_query와 embedded_docs 간의 유사도 계산.\n",
    "\n",
    "for i, ev in enumerate(embedded_docs):\n",
    "    print(f\"{i+1}. {cosine_similarity(ev, embedded_query)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82d02707-99d9-4d48-826f-ae446a405fc6",
   "metadata": {},
   "source": [
    "# 벡터 데이터베이스(Vector Database)\n",
    "- Embedding 된 문서를 Vector Database(Vector Store)에 저장한다.\n",
    "- 이후 질문(Query)와 관련된 내용을 유사도를 이용해 검색해 질문과 함께 prompt로 만든다. (Retrieve)\n",
    "\n",
    "![rag_vector_store](figures/rag_vector_store.png)\n",
    "\n",
    "## 벡터 데이터베이스란\n",
    "- 벡터 임베딩을 저장하고 관리하는 데이터베이스를 의미한다.\n",
    "- 모든 데이터는 적절한 임베딩 모델을 활용하면 임베딩 벡터로 변환할 수 있다. 이렇게 변환된 임베딩 벡터를 벡터 데이터베이스에 저장하면 **임베딩 벡터 간의 거리 계산을 통해 데이터 간 유사도를 검색할 수 있다.**\n",
    "    - **이미지, 텍스트, 음성 등 비정형 데이터**를 임베딩 모델로 **벡터화한 뒤 데이터베이스에 저장**한다.\n",
    "    - 벡터 간의 **유사도 계산**을 통해 연관성 있는 데이터나 유사한 데이터를 효과적으로 검색할 수 있다.\n",
    "    - 좋은 검색 결과를 위해서는 벡터의 품질이 중요하다. 그래서 **임베딩 모델(Embedding Model)을 잘 선택하는 것이 중요**하다.\n",
    "- 벡터 데이터베이스는 이러한 벡터 간 거리 계산에 특화된 데이터베이스다.\n",
    "\n",
    "## 주요 특징\n",
    "\n",
    "- **고차원 벡터 저장**\n",
    "  -  벡터 데이터베이스는 수백에서 수천 차원에 이르는 벡터 데이터를 효율적으로 저장하고 관리한다. \n",
    "  -  전통적인 데이터베이스로는 어려운 고차원 벡터 간 유사도 검색을 효율적으로 수행한다.\n",
    "- **유사성 기반 검색**\n",
    "  -  벡터 간의 거리를 측정하여 유사한 데이터를 빠르게 검색할 수 있다. \n",
    "  -  일반적으로 사용되는 거리계산기법은 다음과 같다.\n",
    "     - 코사인 유사도(Cosine Similarity)\n",
    "     - 유클리드 거리(Euclidean Distance)\n",
    "     - 맨하탄 거리(Manhattan Distance) \n",
    "- 비정형 데이터 처리: 텍스트, 이미지, 오디오 등 다양한 비정형 데이터를 벡터로 변환하여 저장하고, 이러한 데이터를 효과적으로 검색할 수 있다.\n",
    "\n",
    "## 벡터 데이터베이스와 딥러닝\n",
    "- 벡터 데이터베이스는 딥러닝 기술의 발전과 깊은 관련이 있다.\n",
    "- 딥러닝 모델은 학습 과정에서 데이터의 특징을 추출하는 방법을 함께 학습한다. 충분한 데이터를 학습한 딥러닝 모델은 **데이터의 특성을 설명하는 특성 벡터(feature vector)를 효과적으로 생성**할 수 있다.\n",
    "- 이때 추출된 특성 벡터는 고차원 데이터(RAW Data)를 저차원 공간에서 표현한 **임베딩 벡터**다.\n",
    "    - > **임베딩**은 고차원 데이터를 저차원 공간으로 변환하여 표현하는 방법으로, 정보 손실을 최소화하면서 데이터 간의 의미 있는 관계를 벡터 공간에서 유지한다.\n",
    "- 딥러닝 모델로 추출한 데이터의 특징(feature vector)을 임베딩 공간에 배치하면, 비슷한 데이터는 가까이, 그렇지 않은 데이터는 멀리 배치된다.\n",
    "- 이러한 특성을 활용하면 임베딩 벡터 간의 거리를 계산해 유사한 데이터를 효과적으로 검색할 수 있다. 벡터 데이터베이스는 이러한 임베딩 벡터의 특성을 기반으로 개발되었다.\n",
    "- 딥러닝 기술의 발전과 폭넓은 활용으로 임베딩 데이터의 사용이 증가하면서, 이를 저장하고 관리하는 기능에 특화된 데이터베이스에 대한 수요도 증가해 다양한 벡터 데이터베이스가 등장했다.\n",
    "\n",
    "## 벡터 데이터베이스의 주요 기능\n",
    "1. **저장**  \n",
    "   - 이미지, 텍스트, 음성 등 **비정형 데이터**를 임베딩 모델을 통해 벡터로 변환한 뒤 벡터 데이터베이스에 저장한다.\n",
    "2. **검색**  \n",
    "   - 검색하려는 데이터를 임베딩 모델로 변환한 뒤, 벡터 데이터베이스에서 **유사도를 기반**으로 검색한다.\n",
    "3. **결과 반환**  \n",
    "   - 벡터 데이터베이스는 저장된 벡터 중 검색 쿼리 임베딩과 가장 가까운 벡터를 찾아 반환한다.\n",
    "\n",
    "## LLM과 벡터 데이터베이스\n",
    "- ChatGPT(LLM)의 등장 이후 벡터 데이터베이스는 폭발적인 주목을 받았다.\n",
    "- 임베딩 벡터의 유사도를 기반으로 문서를 검색하는 RAG(Relevant Augmented Generation) 기술은 LLM의 환각(할루시네이션) 현상을 줄이고, LLM을 추가 학습하지 않고도 최신 정보를 효율적으로 활용할 수 있는 핵심 기법으로 자리 잡았다.\n",
    "   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51a65063-9482-4fdb-9ada-941eb08fb3b2",
   "metadata": {},
   "source": [
    "## 벡터 데이터베이스 종류\n",
    "![img](figures/vector_database.png)\n",
    "\n",
    "<<https://blog.det.life/why-you-shouldnt-invest-in-vector-databases-c0cd3f59d23c>>\n",
    "\n",
    "### 주요 벡터 데이터베이스 종류\n",
    "- **Pinecone**\n",
    "    - 클라우드 기반의 완전 관리형 벡터 데이터베이스 서비스로, 간단한 API를 통해 벡터 데이터를 관리할 수 있다.  \n",
    "    - 자동 확장성과 고가용성을 제공하며, 실시간 데이터 수집과 유사성 검색에 최적화되어 있다.\n",
    "    - 가장 쉽게 시작할 수 있는 관리형 서비스를 제공한다.\n",
    "- **Chroma**\n",
    "    - 벡터 임베딩을 효율적으로 저장하고 검색할 수 있는 오픈소스 데이터베이스로, AI 및 머신러닝 애플리케이션에 최적화되어 있다.\n",
    "    - 대규모 임베딩 저장에 최적화되어 있다.\n",
    "- **FAISS**\n",
    "    - Facebook AI에서 개발한 고성능 벡터 검색 라이브러리로, 고차원 벡터의 효율적인 유사성 검색을 위해 최적화되어 있다.\n",
    "    - GPU를 활용해 계산 성능을 높이며, 벡터 양자화 기술을 활용하여 메모리 사용을 최적화한다.\n",
    "    - 근사 최근접 이웃 검색(ANNS)에 최적화되어 있다.\n",
    "- **Milvus**\n",
    "    - 오픈소스 벡터 데이터베이스로, 대규모 벡터 데이터를 효율적으로 저장하고 검색할 수 있다.  \n",
    "    - 분산 아키텍처를 채택하여 확장성이 뛰어나며, IVF_PQ, DiskANN 등 다양한 인덱싱 알고리즘을 지원한다.\n",
    "    - 대규모 데이터셋 처리에 가장 적합한 솔루션이다.\n",
    "- **Weaviate**\n",
    "    - 오픈소스 벡터 데이터베이스로, 텍스트, 이미지, 오디오 등 다양한 비정형 데이터를 벡터로 저장하고 검색할 수 있다.  \n",
    "    - GraphQL API를 통해 접근 가능하며, 내장된 머신러닝 모듈을 통해 가장 강력한 의미론적 검색 기능을 제공한다.\n",
    "- **Qdrant**\n",
    "    - Rust로 개발된 고성능 벡터 검색 엔진으로, 실시간 근사 최근접 이웃 검색을 제공한다.  \n",
    "    - 추천 시스템에 특화되어 있으며, 벡터 임베딩 저장과 유사도 쿼리를 효율적으로 수행한다.\n",
    "- **Elasticsearch**\n",
    "    - HNSW 알고리즘을 사용하여 벡터 검색을 구현하는 검색 엔진이다.\n",
    "    - 전통적인 검색 기능과 벡터 검색을 효과적으로 결합할 수 있어, 하이브리드 검색에 가장 적합하다.\n",
    "- **PGVector**\n",
    "    - PostgreSQL의 확장 모듈로, 벡터 데이터를 저장하고 유사성 검색을 수행할 수 있게 해준다.  \n",
    "    - SQL과 통합된 벡터 연산이 가능하며, L2 거리, 코사인 거리, 내적 등 다양한 거리 측정 방식을 지원한다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bf3f6fe-c5e2-4c4f-9ef8-2cf5850f1bb7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1336f523-0b76-419c-8e46-fa96bdbcbdd6",
   "metadata": {},
   "source": [
    "# Langchain - Vector Store 연동 \n",
    "- Langchain은 다양한 벡터 데이터베이스와 연동할 수 있다.\n",
    "- 벡터 데이터베이스 마다 API가 다르기 때문에, Langchain을 사용하면 동일한 interface로 사용할 수 있다.\n",
    "\n",
    "## **VectorStore**\n",
    "- Langchain이 지원하는 모든 벡터 데이터베이스는 **VectorStore** 인터페이스를 구현한다.\n",
    "- 그래서 Langchain에서는 벡터 데이터베이스를 **Vector Store** 라고 한다.\n",
    "- https://python.langchain.com/docs/integrations/vectorstores/\n",
    "\n",
    "### Vector Store 연결\n",
    "- Vector DB와 연결하는 메소드\n",
    "- `VectorStore.from_document()`\n",
    "  - Document들을 insert 하면서 연결.\n",
    "  - Database가 있으면 연결, 없으면 생성하면서 연결한다.\n",
    "  - Parameter\n",
    "    - documents: insert할 문서들을 list[Document]로 전달.\n",
    "    - embedding model\n",
    "    - vector db에 연결하기 위한 설정들을 넣어준다.\n",
    "-`VectorStore()`\n",
    "  - vector db와 연결만 한다.\n",
    "  - Database가 있으면 연결, 없으면 생성하면서 연결한다.\n",
    "  - Parameter\n",
    "    - embedding model\n",
    "    - vector db에 연결하기 위한 설정들을 넣어준다.\n",
    "## InMemoryVectorStore\n",
    "- langchain에서 제공하는 메모리 기반 벡터 데이터베이스이다.\n",
    "- Data들을 Dictionary를 사용해 메모리에 저장하며, 검색 할 때 코사인 유사도(cosine similarity)를 계산하여 조회한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "a7fcddfb-0fd3-4cb8-a4f0-b72d1988d6b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "1092d6e3-2c41-426d-ac58-5f4ba1201ecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_core.vectorstores import InMemoryVectorStore\n",
    "\n",
    "embedding_model = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "# VectorStore 생성시 Embedding 모델을 넣어 생성한다.\n",
    "\n",
    "vector_store = InMemoryVectorStore(\n",
    "    embedding = embedding_model\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "afbc4641-857c-47c1-80ff-5f4c2651a4b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1', '2', '3']"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 문서 정의\n",
    "\n",
    "from langchain_core.documents import Document\n",
    "\n",
    "d1 = Document(\n",
    "    id = \"1\", # 문서 ID(식별자)\n",
    "    page_content=\"Apple, Pear, Watermelon\", # 문서 내용\n",
    "    metadata={\"category\":\"fruit\"}, # 문서 정보\n",
    ")\n",
    "\n",
    "d2 = Document(\n",
    "    id = \"2\",\n",
    "    page_content=\"Python, C++, Java, C#, Rust\",\n",
    "    metadata={\"category\":\"IT\"}\n",
    ")\n",
    "\n",
    "d3 = Document(\n",
    "    id = \"3\",\n",
    "    page_content=\"Football, Baseball, Basketball\",\n",
    "    metadata={\"category\":\"Sports\"}\n",
    ")\n",
    "\n",
    "docs = [d1,d2,d3]\n",
    "\n",
    "# Vector DB에 저장.\n",
    "\n",
    "vector_store.add_documents(documents=docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "473afa9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DB와 연결하면서 document들을 insert/upsert\n",
    "\n",
    "vector_store2 = InMemoryVectorStore.from_documents(\n",
    "    documents=docs,\n",
    "    embedding = embedding_model\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "06164955",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"SQL\"\n",
    "\n",
    "result = vector_store.similarity_search_with_score( # 검색한 결과 + 유사도 점수\n",
    "# result = vector_store.similarity_search(\n",
    "    query=query, # 찾을 질문.\n",
    "    k=2, # 몇개 문서를 찾을지 지정\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "e573fe12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(Document(id='2', metadata={'category': 'IT'}, page_content='Python, C++, Java, C#, Rust'),\n",
       "  0.29180902701976313),\n",
       " (Document(id='3', metadata={'category': 'Sports'}, page_content='Football, Baseball, Basketball'),\n",
       "  0.2635361695895074)]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0da7c8f-c1be-4ddf-a935-90b22eac1f11",
   "metadata": {},
   "source": [
    "# 실습\n",
    "- data/olympic.txt\n",
    "1. text loading\n",
    "2. text split\n",
    "3. embedding + vector store(InMemoryVectorStore)에 저장\n",
    "4. query(질의)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "349be3ce-539e-4d18-bc2b-67e8100ebcb6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "152a3ac6-6f56-41ea-9c60-6a982226eb1f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e8d01f0-2fd7-4795-85a1-4ce9ea26a00c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f2c15ed2-e9d6-4361-9d9e-0dfaf650de41",
   "metadata": {},
   "source": [
    "## MMR(최대 한계 관련성-Maximal Marginal Relevance) 알고리즘 적용\n",
    "최대 한계 관련성(Maximal Marginal Relevance, MMR) 알고리즘은 정보 검색 및 요약에서 검색 결과의 **관련성**과 **다양성**을 동시에 고려하여 최적의 결과를 제공하는 방법이다. \n",
    "이 알고리즘은 사용자 쿼리와의 관련성을 최대화하면서도 중복 정보를 최소화하여 다양한 정보를 제공하는 것을 목표로 한다.\n",
    "\n",
    "1. **관련성과 다양성의 균형 조절**: MMR은 사용자 쿼리와 문서 간의 유사성 점수와 이미 선택된 문서들과의 다양성 점수를 조합하여 각 문서의 최종 점수를 계산한다. 이를 통해 관련성이 높으면서도 중복되지 않는 문서를 선택한다.\n",
    "\n",
    "2. **수학적 정의**\n",
    "   $$\n",
    "   \\text{MMR} = \\lambda \\cdot \\text{Sim}(d, Q) - (1 - \\lambda) \\cdot \\max_{d' \\in D'} \\text{Sim}(d, d')\n",
    "   $$\n",
    "\n",
    "   - $\\text{Sim}(d, Q)$: 문서 $d$와 쿼리 $\\text{Q}$ 사이의 유사성. (문서 유사성 계산)\n",
    "   - $\\max_{d' \\in D'} \\text{Sim}(d, d')$: 문서 $d$와 이미 선택된 문서 집합 $D'$ 중 가장 유사한 문서와의 유사성. (문서 다양성 계산)\n",
    "   - $\\lambda$: 유사성과 다양성의 중요도를 조절하는 매개변수(parameter)\n",
    "3. **적용 분야**: MMR은 정보 검색, 추천 시스템, 문서 요약 등에서 활용된다. 특히 LLM 검색에서 성능 향상이 입증되었다.\n",
    "\n",
    "### `vectorStore.max_marginal_relevance_search()` 메소드\n",
    "  - MMR 알고리즘을 적용한 검색을 수행한다.\n",
    "  - **파라미터**\n",
    "    - **query**: 사용자로부터 입력받은 검색 쿼리\n",
    "    - **k**: 최종적으로 선택할 문서의 수\n",
    "    - **fetch\\_k**: MMR 알고리즘 적용 시 고려할 상위 문서의 수\n",
    "    - **lambda_mult**: 쿼리와의 유사성과 선택된 문서 간의 다양성 사이의 균형을 조절하는 매개변수. $\\lambda = 1$이면 유사성만 고려하고, $\\lambda = 0$이면 다양성만을 최대화한다.\n",
    "    - **filter**: 검색 결과를 필터링할 조건을 지정한다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f92a398d-f0f6-416f-aad8-4c97ced68992",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "908b3c9c-8f56-48fd-a952-9f79f0b75f23",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ab46f5a-14b4-4b0d-a6ea-4dd855a452c6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lang_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
