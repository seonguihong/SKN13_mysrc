{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cff5b412-7083-4729-b85e-203069873ce7",
   "metadata": {},
   "source": [
    "# Chroma Vector Database\n",
    "- Chroma는 대규모 언어 모델(LLM) 애플리케이션 구축을 위해 설계된 AI 네이티브 **오픈 소스 벡터 데이터베이스**다.    \n",
    "- 임베딩 저장소, 쿼리 및 검색 등의 핵심 기능을 제공하여 개발자들이 효율적으로 작업할 수 있도록 돕는다. \n",
    "- https://www.trychroma.com/\n",
    "  \n",
    "## Chroma의 주요 특징\n",
    "\n",
    "- **오픈 소스 라이선스** \n",
    "  - Apache 2.0 라이선스에 따라 제공되어 누구나 자유롭게 사용하고 수정할 수 있다. \n",
    "- **다양한 개발 환경 지원**\n",
    "  -  Python 및 JavaScript/TypeScript SDK를 지원하여 다양한 Langchain 과 연동하여 활용할 수 있다. \n",
    "- **유연한 데이터 저장 옵션**\n",
    "  -  HTTP 방식, 디스크 저장 방식, 인메모리 방식을 선택하여 데이터를 저장할 수 있어 사용자 입장에서 매우 편리하다. \n",
    "- **간편한 사용법** \n",
    "  - 설치 및 사용법이 매우 간단하여 빠르게 프로토타입을 개발하고 검증할 수 있다. \n",
    "\n",
    "## 설치\n",
    "- <del>pip로 chromadb 설치시 **windows**에서는 c컴파일러 관련되어 에러가 난다. **conda 를 이용해 설치한다.**<del>\n",
    "- `conda install conda-forge::chromadb`\n",
    "- `pip install chromadb`\n",
    "- `pip install langchain-chroma`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "426009c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting chromadb\n",
      "  Downloading chromadb-1.0.12-cp39-abi3-win_amd64.whl.metadata (7.0 kB)\n",
      "Collecting build>=1.0.3 (from chromadb)\n",
      "  Downloading build-1.2.2.post1-py3-none-any.whl.metadata (6.5 kB)\n",
      "Requirement already satisfied: pydantic>=1.9 in c:\\users\\tjddm\\miniconda3\\envs\\lang_env\\lib\\site-packages (from chromadb) (2.11.5)\n",
      "Collecting fastapi==0.115.9 (from chromadb)\n",
      "  Downloading fastapi-0.115.9-py3-none-any.whl.metadata (27 kB)\n",
      "Collecting uvicorn>=0.18.3 (from uvicorn[standard]>=0.18.3->chromadb)\n",
      "  Downloading uvicorn-0.34.3-py3-none-any.whl.metadata (6.5 kB)\n",
      "Requirement already satisfied: numpy>=1.22.5 in c:\\users\\tjddm\\miniconda3\\envs\\lang_env\\lib\\site-packages (from chromadb) (2.3.0)\n",
      "Collecting posthog>=2.4.0 (from chromadb)\n",
      "  Downloading posthog-4.10.0-py3-none-any.whl.metadata (6.0 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in c:\\users\\tjddm\\miniconda3\\envs\\lang_env\\lib\\site-packages (from chromadb) (4.14.0)\n",
      "Requirement already satisfied: onnxruntime>=1.14.1 in c:\\users\\tjddm\\miniconda3\\envs\\lang_env\\lib\\site-packages (from chromadb) (1.19.2)\n",
      "Collecting opentelemetry-api>=1.2.0 (from chromadb)\n",
      "  Downloading opentelemetry_api-1.34.1-py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting opentelemetry-exporter-otlp-proto-grpc>=1.2.0 (from chromadb)\n",
      "  Downloading opentelemetry_exporter_otlp_proto_grpc-1.34.1-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting opentelemetry-instrumentation-fastapi>=0.41b0 (from chromadb)\n",
      "  Downloading opentelemetry_instrumentation_fastapi-0.55b1-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting opentelemetry-sdk>=1.2.0 (from chromadb)\n",
      "  Downloading opentelemetry_sdk-1.34.1-py3-none-any.whl.metadata (1.6 kB)\n",
      "Requirement already satisfied: tokenizers>=0.13.2 in c:\\users\\tjddm\\miniconda3\\envs\\lang_env\\lib\\site-packages (from chromadb) (0.21.1)\n",
      "Collecting pypika>=0.48.9 (from chromadb)\n",
      "  Downloading PyPika-0.48.9.tar.gz (67 kB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Requirement already satisfied: tqdm>=4.65.0 in c:\\users\\tjddm\\miniconda3\\envs\\lang_env\\lib\\site-packages (from chromadb) (4.67.1)\n",
      "Collecting overrides>=7.3.1 (from chromadb)\n",
      "  Using cached overrides-7.7.0-py3-none-any.whl.metadata (5.8 kB)\n",
      "Collecting importlib-resources (from chromadb)\n",
      "  Downloading importlib_resources-6.5.2-py3-none-any.whl.metadata (3.9 kB)\n",
      "Requirement already satisfied: grpcio>=1.58.0 in c:\\users\\tjddm\\miniconda3\\envs\\lang_env\\lib\\site-packages (from chromadb) (1.73.0)\n",
      "Collecting bcrypt>=4.0.1 (from chromadb)\n",
      "  Downloading bcrypt-4.3.0-cp39-abi3-win_amd64.whl.metadata (10 kB)\n",
      "Collecting typer>=0.9.0 (from chromadb)\n",
      "  Downloading typer-0.16.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting kubernetes>=28.1.0 (from chromadb)\n",
      "  Downloading kubernetes-33.1.0-py2.py3-none-any.whl.metadata (1.7 kB)\n",
      "Requirement already satisfied: tenacity>=8.2.3 in c:\\users\\tjddm\\miniconda3\\envs\\lang_env\\lib\\site-packages (from chromadb) (9.1.2)\n",
      "Requirement already satisfied: pyyaml>=6.0.0 in c:\\users\\tjddm\\miniconda3\\envs\\lang_env\\lib\\site-packages (from chromadb) (6.0.2)\n",
      "Collecting mmh3>=4.0.1 (from chromadb)\n",
      "  Downloading mmh3-5.1.0-cp312-cp312-win_amd64.whl.metadata (16 kB)\n",
      "Requirement already satisfied: orjson>=3.9.12 in c:\\users\\tjddm\\miniconda3\\envs\\lang_env\\lib\\site-packages (from chromadb) (3.10.18)\n",
      "Requirement already satisfied: httpx>=0.27.0 in c:\\users\\tjddm\\miniconda3\\envs\\lang_env\\lib\\site-packages (from chromadb) (0.28.1)\n",
      "Collecting rich>=10.11.0 (from chromadb)\n",
      "  Downloading rich-14.0.0-py3-none-any.whl.metadata (18 kB)\n",
      "Requirement already satisfied: jsonschema>=4.19.0 in c:\\users\\tjddm\\miniconda3\\envs\\lang_env\\lib\\site-packages (from chromadb) (4.24.0)\n",
      "Collecting starlette<0.46.0,>=0.40.0 (from fastapi==0.115.9->chromadb)\n",
      "  Downloading starlette-0.45.3-py3-none-any.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\tjddm\\miniconda3\\envs\\lang_env\\lib\\site-packages (from pydantic>=1.9->chromadb) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in c:\\users\\tjddm\\miniconda3\\envs\\lang_env\\lib\\site-packages (from pydantic>=1.9->chromadb) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\users\\tjddm\\miniconda3\\envs\\lang_env\\lib\\site-packages (from pydantic>=1.9->chromadb) (0.4.1)\n",
      "Requirement already satisfied: anyio<5,>=3.6.2 in c:\\users\\tjddm\\miniconda3\\envs\\lang_env\\lib\\site-packages (from starlette<0.46.0,>=0.40.0->fastapi==0.115.9->chromadb) (4.9.0)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\tjddm\\miniconda3\\envs\\lang_env\\lib\\site-packages (from anyio<5,>=3.6.2->starlette<0.46.0,>=0.40.0->fastapi==0.115.9->chromadb) (3.10)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\tjddm\\miniconda3\\envs\\lang_env\\lib\\site-packages (from anyio<5,>=3.6.2->starlette<0.46.0,>=0.40.0->fastapi==0.115.9->chromadb) (1.3.1)\n",
      "Requirement already satisfied: packaging>=19.1 in c:\\users\\tjddm\\miniconda3\\envs\\lang_env\\lib\\site-packages (from build>=1.0.3->chromadb) (24.2)\n",
      "Collecting pyproject_hooks (from build>=1.0.3->chromadb)\n",
      "  Downloading pyproject_hooks-1.2.0-py3-none-any.whl.metadata (1.3 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\tjddm\\miniconda3\\envs\\lang_env\\lib\\site-packages (from build>=1.0.3->chromadb) (0.4.6)\n",
      "Requirement already satisfied: certifi in c:\\users\\tjddm\\miniconda3\\envs\\lang_env\\lib\\site-packages (from httpx>=0.27.0->chromadb) (2025.4.26)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\tjddm\\miniconda3\\envs\\lang_env\\lib\\site-packages (from httpx>=0.27.0->chromadb) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\users\\tjddm\\miniconda3\\envs\\lang_env\\lib\\site-packages (from httpcore==1.*->httpx>=0.27.0->chromadb) (0.16.0)\n",
      "Requirement already satisfied: attrs>=22.2.0 in c:\\users\\tjddm\\miniconda3\\envs\\lang_env\\lib\\site-packages (from jsonschema>=4.19.0->chromadb) (25.3.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in c:\\users\\tjddm\\miniconda3\\envs\\lang_env\\lib\\site-packages (from jsonschema>=4.19.0->chromadb) (2025.4.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in c:\\users\\tjddm\\miniconda3\\envs\\lang_env\\lib\\site-packages (from jsonschema>=4.19.0->chromadb) (0.36.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in c:\\users\\tjddm\\miniconda3\\envs\\lang_env\\lib\\site-packages (from jsonschema>=4.19.0->chromadb) (0.25.1)\n",
      "Requirement already satisfied: six>=1.9.0 in c:\\users\\tjddm\\miniconda3\\envs\\lang_env\\lib\\site-packages (from kubernetes>=28.1.0->chromadb) (1.17.0)\n",
      "Requirement already satisfied: python-dateutil>=2.5.3 in c:\\users\\tjddm\\miniconda3\\envs\\lang_env\\lib\\site-packages (from kubernetes>=28.1.0->chromadb) (2.9.0.post0)\n",
      "Requirement already satisfied: google-auth>=1.0.1 in c:\\users\\tjddm\\miniconda3\\envs\\lang_env\\lib\\site-packages (from kubernetes>=28.1.0->chromadb) (2.40.3)\n",
      "Collecting websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 (from kubernetes>=28.1.0->chromadb)\n",
      "  Using cached websocket_client-1.8.0-py3-none-any.whl.metadata (8.0 kB)\n",
      "Requirement already satisfied: requests in c:\\users\\tjddm\\miniconda3\\envs\\lang_env\\lib\\site-packages (from kubernetes>=28.1.0->chromadb) (2.32.3)\n",
      "Collecting requests-oauthlib (from kubernetes>=28.1.0->chromadb)\n",
      "  Downloading requests_oauthlib-2.0.0-py2.py3-none-any.whl.metadata (11 kB)\n",
      "Collecting oauthlib>=3.2.2 (from kubernetes>=28.1.0->chromadb)\n",
      "  Downloading oauthlib-3.2.2-py3-none-any.whl.metadata (7.5 kB)\n",
      "Requirement already satisfied: urllib3>=1.24.2 in c:\\users\\tjddm\\miniconda3\\envs\\lang_env\\lib\\site-packages (from kubernetes>=28.1.0->chromadb) (2.4.0)\n",
      "Collecting durationpy>=0.7 (from kubernetes>=28.1.0->chromadb)\n",
      "  Downloading durationpy-0.10-py3-none-any.whl.metadata (340 bytes)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\tjddm\\miniconda3\\envs\\lang_env\\lib\\site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (5.5.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\tjddm\\miniconda3\\envs\\lang_env\\lib\\site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.4.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\tjddm\\miniconda3\\envs\\lang_env\\lib\\site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (4.9.1)\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in c:\\users\\tjddm\\miniconda3\\envs\\lang_env\\lib\\site-packages (from rsa<5,>=3.1.4->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.6.1)\n",
      "Requirement already satisfied: coloredlogs in c:\\users\\tjddm\\miniconda3\\envs\\lang_env\\lib\\site-packages (from onnxruntime>=1.14.1->chromadb) (15.0.1)\n",
      "Requirement already satisfied: flatbuffers in c:\\users\\tjddm\\miniconda3\\envs\\lang_env\\lib\\site-packages (from onnxruntime>=1.14.1->chromadb) (25.2.10)\n",
      "Requirement already satisfied: protobuf in c:\\users\\tjddm\\miniconda3\\envs\\lang_env\\lib\\site-packages (from onnxruntime>=1.14.1->chromadb) (6.31.1)\n",
      "Requirement already satisfied: sympy in c:\\users\\tjddm\\miniconda3\\envs\\lang_env\\lib\\site-packages (from onnxruntime>=1.14.1->chromadb) (1.14.0)\n",
      "Collecting importlib-metadata<8.8.0,>=6.0 (from opentelemetry-api>=1.2.0->chromadb)\n",
      "  Downloading importlib_metadata-8.7.0-py3-none-any.whl.metadata (4.8 kB)\n",
      "Collecting zipp>=3.20 (from importlib-metadata<8.8.0,>=6.0->opentelemetry-api>=1.2.0->chromadb)\n",
      "  Downloading zipp-3.23.0-py3-none-any.whl.metadata (3.6 kB)\n",
      "Requirement already satisfied: googleapis-common-protos~=1.52 in c:\\users\\tjddm\\miniconda3\\envs\\lang_env\\lib\\site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.70.0)\n",
      "Collecting opentelemetry-exporter-otlp-proto-common==1.34.1 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb)\n",
      "  Downloading opentelemetry_exporter_otlp_proto_common-1.34.1-py3-none-any.whl.metadata (1.9 kB)\n",
      "Collecting opentelemetry-proto==1.34.1 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb)\n",
      "  Downloading opentelemetry_proto-1.34.1-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting protobuf (from onnxruntime>=1.14.1->chromadb)\n",
      "  Downloading protobuf-5.29.5-cp310-abi3-win_amd64.whl.metadata (592 bytes)\n",
      "Collecting opentelemetry-semantic-conventions==0.55b1 (from opentelemetry-sdk>=1.2.0->chromadb)\n",
      "  Downloading opentelemetry_semantic_conventions-0.55b1-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting opentelemetry-instrumentation-asgi==0.55b1 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
      "  Downloading opentelemetry_instrumentation_asgi-0.55b1-py3-none-any.whl.metadata (2.0 kB)\n",
      "Collecting opentelemetry-instrumentation==0.55b1 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
      "  Downloading opentelemetry_instrumentation-0.55b1-py3-none-any.whl.metadata (6.7 kB)\n",
      "Collecting opentelemetry-util-http==0.55b1 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
      "  Downloading opentelemetry_util_http-0.55b1-py3-none-any.whl.metadata (2.6 kB)\n",
      "Requirement already satisfied: wrapt<2.0.0,>=1.0.0 in c:\\users\\tjddm\\miniconda3\\envs\\lang_env\\lib\\site-packages (from opentelemetry-instrumentation==0.55b1->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (1.17.2)\n",
      "Collecting asgiref~=3.0 (from opentelemetry-instrumentation-asgi==0.55b1->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
      "  Downloading asgiref-3.8.1-py3-none-any.whl.metadata (9.3 kB)\n",
      "Requirement already satisfied: backoff>=1.10.0 in c:\\users\\tjddm\\miniconda3\\envs\\lang_env\\lib\\site-packages (from posthog>=2.4.0->chromadb) (2.2.1)\n",
      "Requirement already satisfied: distro>=1.5.0 in c:\\users\\tjddm\\miniconda3\\envs\\lang_env\\lib\\site-packages (from posthog>=2.4.0->chromadb) (1.9.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\tjddm\\miniconda3\\envs\\lang_env\\lib\\site-packages (from requests->kubernetes>=28.1.0->chromadb) (3.4.2)\n",
      "Collecting markdown-it-py>=2.2.0 (from rich>=10.11.0->chromadb)\n",
      "  Downloading markdown_it_py-3.0.0-py3-none-any.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\tjddm\\miniconda3\\envs\\lang_env\\lib\\site-packages (from rich>=10.11.0->chromadb) (2.19.1)\n",
      "Collecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich>=10.11.0->chromadb)\n",
      "  Downloading mdurl-0.1.2-py3-none-any.whl.metadata (1.6 kB)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in c:\\users\\tjddm\\miniconda3\\envs\\lang_env\\lib\\site-packages (from tokenizers>=0.13.2->chromadb) (0.32.4)\n",
      "Requirement already satisfied: filelock in c:\\users\\tjddm\\miniconda3\\envs\\lang_env\\lib\\site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (3.18.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\tjddm\\miniconda3\\envs\\lang_env\\lib\\site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (2025.5.1)\n",
      "Requirement already satisfied: click>=8.0.0 in c:\\users\\tjddm\\miniconda3\\envs\\lang_env\\lib\\site-packages (from typer>=0.9.0->chromadb) (8.2.1)\n",
      "Collecting shellingham>=1.3.0 (from typer>=0.9.0->chromadb)\n",
      "  Downloading shellingham-1.5.4-py2.py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting httptools>=0.6.3 (from uvicorn[standard]>=0.18.3->chromadb)\n",
      "  Downloading httptools-0.6.4-cp312-cp312-win_amd64.whl.metadata (3.7 kB)\n",
      "Requirement already satisfied: python-dotenv>=0.13 in c:\\users\\tjddm\\miniconda3\\envs\\lang_env\\lib\\site-packages (from uvicorn[standard]>=0.18.3->chromadb) (1.1.0)\n",
      "Collecting watchfiles>=0.13 (from uvicorn[standard]>=0.18.3->chromadb)\n",
      "  Downloading watchfiles-1.1.0-cp312-cp312-win_amd64.whl.metadata (5.0 kB)\n",
      "Collecting websockets>=10.4 (from uvicorn[standard]>=0.18.3->chromadb)\n",
      "  Downloading websockets-15.0.1-cp312-cp312-win_amd64.whl.metadata (7.0 kB)\n",
      "Requirement already satisfied: humanfriendly>=9.1 in c:\\users\\tjddm\\miniconda3\\envs\\lang_env\\lib\\site-packages (from coloredlogs->onnxruntime>=1.14.1->chromadb) (10.0)\n",
      "Requirement already satisfied: pyreadline3 in c:\\users\\tjddm\\miniconda3\\envs\\lang_env\\lib\\site-packages (from humanfriendly>=9.1->coloredlogs->onnxruntime>=1.14.1->chromadb) (3.5.4)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\tjddm\\miniconda3\\envs\\lang_env\\lib\\site-packages (from sympy->onnxruntime>=1.14.1->chromadb) (1.3.0)\n",
      "Downloading chromadb-1.0.12-cp39-abi3-win_amd64.whl (19.3 MB)\n",
      "   ---------------------------------------- 0.0/19.3 MB ? eta -:--:--\n",
      "   ----------- ---------------------------- 5.5/19.3 MB 30.5 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 12.3/19.3 MB 30.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  19.1/19.3 MB 31.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 19.3/19.3 MB 29.0 MB/s eta 0:00:00\n",
      "Downloading fastapi-0.115.9-py3-none-any.whl (94 kB)\n",
      "Downloading starlette-0.45.3-py3-none-any.whl (71 kB)\n",
      "Downloading bcrypt-4.3.0-cp39-abi3-win_amd64.whl (152 kB)\n",
      "Downloading build-1.2.2.post1-py3-none-any.whl (22 kB)\n",
      "Downloading kubernetes-33.1.0-py2.py3-none-any.whl (1.9 MB)\n",
      "   ---------------------------------------- 0.0/1.9 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.9/1.9 MB 26.7 MB/s eta 0:00:00\n",
      "Downloading durationpy-0.10-py3-none-any.whl (3.9 kB)\n",
      "Downloading mmh3-5.1.0-cp312-cp312-win_amd64.whl (41 kB)\n",
      "Downloading oauthlib-3.2.2-py3-none-any.whl (151 kB)\n",
      "Downloading opentelemetry_api-1.34.1-py3-none-any.whl (65 kB)\n",
      "Downloading importlib_metadata-8.7.0-py3-none-any.whl (27 kB)\n",
      "Downloading opentelemetry_exporter_otlp_proto_grpc-1.34.1-py3-none-any.whl (18 kB)\n",
      "Downloading opentelemetry_exporter_otlp_proto_common-1.34.1-py3-none-any.whl (18 kB)\n",
      "Downloading opentelemetry_proto-1.34.1-py3-none-any.whl (55 kB)\n",
      "Downloading opentelemetry_sdk-1.34.1-py3-none-any.whl (118 kB)\n",
      "Downloading opentelemetry_semantic_conventions-0.55b1-py3-none-any.whl (196 kB)\n",
      "Downloading protobuf-5.29.5-cp310-abi3-win_amd64.whl (434 kB)\n",
      "Downloading opentelemetry_instrumentation_fastapi-0.55b1-py3-none-any.whl (12 kB)\n",
      "Downloading opentelemetry_instrumentation-0.55b1-py3-none-any.whl (31 kB)\n",
      "Downloading opentelemetry_instrumentation_asgi-0.55b1-py3-none-any.whl (16 kB)\n",
      "Downloading opentelemetry_util_http-0.55b1-py3-none-any.whl (7.3 kB)\n",
      "Downloading asgiref-3.8.1-py3-none-any.whl (23 kB)\n",
      "Using cached overrides-7.7.0-py3-none-any.whl (17 kB)\n",
      "Downloading posthog-4.10.0-py3-none-any.whl (102 kB)\n",
      "Downloading rich-14.0.0-py3-none-any.whl (243 kB)\n",
      "Downloading markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\n",
      "Downloading mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Downloading typer-0.16.0-py3-none-any.whl (46 kB)\n",
      "Downloading shellingham-1.5.4-py2.py3-none-any.whl (9.8 kB)\n",
      "Downloading uvicorn-0.34.3-py3-none-any.whl (62 kB)\n",
      "Downloading httptools-0.6.4-cp312-cp312-win_amd64.whl (88 kB)\n",
      "Downloading watchfiles-1.1.0-cp312-cp312-win_amd64.whl (292 kB)\n",
      "Using cached websocket_client-1.8.0-py3-none-any.whl (58 kB)\n",
      "Downloading websockets-15.0.1-cp312-cp312-win_amd64.whl (176 kB)\n",
      "Downloading zipp-3.23.0-py3-none-any.whl (10 kB)\n",
      "Downloading importlib_resources-6.5.2-py3-none-any.whl (37 kB)\n",
      "Downloading pyproject_hooks-1.2.0-py3-none-any.whl (10 kB)\n",
      "Downloading requests_oauthlib-2.0.0-py2.py3-none-any.whl (24 kB)\n",
      "Building wheels for collected packages: pypika\n",
      "  Building wheel for pypika (pyproject.toml): started\n",
      "  Building wheel for pypika (pyproject.toml): finished with status 'done'\n",
      "  Created wheel for pypika: filename=pypika-0.48.9-py2.py3-none-any.whl size=53916 sha256=8639964c3fc63d9c92954bbf149655852fbaa8c961f712df4fd475583a378866\n",
      "  Stored in directory: c:\\users\\tjddm\\appdata\\local\\pip\\cache\\wheels\\d5\\3d\\69\\8d68d249cd3de2584f226e27fd431d6344f7d70fd856ebd01b\n",
      "Successfully built pypika\n",
      "Installing collected packages: pypika, durationpy, zipp, websockets, websocket-client, shellingham, pyproject_hooks, protobuf, overrides, opentelemetry-util-http, oauthlib, mmh3, mdurl, importlib-resources, httptools, bcrypt, asgiref, watchfiles, uvicorn, starlette, requests-oauthlib, posthog, opentelemetry-proto, markdown-it-py, importlib-metadata, build, rich, opentelemetry-exporter-otlp-proto-common, opentelemetry-api, kubernetes, fastapi, typer, opentelemetry-semantic-conventions, opentelemetry-sdk, opentelemetry-instrumentation, opentelemetry-instrumentation-asgi, opentelemetry-exporter-otlp-proto-grpc, opentelemetry-instrumentation-fastapi, chromadb\n",
      "\n",
      "   -- -------------------------------------  2/39 [zipp]\n",
      "   --- ------------------------------------  3/39 [websockets]\n",
      "   ---- -----------------------------------  4/39 [websocket-client]\n",
      "  Attempting uninstall: protobuf\n",
      "   ---- -----------------------------------  4/39 [websocket-client]\n",
      "   ------- --------------------------------  7/39 [protobuf]\n",
      "    Found existing installation: protobuf 6.31.1\n",
      "   ------- --------------------------------  7/39 [protobuf]\n",
      "    Uninstalling protobuf-6.31.1:\n",
      "   ------- --------------------------------  7/39 [protobuf]\n",
      "      Successfully uninstalled protobuf-6.31.1\n",
      "   ------- --------------------------------  7/39 [protobuf]\n",
      "   ------- --------------------------------  7/39 [protobuf]\n",
      "   ------- --------------------------------  7/39 [protobuf]\n",
      "   --------- ------------------------------  9/39 [opentelemetry-util-http]\n",
      "   ---------- ----------------------------- 10/39 [oauthlib]\n",
      "   ---------- ----------------------------- 10/39 [oauthlib]\n",
      "   ------------- -------------------------- 13/39 [importlib-resources]\n",
      "   ---------------- ----------------------- 16/39 [asgiref]\n",
      "   ------------------ --------------------- 18/39 [uvicorn]\n",
      "   ------------------- -------------------- 19/39 [starlette]\n",
      "   ------------------- -------------------- 19/39 [starlette]\n",
      "   --------------------- ------------------ 21/39 [posthog]\n",
      "   --------------------- ------------------ 21/39 [posthog]\n",
      "   ---------------------- ----------------- 22/39 [opentelemetry-proto]\n",
      "   ----------------------- ---------------- 23/39 [markdown-it-py]\n",
      "   ----------------------- ---------------- 23/39 [markdown-it-py]\n",
      "   -------------------------- ------------- 26/39 [rich]\n",
      "   -------------------------- ------------- 26/39 [rich]\n",
      "   -------------------------- ------------- 26/39 [rich]\n",
      "   -------------------------- ------------- 26/39 [rich]\n",
      "   ---------------------------- ----------- 28/39 [opentelemetry-api]\n",
      "   ----------------------------- ---------- 29/39 [kubernetes]\n",
      "   ----------------------------- ---------- 29/39 [kubernetes]\n",
      "   ----------------------------- ---------- 29/39 [kubernetes]\n",
      "   ----------------------------- ---------- 29/39 [kubernetes]\n",
      "   ----------------------------- ---------- 29/39 [kubernetes]\n",
      "   ----------------------------- ---------- 29/39 [kubernetes]\n",
      "   ----------------------------- ---------- 29/39 [kubernetes]\n",
      "   ----------------------------- ---------- 29/39 [kubernetes]\n",
      "   ----------------------------- ---------- 29/39 [kubernetes]\n",
      "   ----------------------------- ---------- 29/39 [kubernetes]\n",
      "   ----------------------------- ---------- 29/39 [kubernetes]\n",
      "   ----------------------------- ---------- 29/39 [kubernetes]\n",
      "   ----------------------------- ---------- 29/39 [kubernetes]\n",
      "   ----------------------------- ---------- 29/39 [kubernetes]\n",
      "   ----------------------------- ---------- 29/39 [kubernetes]\n",
      "   ----------------------------- ---------- 29/39 [kubernetes]\n",
      "   ----------------------------- ---------- 29/39 [kubernetes]\n",
      "   ----------------------------- ---------- 29/39 [kubernetes]\n",
      "   ----------------------------- ---------- 29/39 [kubernetes]\n",
      "   ----------------------------- ---------- 29/39 [kubernetes]\n",
      "   ----------------------------- ---------- 29/39 [kubernetes]\n",
      "   ----------------------------- ---------- 29/39 [kubernetes]\n",
      "   ----------------------------- ---------- 29/39 [kubernetes]\n",
      "   ----------------------------- ---------- 29/39 [kubernetes]\n",
      "   ----------------------------- ---------- 29/39 [kubernetes]\n",
      "   ----------------------------- ---------- 29/39 [kubernetes]\n",
      "   ----------------------------- ---------- 29/39 [kubernetes]\n",
      "   ----------------------------- ---------- 29/39 [kubernetes]\n",
      "   ----------------------------- ---------- 29/39 [kubernetes]\n",
      "   ------------------------------ --------- 30/39 [fastapi]\n",
      "   ------------------------------- -------- 31/39 [typer]\n",
      "   --------------------------- ----- 32/39 [opentelemetry-semantic-conventions]\n",
      "   --------------------------- ----- 32/39 [opentelemetry-semantic-conventions]\n",
      "   --------------------------- ----- 32/39 [opentelemetry-semantic-conventions]\n",
      "   --------------------------------- ------ 33/39 [opentelemetry-sdk]\n",
      "   --------------------------------- ------ 33/39 [opentelemetry-sdk]\n",
      "   --------------------------------- ---- 34/39 [opentelemetry-instrumentation]\n",
      "   -------------------------------------- - 38/39 [chromadb]\n",
      "   -------------------------------------- - 38/39 [chromadb]\n",
      "   -------------------------------------- - 38/39 [chromadb]\n",
      "   -------------------------------------- - 38/39 [chromadb]\n",
      "   -------------------------------------- - 38/39 [chromadb]\n",
      "   -------------------------------------- - 38/39 [chromadb]\n",
      "   -------------------------------------- - 38/39 [chromadb]\n",
      "   -------------------------------------- - 38/39 [chromadb]\n",
      "   ---------------------------------------- 39/39 [chromadb]\n",
      "\n",
      "Successfully installed asgiref-3.8.1 bcrypt-4.3.0 build-1.2.2.post1 chromadb-1.0.12 durationpy-0.10 fastapi-0.115.9 httptools-0.6.4 importlib-metadata-8.7.0 importlib-resources-6.5.2 kubernetes-33.1.0 markdown-it-py-3.0.0 mdurl-0.1.2 mmh3-5.1.0 oauthlib-3.2.2 opentelemetry-api-1.34.1 opentelemetry-exporter-otlp-proto-common-1.34.1 opentelemetry-exporter-otlp-proto-grpc-1.34.1 opentelemetry-instrumentation-0.55b1 opentelemetry-instrumentation-asgi-0.55b1 opentelemetry-instrumentation-fastapi-0.55b1 opentelemetry-proto-1.34.1 opentelemetry-sdk-1.34.1 opentelemetry-semantic-conventions-0.55b1 opentelemetry-util-http-0.55b1 overrides-7.7.0 posthog-4.10.0 protobuf-5.29.5 pypika-0.48.9 pyproject_hooks-1.2.0 requests-oauthlib-2.0.0 rich-14.0.0 shellingham-1.5.4 starlette-0.45.3 typer-0.16.0 uvicorn-0.34.3 watchfiles-1.1.0 websocket-client-1.8.0 websockets-15.0.1 zipp-3.23.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "grpcio-status 1.73.0 requires protobuf<7.0.0,>=6.30.0, but you have protobuf 5.29.5 which is incompatible.\n"
     ]
    }
   ],
   "source": [
    "!pip install chromadb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d70ea95b-9244-4208-9d99-bb8698cc5d43",
   "metadata": {},
   "source": [
    "# Chroma API 를 이용해 연동\n",
    "- https://docs.trychroma.com/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a9d0df5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import chromadb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93535b1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from uuid import uuid4\n",
    "\n",
    "str(uuid4()) # ID값 생성해주는 함수. / 계속변함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8011c707-5a8e-4333-bb5f-c13bed9b30b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from uuid import uuid4\n",
    "\n",
    "# 추가할 데이터\n",
    "document_list = [\n",
    "        \"This is a document about pineapple\",\n",
    "        \"This is a document about oranges\",\n",
    "        \"This is a document about sports\",\n",
    "        \"This is a document about langchain\",\n",
    "]\n",
    "ids = [str(uuid4()) for _ in range(len(document_list))]\n",
    "# DB에 저장할 때 지정할 각 문서들의 ID 생성."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f0c31dd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "# Embedding modle 생성.\n",
    "embedding_model = OpenAIEmbeddings(model=\"text-embedding-3-small\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cb7a37e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "# 외부 Embedding model 사용\n",
    "\n",
    "import chromadb.utils.embedding_functions as embedding_functions\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "print(load_dotenv())\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "openai_ef = embedding_functions.OpenAIEmbeddingFunction(\n",
    "                api_key=OPENAI_API_KEY,\n",
    "                model_name=\"text-embedding-3-small\"\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2e807f75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# collection 생성 - Database 생성\n",
    "# Chroma DB와 연결\n",
    "\n",
    "import chromadb\n",
    "\n",
    "client = chromadb.Client() # Inmemory DB 생성. -> 데이터를 메모리에 저장.\n",
    "# client = chromadb.PersistentClient(path=\"vector_store/my_db\") # Local 파일에 저장\n",
    "# client = chromadb.HttpClient(host=\"ip주소\", port=8000) # 서버로 서비스하는 chromadb에 연결.\n",
    "\n",
    "# Collection(Database)를 생성.\n",
    "collection_name = \"test_db\"\n",
    "collection = client.create_collection(\n",
    "    name=collection_name,\n",
    "    get_or_create=True, # default = False / collection 이 있으면 연결, 없으면 생성. / False이면 동일한 collection이 존재 할시 exception.\n",
    "    metadata={\"hnsw:space\":\"cosine\"},\n",
    "    embedding_function=openai_ef\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "424223d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  데이터 추가\n",
    "\n",
    "collection.add(documents=document_list, ids=ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bb603121",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ids': [['22d6b42f-fff7-4070-9c18-3a9f2a1a9767',\n",
       "   '663b1671-9785-498b-93b7-181547eb7b6e'],\n",
       "  ['663b1671-9785-498b-93b7-181547eb7b6e',\n",
       "   '22d6b42f-fff7-4070-9c18-3a9f2a1a9767']],\n",
       " 'embeddings': None,\n",
       " 'documents': [['This is a document about langchain',\n",
       "   'This is a document about pineapple'],\n",
       "  ['This is a document about pineapple',\n",
       "   'This is a document about langchain']],\n",
       " 'uris': None,\n",
       " 'included': ['metadatas', 'documents', 'distances'],\n",
       " 'data': None,\n",
       " 'metadatas': [[None, None], [None, None]],\n",
       " 'distances': [[0.7781245708465576, 0.8145824670791626],\n",
       "  [0.7556753754615784, 0.8807662725448608]]}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 유사도 겁색\n",
    "\n",
    "result = collection.query(\n",
    "    query_texts= [\"deeplearning\", \"hawaii\"], # 질문\n",
    "    n_results=2, # 검색 결과의 개수\n",
    ")\n",
    "\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fb6c861",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fb8d7bba-a840-477e-9ef3-666b1d5c1301",
   "metadata": {},
   "source": [
    "# Langchain을 이용해 Chroma 연동\n",
    "\n",
    "## Data 준비"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d281e998-76c4-46b7-8e96-ddd08e7ba42c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-02T12:09:44.559588Z",
     "iopub.status.busy": "2024-12-02T12:09:44.558586Z",
     "iopub.status.idle": "2024-12-02T12:09:46.061566Z",
     "shell.execute_reply": "2024-12-02T12:09:46.061566Z",
     "shell.execute_reply.started": "2024-12-02T12:09:44.559588Z"
    }
   },
   "outputs": [],
   "source": [
    "from uuid import uuid4\n",
    "from langchain_core.documents import Document\n",
    "\n",
    "document_1 = Document(\n",
    "    page_content=\"I had chocolate chip pancakes and scrambled eggs for breakfast this morning.\",\n",
    "    metadata={\"source\": \"tweet\"},\n",
    "    id=1,\n",
    ")\n",
    "\n",
    "document_2 = Document(\n",
    "    page_content=\"The weather forecast for tomorrow is cloudy and overcast, with a high of 62 degrees.\",\n",
    "    metadata={\"source\": \"news\"},\n",
    "    id=2,\n",
    ")\n",
    "\n",
    "document_3 = Document(\n",
    "    page_content=\"Building an exciting new project with LangChain - come check it out!\",\n",
    "    metadata={\"source\": \"tweet\"},\n",
    "    id=3,\n",
    ")\n",
    "\n",
    "document_4 = Document(\n",
    "    page_content=\"Robbers broke into the city bank and stole $1 million in cash.\",\n",
    "    metadata={\"source\": \"news\"},\n",
    "    id=4,\n",
    ")\n",
    "\n",
    "document_5 = Document(\n",
    "    page_content=\"Wow! That was an amazing movie. I can't wait to see it again.\",\n",
    "    metadata={\"source\": \"tweet\"},\n",
    "    id=5,\n",
    ")\n",
    "\n",
    "document_6 = Document(\n",
    "    page_content=\"Is the new iPhone worth the price? Read this review to find out.\",\n",
    "    metadata={\"source\": \"website\"},\n",
    "    id=6,\n",
    ")\n",
    "\n",
    "document_7 = Document(\n",
    "    page_content=\"The top 10 soccer players in the world right now.\",\n",
    "    metadata={\"source\": \"website\"},\n",
    "    id=7,\n",
    ")\n",
    "\n",
    "document_8 = Document(\n",
    "    page_content=\"LangGraph is the best framework for building stateful, agentic applications!\",\n",
    "    metadata={\"source\": \"tweet\"},\n",
    "    id=8,\n",
    ")\n",
    "\n",
    "document_9 = Document(\n",
    "    page_content=\"The stock market is down 500 points today due to fears of a recession.\",\n",
    "    metadata={\"source\": \"news\"},\n",
    "    id=9,\n",
    ")\n",
    "\n",
    "document_10 = Document(\n",
    "    page_content=\"I have a bad feeling I am going to get deleted :(\",\n",
    "    metadata={\"source\": \"tweet\"},\n",
    "    id=10,\n",
    ")\n",
    "\n",
    "document_list = [document_1, document_2, document_3, document_4, document_5, document_6, document_7, document_8, document_9, document_10]\n",
    "\n",
    "ids = [str(uuid4()) for _ in range(len(document_list))]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd05fc0a-c00e-4df8-a455-0333cbf17821",
   "metadata": {},
   "source": [
    "## Vector Store 생성, 연결\n",
    "- Chroma.from_documents()\n",
    "  - VectorStore를 초기화(생성)하고 문서를 추가한다.\n",
    "  - persist_directory를 지정하지 않으면 메모리에 저장된다.\n",
    "- Chroma()\n",
    "  - VectorStore와 연결.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3aeed090-a67f-4599-a47d-0fe8b034603f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_chroma import Chroma\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "COLLECTION_NAME = \"example\" # 컬렉션 이름.\n",
    "PERSISTENT_PATH = \"vector_store/chroma/example_db\" # 저장할 로컬 경로.\n",
    "\n",
    "embedding_model = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "\n",
    "# 1. 연결(생성)하면서 document들을 저장.(upsert)\n",
    "\n",
    "vector_store = Chroma.from_documents(\n",
    "    documents = document_list,\n",
    "    ids = ids,\n",
    "    embedding = embedding_model,\n",
    "    collection_name = COLLECTION_NAME,\n",
    "    persist_directory = PERSISTENT_PATH\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e16c700e-54ec-43a9-890b-ae804cf3ca3f",
   "metadata": {},
   "source": [
    "## VectorStore 정보 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e8ebf6ab-776b-4ae8-be97-7046de1873c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Collection(name=example)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coll = vector_store._collection # 연결된 collection 정보를 확인\n",
    "coll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9c586ed7-7d81-4a5f-ac49-f476ee980bc9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coll.count() # 저장된 데이터 개수"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "051a46bf-3d08-4c00-97d1-f71488b39c76",
   "metadata": {},
   "source": [
    "## Add (추가)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3c040506-b68c-43ed-95d7-3184a10dc742",
   "metadata": {},
   "outputs": [],
   "source": [
    "document_11 = Document(\n",
    "    page_content=\"랭체인은 대규모 언어 모델(LLM)을 효과적으로 활용하기 위한 도구와 프레임워크를 제공하는 오픈소스 라이브러리입니다.\",\n",
    "    metadata={\"source\": \"tweet\"},\n",
    "    id=10,\n",
    ")\n",
    "\n",
    "document_12 = Document(\n",
    "    page_content=\"랭체인은 체인 구조를 사용하여 여러 LLM 작업을 연결하고, 이를 통해 더 복잡하고 맞춤화된 자연어 처리 애플리케이션을 개발할 수 있게 합니다\",\n",
    "    metadata={\"source\": \"tweet\"},\n",
    "    id=10,\n",
    ")\n",
    "\n",
    "document_13 = Document(\n",
    "    page_content=\"랭체인, AI 활용의 새 시대를 열다: 복잡한 언어 처리도 간단하게!\",\n",
    "    metadata={\"source\": \"news\"},\n",
    "    id=10,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "92f9d5f9-aef7-4a5a-aec9-dbbd0ade4adf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ba33483b-69ef-463b-bfe4-db7decde56e7',\n",
       " '7504ce84-d0b6-42f2-a871-5b8e880141e5',\n",
       " '4a8eccd6-f0b9-455e-abeb-6610a7d2253a']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector_store.add_documents(\n",
    "    [document_11, document_12, document_13],\n",
    "    ids = [str(uuid4()), str(uuid4()), str(uuid4())]\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "fb752d1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coll.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3f0d979-ea73-4dfb-abe5-ff328cc77b3e",
   "metadata": {},
   "source": [
    "## Update(갱신)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9cf981b7-80e3-4a2f-b607-d73c409fdfd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_document_13 = Document(\n",
    "    page_content=\"랭체인, AI 활용의 새 시대를 열다: 복잡한 언어 처리도 간단하게 처리할수 있는 Framework!\",\n",
    "    metadata={\"source\": \"news\"},\n",
    "    id=10,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2960f4a5-6407-49cc-9272-7b8f37cc3dbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_store.update_document(\n",
    "    document_id=\"4a8eccd6-f0b9-455e-abeb-6610a7d2253a\", # 바꿀 문서의 ID\n",
    "    document= new_document_13 # 바꿀 내용을 가진 Document 객체\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "5f0a93b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "update_document_12 = Document(\n",
    "    page_content=\"랭체인은 체인 구조를 사용하여 여러 LLM 작업을 연결할 수있다.\",\n",
    "    metadata={\"source\": \"website\"},\n",
    ")\n",
    "\n",
    "update_document_13 = Document(\n",
    "    page_content=\"랭체인, AI 활용의 새 시대를 열다: 복잡한 언어 처리도 간단하게!\",\n",
    "    metadata={\"source\": \"news\"},\n",
    ")\n",
    "\n",
    "update_docs = [update_document_12, update_document_13]\n",
    "update_ids = ['7504ce84-d0b6-42f2-a871-5b8e880141e5', '4a8eccd6-f0b9-455e-abeb-6610a7d2253a']\n",
    "\n",
    "# 한번에 여러개 update\n",
    "vector_store.update_documents(documents=update_docs, ids=update_ids)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ea5ccca2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ids': ['428e603d-a8c2-418d-89ff-50ebdbdab8aa',\n",
       "  'fefdadc9-5c77-4452-bc2a-91119440043c',\n",
       "  '6a890808-a671-406f-9756-0318d1900341',\n",
       "  '3d3d67a4-8f6d-484d-9a23-3e3c14934b47',\n",
       "  '3425e544-f4fd-4608-9dad-c68f76cf4cc6',\n",
       "  'c8435827-32a2-4b14-bdbe-791d50dda6a1',\n",
       "  '97ca3bca-7944-4b2b-80c1-1e232f4139e7',\n",
       "  '45191a18-1603-4056-9b24-38230bc0ab31',\n",
       "  'cb40c318-80a9-4a9a-ac1c-a94d6b900f56',\n",
       "  '2f4f853c-326e-43ca-9b90-ac3505abf9fe',\n",
       "  'ba33483b-69ef-463b-bfe4-db7decde56e7',\n",
       "  '7504ce84-d0b6-42f2-a871-5b8e880141e5',\n",
       "  '4a8eccd6-f0b9-455e-abeb-6610a7d2253a'],\n",
       " 'embeddings': None,\n",
       " 'documents': ['I had chocolate chip pancakes and scrambled eggs for breakfast this morning.',\n",
       "  'The weather forecast for tomorrow is cloudy and overcast, with a high of 62 degrees.',\n",
       "  'Building an exciting new project with LangChain - come check it out!',\n",
       "  'Robbers broke into the city bank and stole $1 million in cash.',\n",
       "  \"Wow! That was an amazing movie. I can't wait to see it again.\",\n",
       "  'Is the new iPhone worth the price? Read this review to find out.',\n",
       "  'The top 10 soccer players in the world right now.',\n",
       "  'LangGraph is the best framework for building stateful, agentic applications!',\n",
       "  'The stock market is down 500 points today due to fears of a recession.',\n",
       "  'I have a bad feeling I am going to get deleted :(',\n",
       "  '랭체인은 대규모 언어 모델(LLM)을 효과적으로 활용하기 위한 도구와 프레임워크를 제공하는 오픈소스 라이브러리입니다.',\n",
       "  '랭체인은 체인 구조를 사용하여 여러 LLM 작업을 연결할 수있다.',\n",
       "  '랭체인, AI 활용의 새 시대를 열다: 복잡한 언어 처리도 간단하게!'],\n",
       " 'uris': None,\n",
       " 'included': ['metadatas', 'documents'],\n",
       " 'data': None,\n",
       " 'metadatas': [{'source': 'tweet'},\n",
       "  {'source': 'news'},\n",
       "  {'source': 'tweet'},\n",
       "  {'source': 'news'},\n",
       "  {'source': 'tweet'},\n",
       "  {'source': 'website'},\n",
       "  {'source': 'website'},\n",
       "  {'source': 'tweet'},\n",
       "  {'source': 'news'},\n",
       "  {'source': 'tweet'},\n",
       "  {'source': 'tweet'},\n",
       "  {'source': 'website'},\n",
       "  {'source': 'news'}]}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coll.get() # 전체 저장된 문서를 조회\n",
    "# vector_store.get()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28084f0a-4baf-4f94-8d06-6992d7551d81",
   "metadata": {},
   "source": [
    "## Delete(삭제)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "37216a6d-7192-438a-99f3-c1de8e2a0728",
   "metadata": {},
   "outputs": [],
   "source": [
    "del_ids = ['6a890808-a671-406f-9756-0318d1900341', '3d3d67a4-8f6d-484d-9a23-3e3c14934b47']\n",
    "\n",
    "vector_store.delete(ids=del_ids) # 삭제할 문서의 id들"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c82b1400-e241-4e83-bdb6-c3fb0157306f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coll.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3350ace1-7997-4e5b-a6b1-52a5741a41ce",
   "metadata": {},
   "source": [
    "## Query(조회)\n",
    "- `similarity_search(query, k, filter)`\n",
    "  - 저장되 있는 item들 중 질의와 가장 유사한 것 k개를 찾는다. \n",
    "  - 찾은 결과를 filter 조건으로 필터링 한다. filter 조건은 meta-data의 정보를 이용한다.\n",
    "  - 질의어(query)는 text(자연어)로 입력한다.\n",
    "- `similarity_search_with_score(query, k, filter)`\n",
    "  - 저장되 있는 item들 중 질의와 가장 유사한 것 k개를 찾아 유사도 점수와 함께 반환\n",
    "- `similarity_search_by_vector(embedding, k, filter)`\n",
    "  - Embedding Vector 를 질의로 입력한다. (질의(query)를 문장이 아니라 embedding vector로 입력.) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc28dff1-8241-4200-84ad-a3994595e9e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(Document(id='428e603d-a8c2-418d-89ff-50ebdbdab8aa', metadata={'source': 'tweet'}, page_content='I had chocolate chip pancakes and scrambled eggs for breakfast this morning.'),\n",
       "  1.1996257305145264),\n",
       " (Document(id='c8435827-32a2-4b14-bdbe-791d50dda6a1', metadata={'source': 'website'}, page_content='Is the new iPhone worth the price? Read this review to find out.'),\n",
       "  1.8273663520812988),\n",
       " (Document(id='ba33483b-69ef-463b-bfe4-db7decde56e7', metadata={'source': 'tweet'}, page_content='랭체인은 대규모 언어 모델(LLM)을 효과적으로 활용하기 위한 도구와 프레임워크를 제공하는 오픈소스 라이브러리입니다.'),\n",
       "  1.8730052709579468)]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = vector_store.similarity_search_with_score(\n",
    "    query = \"아침에 뭐먹을까?\",\n",
    "    k = 3, # 조회 개수\n",
    "    # filter= {\"source\":\"tweet\"} # metadata의 source키 값이 tweet(source == tweet)\n",
    "    filter = {\"source\":{\"$ne\":\"news\"}} # source가 news가 아닌것들.\n",
    "    # {metadata key: {\"연산자\":\"값\"}}\n",
    "    # {\"age\":{\"$gt\":30}} -> age > 30\n",
    ")\n",
    "# 1. filter에 설정과 metadata를 비교해서 조회\n",
    "# 2. 1에서 조회된 문서들과 query간의 유사도를 체크\n",
    "# 필터에서 먼저거르고 k개수 만큼 찾기\n",
    "results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lang_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
