{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "227316ea",
   "metadata": {},
   "source": [
    "# RAG(Retrieval Augmented Generation)\n",
    "- [RAG](https://python.langchain.com/v0.1/docs/modules/data_connection/)은 *Retrieval Augmented Generation*의 약자로, **검색 기반 생성 기법**을 의미한다. 이 기법은 LLM이 특정 문서에 기반하여 보다 정확하고 신뢰할 수 있는 답변을 생성할 수 있도록 돕는다.     \n",
    "- 사용자의 질문에 대해 자체적으로 구축한 데이터베이스(DB)나 외부 데이터베이스에서 질문과 관련된 문서를 검색하고, 이를 질문과 함께 LLM에 전달한다.\n",
    "- LLM은 같이 전달된 문서를 바탕으로 질문에 대한 답변을 생성한다. \n",
    "- 이를 통해 LLM이 학습하지 않은 내용도 다룰 수 있으며, 잘못된 정보를 생성하는 환각 현상(*hallucination*)을 줄일 수 있다.\n",
    "\n",
    "## RAG와 파인튜닝(Fine Tuning) 비교\n",
    "\n",
    "### 파인튜닝(Fine Tuning)\n",
    "\n",
    "- **정의**: 사전 학습(pre-trained)된 LLM에 특정 도메인의 데이터를 추가로 학습시켜 해당 도메인에 특화된 맞춤형 모델로 만드는 방식이다.\n",
    "- **장점**\n",
    "  - 특정 도메인에 최적화되어 높은 정확도와 성능을 낼 수 있다.\n",
    "- **단점**\n",
    "  - 모델 재학습에 많은 시간과 자원이 필요하다.\n",
    "  - 새로운 정보가 반영되지 않으며, 이를 위해서는 다시 학습해야 한다.\n",
    "\n",
    "### RAG\n",
    "\n",
    "- **정의**: 모델을 다시 학습시키지 않고, 외부 지식 기반에서 정보를 검색하여 실시간으로 답변에 활용하는 방식이다.\n",
    "- **장점**\n",
    "  - 최신 정보를 쉽게 반영할 수 있다.\n",
    "  - 모델을 수정하지 않아도 되므로 효율적이다.\n",
    "- **단점**\n",
    "  - 검색된 문서의 품질에 따라 답변의 정확성이 달라질 수 있다.\n",
    "  - 검색 시스템 구축이 필요하다.\n",
    "\n",
    "## 정리\n",
    "\n",
    "| 항목       | 파인튜닝 | RAG |\n",
    "| -------- | ---- | --- |\n",
    "| 도메인 최적화  | 가능   | 제한적 |\n",
    "| 최신 정보 반영 | 불가능  | 가능  |\n",
    "| 구현 난이도   | 높음   | 보통  |\n",
    "| 유연성      | 낮음   | 높음  |\n",
    "\n",
    "- LLM은 학습 당시의 데이터만을 기반으로 작동하므로 최신 정보나 기업 내부 자료와 같은 특정한 지식 기반에 접근할 수 없다.\n",
    "- 파인튜닝은 시간과 비용이 많이 들고 유지보수가 어렵다.\n",
    "-\t반면, RAG는 기존 LLM을 변경하지 않고도 외부 문서를 통해 그 한계를 보완할 수 있다.\n",
    "- RAG는 특히 빠르게 변화하는 정보를 다루는 분야(예: 기술 지원, 뉴스, 법률 등)에서 유용하게 활용된다. 반면, 정적인 정보에 대해 높은 정확도가 필요한 경우에는 파인튜닝이 효과적이다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9017ca94-32e0-4460-8937-90a8d92ca07b",
   "metadata": {},
   "source": [
    "## RAG 작동 단계\n",
    "- 크게 \"**정보 저장(인덱싱)**\", \"**검색**, **생성**\"의 단계로 나눌 수 있다.\n",
    "  \n",
    "### 1. 정보 저장(인덱싱)\n",
    "RAG는 사전에 정보를 가공하여 **벡터 데이터베이스**(Vector 저장소)에 저장해 두고, 나중에 검색할 수 있도록 준비한다. 이 단계는 다음과 같은 과정으로 이루어진다.\n",
    "\n",
    "1. **Load (불러오기)**\n",
    "   - 답변시 참조할 사전 정보를 가진 데이터들을 불러온다.\n",
    "2. **Split/Chunking (문서 분할)**\n",
    "   - 긴 텍스트를 일정한 길이의 작은 덩어리(*chunk*)로 나눈다.\n",
    "   - 이렇게 해야 검색과 생성의 정확도를 높일 수 있다.\n",
    "3. **Embedding (임베딩)**\n",
    "   - 각 텍스트 조각을 **임베딩 벡터**로 변환한다.\n",
    "   - 임베딩 벡터는 그 문서의 의미를 벡터화 한 것으로 질문과 유사한 문서를 찾을 때 인덱스로 사용된다.\n",
    "4. **Store (저장)**\n",
    "   - 임베딩된 벡터를 **벡터 데이터베이스**(벡터 저장소)에 저장한다.\n",
    "   - 벡터 데이터베이스는 유사한 질문이나 문장을 빠르게 찾을 수 있도록 특화된 데이터 저장소이다.\n",
    "   \n",
    "![rag](figures/rag1.png)\n",
    "\n",
    "### 2. 검색, 생성\n",
    "\n",
    "사용자가 질문을 하면 다음과 같은 절차로 답변이 생성된다.\n",
    "1. **Retrieve (검색)**\n",
    "   - 사용자의 질문을 임베딩한 후, 이 질문 벡터와 유사한 context 벡터를 벡터 데이터베이스에서 검색하여 찾는다.\n",
    "2. **Query (질의 생성)**\n",
    "   - 벡터 데이터베이스에서 검색된 문서 조각과 사용자의 질문을 함께 **프롬프트**(prompt)로 구성하여 LLM에 전달한다.\n",
    "3. **Generation (응답 생성)**\n",
    "   - LLM은 받은 프롬프트에 대한 응답을 생성한다.\n",
    "   \n",
    "- **RAG 흐름**\n",
    "  \n",
    "![Retrieve and Generation](figures/rag2.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e7e3d03-2250-4c79-aa83-7faf709ba4cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "21f6fd91-e3de-4f9d-9c8a-9c21de7a768c",
   "metadata": {},
   "source": [
    "# Document Loader\n",
    "- LLM에게 질의할 때 같이 제공할 Data들을 저장하기 위해 먼저 읽어들인다.(Load)\n",
    "- 데이터 Resouce는 다양하다.\n",
    "    - 데이터를 로드(load)하는 방식은 저장된 위치와 형식에 따라 다양하다. \n",
    "      - 로컬 컴퓨터(Local Computer)에 저장된 문서\n",
    "        - 예: CSV, Excel, JSON, TXT 파일 등\n",
    "      - 데이터베이스(Database)에 저장된 데이터셋\n",
    "      - 인터넷에 존재하는 데이터\n",
    "        - 예: 웹에 공개된 API, 웹 페이지에 있는 데이터, 클라우드 스토리지에 저장된 파일 등\n",
    "\n",
    "![rag_load](figures/rag_load.png)\n",
    "\n",
    "- 다양한 문서 형식(format)에 맞춰 읽어오는 다양한 **document loader** 들을 Langchain에서 지원한다.\n",
    "    - 다양한 Resource들로 부터 데이터를 읽기 위해서는 다양한 라이브러리를 이용해 서로 다른 방법으로 읽어야 한다.\n",
    "    - Langchain은 데이터를 읽는 다양한 방식의 코드를 하나의 interface로 사용 할 수 있도록 지원한다.\n",
    "        - https://python.langchain.com/docs/how_to/#document-loaders\n",
    "    - 다양한 3rd party library(ppt, github 등등 다양한 3rd party lib도 있음. )들과 연동해 다양한 Resource로 부터 데이터를 Loading 할 수 있다.\n",
    "        - https://python.langchain.com/docs/integrations/document_loaders/\n",
    "- **모든 document loader는 기본적으로 동일한 interface(사용법)로 호출할 수있다.**\n",
    "- **반환타입**\n",
    "    - **list[Document]**\n",
    "    - Load 한 문서는 Document객체에 정보들을 넣는다. 여러 문서를 읽을 수 있기 대문에 list에 묶어서 반환한다.\n",
    "        - **Document 속성**\n",
    "            - page_content: 문서의 내용\n",
    "            - metadata(option): 문서에 대한 메타데이터(정보)를 dict 형태로 저장한다. \n",
    "            - id(option): 문서의 고유 id\n",
    "     \n",
    "- **주의**\n",
    "    - Langchain을 이용해 RAG를 구현할 때 **꼭 Langchain의 DocumentLoader를 사용해야 하는 것은 아니다.**\n",
    "    - DocumentLoader는 데이터를 읽어오는 것을 도와주는 라이브러리일 뿐이다. 다른 라이브러리를 이용해서 읽어 들여도 상관없다. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36f25589-24a2-4f1f-9e8c-41e0594b6ce1",
   "metadata": {},
   "source": [
    "## 주요 Document Loader\n",
    "\n",
    "### Text file\n",
    "- TextLoader 이용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "40998e95-a607-45d5-a3f6-2bb598b1aa19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'> 1\n",
      "<class 'langchain_core.documents.base.Document'>\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import TextLoader\n",
    "\n",
    "path = \"data/olympic.txt\"\n",
    "\n",
    "# with open(path, 'rt') as f:\n",
    "#     doc = f.read()\n",
    "\n",
    "# 1. 객체 생성 -> 읽어올 자원의 정보(경로)를 제공.\n",
    "loader = TextLoader(path, encoding=\"utf-8\")\n",
    "\n",
    "# 2. 읽어 오기(Loading)\n",
    "docs = loader.load()  # lazy_load() -> 문서를 사용하는 시점에 읽어온다.\n",
    "\n",
    "print(type(docs), len(docs))\n",
    "print(type(docs[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0ec8523a-e87c-4214-aee9-c1aa8d1745c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "문서의 정보-metadata: {'source': 'data/olympic.txt'}\n",
      "문서식별자(ID): None\n",
      "문서내용:\n",
      "올림픽\n",
      "올림픽(영어: Olympic Games, 프랑스어: Jeux olympiques)은 전 세계 각 대륙 각국에서 모인 수천 명의 선수가 참가해 여름과 겨울에 스포츠 경기를 하\n"
     ]
    }
   ],
   "source": [
    "# Document 객체 속성\n",
    "doc = docs[0]\n",
    "print(\"문서의 정보-metadata:\", doc.metadata)\n",
    "print(\"문서식별자(ID):\", doc.id)\n",
    "print(\"문서내용:\")\n",
    "print(doc.page_content[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "591ae197",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(metadata={'category': '올림픽', 'path': 'data/olympic.txt'}, page_content='올림픽\\n올림픽(영어: Olympic Games, 프랑스어: Jeux olympiques)은 전 세계 각 대륙 각국에서 모인 수천 명의 선수가 참가해 여름과 겨울에 스포츠 경기를 하는 국제적인 대회이다. 전 세계에서 가장 큰 지구촌 최대의 스포츠 축제인 올림픽은 세계에서 가장 인지도있는 국제 행사이다. 올림픽은 2년마다 하계 올림픽과 동계 올림픽이 번갈아 열리며, 국제 올림픽 위원회(IOC)가 감독하고 있다. 또한 오늘날의 올림픽은 기원전 8세기부터 서기 5세기에 이르기까지 고대 그리스 올림피아에서 열렸던 올림피아 제전에서 비롯되었다. 그리고 19세기 말에 피에르 드 쿠베르탱 남작이 고대 올림피아 제전에서 영감을 얻어, 근대 올림픽을 부활시켰다. 이를 위해 쿠베르탱 남작은 1894년에 IOC를 창설했으며, 2년 뒤인 1896년에 그리스 아테네에서 제 1회 올림픽이 열렸다. 이때부터 IOC는 올림픽 운동의 감독 기구가 되었으며, 조직과 활동은 올림픽 헌장을 따른다. 오늘날 전 세계 대부분의 국가에서 올림픽 메달은 매우 큰 영예이며, 특히 올림픽 금메달리스트는 국가 영웅급의 대우를 받으며 스포츠 스타가 된다. 국가별로 올림픽 메달리스트들에게 지급하는 포상금도 크다. 대부분의 인기있는 종목들이나 일상에서 쉽게 접하고 즐길 수 있는 생활스포츠 종목들이 올림픽이라는 한 대회에서 동시에 열리고, 전 세계 대부분의 국가 출신의 선수들이 참여하는 만큼 전 세계 스포츠 팬들이 가장 많이 시청하는 이벤트이다. 2008 베이징 올림픽의 모든 종목 누적 시청자 수만 47억 명에 달하며, 이는 인류 역사상 가장 많은 수의 인구가 시청한 이벤트였다.\\n또한 20세기에 올림픽 운동이 발전함에 따라, IOC는 변화하는 세계의 사회 환경에 적응해야 했다. 이러한 변화의 예로는 얼음과 눈을 이용한 경기 종목을 다루는 동계 올림픽, 장애인이 참여하는 패럴림픽, 스페셜 올림픽, 데플림픽, 10대 선수들이 참여하는 유스 올림픽 등을 들 수 있다. 그 뿐만 아니라 IOC는 20세기의 변화하는 경제, 정치, 기술 환경에도 적응해야 했다. 그리하여 올림픽은 피에르 드 쿠베르탱이 기대했던 순수한 아마추어 정신에서 벗어나서, 프로 선수도 참가할 수 있게 되었다. 올림픽은 점차 대중 매체의 중요성이 커짐에 따라 올림픽의 상업화와 기업 후원을 놓고도 논란이 생겨났다. 또한 올림픽을 치르며 발생한 보이콧, 도핑, 심판 매수, 테러와 같은 수많은 일들은 올림픽이 더욱 굳건히 성장할 수 있는 원동력이 되었다.\\n올림픽은 국제경기연맹(IF), 국가 올림픽 위원회(NOC), 각 올림픽의 위원회(예-벤쿠버동계올림픽조직위원회)로 구성된다. 의사 결정 기구인 IOC는 올림픽 개최 도시를 선정하며, 각 올림픽 대회마다 열리는 올림픽 종목도 IOC에서 결정한다. 올림픽 경기 개최 도시는 경기 축하 의식이 올림픽 헌장에 부합하도록 조직하고 기금을 마련해야 한다. 올림픽 축하 행사로는 여러 의식과 상징을 들 수 있는데 올림픽기나 성화가 그 예이다.\\n올림픽은 거의 모든 국가가 참여할 정도로 규모가 커졌다. 하계 올림픽은 33개의 종목과 약 400개의 세부종목에서 13,000명이 넘는 선수들이 겨루고 그중 각 종목별 1, 2, 3위는 각각 금/은/동을 수여받는다. 전 세계 언론에서 각각 4년마다 열리는 올림픽 경기를 중계하기 때문에 이름 없는 선수가 개인적, 국가적, 세계적으로 명성을 얻을 수 있는 기회가 된다. 이와 더불어 올림픽 경기는 개최지와 개최국에게도 전 세계에 그 이름을 널리 알리는 좋은 기회가 된다.\\n\\n고대올림픽\\n고대의 올림픽 경기(올림피아 경기)는 고대 그리스의 여러 도시 국가의 대표선수들이 모여 벌인 일련의 시합이었으며, 육상 경기가 주 종목이지만 격투기와 전차 경기도 열렸다. 그리고 패배하면 죽기도 하였다. 고대 올림픽의 유래는 수수께끼로 남아있다. 잘 알려진 신화로는 헤라클레스와 그의 아버지인 제우스가 올림픽의 창시자였다는 것이다. 전설에 따르면 이 경기를 최초로 \\'올림픽\\'이라고 부르고, 4년마다 대회를 개최하는 관례를 만든 사람이 헤라클레스라고 한다. 어떤 전설에서는 헤라클레스가 이른바 헤라클레스의 12업을 달성한 뒤에 제우스를 기리고자 올림픽 경기장을 지었다고 한다. 경기장이 완성되자 헤라클레스는 일직선으로 200 걸음을 걸었으며, 이 거리를 \"스타디온\"이라 불렀는데, 후에 이것이 길이 단위인 \\'스타디온\\'(그리스어: στάδιον → 라틴어: 영어: stadium)이 되었다. 또 다른 설로는 \\'올림픽 휴전\\'(그리스어: ἐκεχειρία 에케케이리아[*])이라는 고대 그리스의 관념이 최초의 올림피아 경기와 관련이 있다고 한다. \\'올림픽 휴전\\'이란 어느 도시 국가라도 올림피아 경기 기간 중에 다른 나라를 침범하면 그에 대한 응징을 받을 수 있다는 뜻으로, \"올림픽 기간에는 전쟁하지 말 것\"으로 요약할 수 있다.\\n고대 올림피아 경기가 처음 열린 시점은 보통 기원전 776년으로 인정되고 있는데, 이 연대는 그리스 올림피아에서 발견된 비문에 근거를 둔 것이다. 이 비문의 내용은 달리기 경주 승자 목록이며 기원전 776년부터 4년 이후 올림피아 경기 마다의 기록이 남겨져 있다. 고대 올림픽의 종목으로는 육상, 5종 경기(원반던지기, 창던지기, 달리기, 레슬링, 멀리뛰기), 복싱, 레슬링, 승마 경기가 있었다. 전설에 따르면 엘리스의 코로이보스가 최초로 올림피아 경기에서 우승한 사람이라고 한다.\\n고대 올림피아 경기는 근본적으로 종교적인 중요성을 띄고 있었는데, 스포츠 경기를 할 때는 제우스(올림피아의 제우스 신전에는 페이디아스가 만든 제우스 상이 있음)와 펠롭스를 기리기 위하여 제물 봉헌 의식을 치렀다. 펠롭스는 올림피아의 전설상의 임금이었던 피사티스의 오이노마오스 왕과 전차 경주를 겨룬 영웅으로 유명한 인물이다. 올림피아 경기의 승자는 시와 조각상으로 칭송받았다. 올림피아 경기는 4년마다 열렸으며, 이 기간을 \\'올림피아드\\'(Olympiad)라고 했는데, 그리스인들은 이를 시간 단위로 이용하였다. 올림피아 경기는 고대 그리스에서 정기적으로 열렸던 범그리스 대회의 순환 대회 가운데 하나였다.\\n올림피아 경기는 기원전 6세기~기원전 5세기에 절정에 이르렀으나, 그 후 로마가 패권을 잡은 뒤 그리스에 영향력을 행사하면서 서서히 쇠퇴하게 된다. 고대 올림픽이 공식적으로 끝난 해는 확실히 알 수 없으나, 대부분 테오도시우스 1세 황제가 모든 이단 숭배 및 예배를 금지했던 393년을 고대 올림픽의 마지막이라고 추정한다. 다른 설에 따르면 테오도시우스의 후계자인 테오도시우스 2세가 모든 그리스 신전을 파괴하라고 명령한 426년이라고도 한다. 이렇게 올림픽이 사라진 이후로 이보다 한참 뒤인 19세기에 이르러서야 비로소 다시 올림픽 경기가 열리게 된다.\\n\\n\\n근대올림픽\\n고대 올림피아 경기를 제대로 구현한 최초의 시도는 혁명 시대의 프랑스에서 1796년부터 1798년까지 3년동안 실시했던 프랑스 국내 올림픽인 \\'공화국 올림픽\\'(L\\'Olympiade de la République)이었다. 이 대회의 종목 중에는 고대 그리스 올림피아 경기 때 행한 일부 종목도 있었다. 특히 1798년 공화국 올림픽 대회는 미터법을 최초로 스포츠에 도입시킨 대회이기도 하다. 이후 52년뒤인 1850년에는 잉글랜드 슈롭셔주의 웬록에서 올림픽급의 대회가 열리기 시작하였다. 이 대회는 1859년에 아테네에서 열렸을 때 웬록 올림픽으로 명칭이 변경되었으며 지금도 열리고 있다. 브룩스 박사는 1859년에 아테네에서 열린 올림픽 경기의 내용을 이후 경기에 채택하였다. 1866년 런던의 수정궁에서는 윌리엄 페니 브룩스가 영국의 국가 올림픽 대회를 만들었다.\\n1821년 그리스에서는 오스만 제국의 지배에 반기를 들고 독립 전쟁이 일어나면서, 이때부터 올림픽 부활에 대한 관심이 생겨났다. 시인이자 신문 편집자였던 파나요티스 수초스(Παναγιώτης Σούτσος)는 1833년에 출간한 자신의 시 \\'망자(亡者)의 대화\\'에서 최초로 올림픽 부활에 대한 제안을 내놓았다. 그리스의 부유한 박애주의자였던 에방겔리스 자파스(Ευαγγέλης Ζάππας)는 1859년에 아테네 시 광장에서 열린 \"올림픽 경기(일명 자파스 올림픽)\"를 후원하였다. 이 경기에는 그리스와 오스만 제국 출신의 선수들이 참가하였다. 에방겔리스 자파스는 이후에도 올림픽 경기를 개최할 수 있도록 고대의 경기장이었던 파나티네코 경기장을 복원하는 데도 돈을 썼다. 파나티네코 경기장에서 1870년과 1875년에 자파스 올림픽을 개최했으며, 현대 올림픽인 2004년 하계 올림픽 때는 양궁 경기장으로도 쓰였다.\\n역사학자였던 쿠베르탱은 프로이센-프랑스 전쟁(1870–1871)에서 프랑스의 패배 원인을 분석하면서 군사들이 체계적인 체력 훈련을 받지 않았기 때문에 전쟁에서 패배했다고 말한 인물이다. 1890년 웬록 올림픽에 참석한 쿠베르탱은 그 이후부터 올림픽을 대규모로 부활시킬 수 있으리라 생각했다. 쿠베르탱은 웬록 올림픽과 자파스 올림픽을 토대로 하여 올림픽 경기를 국제적으로 시행하기 위해 나라별로 올림픽을 번갈아가며 개최하는 방식을 생각해냈다. 그는 이 방안을 새로 설립된 국제 올림픽 위원회(IOC)의 첫 올림픽 의회 기간 중에 언급했다. 총회는 파리의 소르본 대학교에서 1894년 6월 16일부터 6월 23일까지 7일간 지속되었으며, 총회 마지막날, 2년 후인 1896년에 아테네에서 국제적 규모의 올림픽 대회를 열기로 결정되었다. IOC는 올림픽을 조직하는 데에 모든 책임을 졌으며, 초대 위원장으로는 그리스의 작가였던 디미트리오스 비켈라스(Δημήτριος Βικέλας)가 선출되었다.\\n\\n하계올림픽\\n1859년 자파스 올림픽에 참가한 선수의 수는 250명을 넘지 못했다. 에방겔리스 자파스는 \"지난 자파스 올림픽을 포함, 1896년에 개최될 2번째 올림픽을 위해 파나티네코 경기장을 보수해야 한다.\"라는 충고를 하지만, 그리스 정부는 그의 말을 듣지 않았고 결국 1896년 아테네 올림픽 준비를 위해 파나티네코 경기장은 두 번이나 정비해야 했다. 1회 대회 정식종목으로는 9종목이 있었는데 육상, 사이클, 펜싱, 체조, 사격, 수영, 테니스, 역도, 레슬링이 있었으며, 조정도 정식종목이었으나 매우 나쁜 날씨로 인해 조정 경기는 취소되었다. 펜싱 경기는 역사적 건물인 자피온(에반젤리스 자파스의 이름을 딴 것이다)에서 열렸다. 그리스의 관리들과 국민들은 올림픽 경기 개최에 열광적이었다. 많은 선수들이 이에 동감하면서 앞으로도 올림픽 대회를 아테네에서 영구히 개최해야 한다고 요구하기까지 하였다. 그러나 국제올림픽위원회(IOC)는 근대 올림픽은 순환 개최로 열리는 세계적인 행사가 되어야 한다고 생각했다. 결국 2회 올림픽은 프랑스 파리에서 열기로 결정되었다.\\n1896년 올림픽 대회의 성공을 이어서 개최된 두 번째 올림픽인 1900년 올림픽에서는 올림픽의 존폐여부를 위협받는 지경에 이르게 되었다. 1900년에 파리와 1904년에 세인트루이스에서 열린 올림픽은 하필이면 엑스포와 시간과 장소가 겹치는 바람에 빛을 바래게 된다. 1904년 대회를 예로 들면 650명의 선수단이 참가했지만 그중 580명은 미국국적을 가진 사람이었다. 1900년과 1904년의 두 올림픽 대회는 역대 올림픽중에 최저점을 기록한다. 올림픽은 1906년 올림픽이 아테네에서 개최되었을 때 다시 일어서게 된다. 또 다른 성공적인 올림픽은 그리스 올림픽 협회가 조직했으며 세 차례나 올림픽을 치른 경기장에서 개최되었다. 이 경기는 비공식 올림픽이긴 했지만 세계적으로 상당한 참가자들을 불러 모았으며 대중들에게 큰 재미를 갖다주었다. 이 때를 시작으로 올림픽의 인기와 번영이 시작되었다.\\n\\n동계올림픽\\n동계 올림픽은 눈과 얼음을 이용하는 스포츠들을 모아 이루어졌으며 하계 올림픽 때 실행하기 불가능한 종목들로 구성되어 있다. 피겨스케이팅, 아이스하키는 각각 1908년과 1920년에 하계올림픽 종목으로 들어가 있었다. IOC는 다른 동계 스포츠로 구성된 새로운 대회를 만들고 싶어 했고, 로잔에서 열린 1921년 올림픽 의회에서 겨울판 올림픽을 열기로 합의했다. 1회 동계올림픽은 1924년, 프랑스의 샤모니에서 11일간 진행되었고, 16개 종목의 경기가 치러졌다. IOC는 동계 올림픽이 4년 주기로 하계 올림픽과 같은 년도에 열리도록 했다. 이 전통은 프랑스의 알베르빌에서 열린 1992년 올림픽 때까지 지속되었으나, 노르웨이의 릴레함메르에서 열린 1994년 올림픽부터 동계 올림픽은 하계 올림픽이 끝난지 2년후에 개최하였다.\\n\\n패럴림픽\\n패럴림픽(Paralympic)은 신체·감각 장애가 있는운동 선수가 참가하는 국제 스포츠 대회로, 장애인 올림픽으로 불린다. 1948년에 루드비히 구트만 경(Sir Ludwig Guttman)은 제2차 세계대전에 참전한 군인들의 사회 복귀를 위한 일환으로 1948년 런던 올림픽과 동시에 몇몇 병원들을 연합해서 여러 경기를 펼쳤다. 구트만의 세계 휠체어, 신체부자유자대회(World Wheelchair and Amputee Games)로 알려진 이 대회는 매년 열리는 스포츠대회가 되었다. 12년이 넘도록 구트만과 다른 사람들은 스포츠를 상처를 치료하는 방법 중 하나로써 계속 대회 개최에 노력을 기울였다. 로마에서 열린 1960년 하계 올림픽때 구트만은 400명의 선수들을 \"Parallel Olympics\"에 참가시켰으며 이것이 곧 1회 패럴림픽으로 알려지게 되었다. 그 때부터 패럴림픽은 하계 올림픽이 열린 년도에 열리게 되었다. 서울에서 열린 1988년 하계 올림픽부터는 하계 올림픽을 개최한 도시는 패럴림픽도 같이 개최하기로 한다.\\n\\n오늘날의 올림픽\\n1896년 대회때는 14개국에서 241명의 선수단이 참가했지만 2008년 하계 올림픽때는 204개국에서 10,500명의 선수가 참가하는 등 세계적인 대회로 변모했다. 동계 올림픽의 규모는 하계 올림픽 규모보다 작다. 예를 들면 2006 토리노 동계 대회때는 80개국에서 2,508명의 선수가 참가했으며 82개 세부종목이 있었고, 2008 베이징 하계 대회때는 204개국, 11,508명의 선수, 302개의 세부종목이 있었다. 올림픽이 진행되는 동안 선수와 임직원들은 올림픽 선수촌에서 지낸다. 올림픽 선수촌에는 선수들을 위한 개인실이 있으며 카페테리아, 헬스 클리닉, 종교적인 시설 등 최상의 편의를 위한 시설들이 있다.\\n올림픽에 참가하는 나라는 UN에 등록된 국가의 수 193개보다 많다. 다른 국제조직이 개최하는 대회들은 정치적 주권국으로 참가를 제한하는 반면, IOC는 그에 상관없이 올림픽에 모든 공동체들이 참가할 수 있도록 한다. 이는 연합체나 공동체에서 국가올림픽위원회(NOC)를 만드는 것을 허용한다는 의미이다. 예를 들면 푸에르토리코, 버뮤다, 홍콩과 같은 곳도 올림픽에서 다른 나라와 스포츠 경쟁을 합법적으로 할 수 있다.\\n\\n국제 올림픽 위원회\\n올림픽 활동이란 많은 수의 국가, 국제 경기 연맹과 협회 • 미디어 파트너를 맺기 • 선수, 직원, 심판, 모든 사람과 기관이 올림픽 헌장을 지키는 것을 말한다. 국제올림픽위원회(IOC)는 모든 올림픽 활동을 통솔하는 단체로서, 올림픽 개최 도시 선정, 계획 감독, 종목 변경, 스폰서 및 방송권 계약 체결 등의 권리가 있다. 올림픽 활동은 크게 세 가지로 구성된다.\\n- 국제경기연맹(IF)은 국제적인 규모의 경기를 관리, 감독하는 기구이다. 예를 들어서 국제 축구 연맹(FIFA)는 축구를 주관하며, 국제 배구 연맹(FIVB)은 배구를 주관하는 기구이다. 올림픽에는 현재 35개의 국제경기연맹이 있고 각 종목을 대표한다. (이 중에는 올림픽 종목은 아니지만 IOC의 승인을 받은 연맹도 있다.)\\n- 국가 올림픽 위원회(NOC)는 각국의 올림픽 활동을 감독하는 기구이다. 예를 들어서 대한 올림픽 위원회(KOC)는 대한민국의 국가 올림픽 위원회이다. 현재 IOC에 소속된 국가 올림픽 위원회는 205개이다.\\n- 올림픽 조직 위원회(OCOG)는 임시적인 조직으로 올림픽의 총체적인 것(개막식, 페막식 등)을 책임지기 위해 구성된 조직이다. 올림픽 조직 위원회는 올림픽이 끝나면 해산되며 최종보고서를 IOC에 제출한다.\\n올림픽의 공식언어는 프랑스어와 영어와 개최국의 공용어이다. 모든 선언(예를 들어서 개막식 때 각국 소개를 할 때)들은 세 언어가 모두 나오거나 영어나 프랑스어 중에서 한 언어로만 말하기도 한다. 개최국의 공용어가 영어나 프랑스어가 아닐 때는 당연히 그 나라의 공용어도 함께 나온다.\\n\\n국제 올림픽 위원회(이하 IOC로 지칭)는 몇몇 위원들이 한 행위에 대해서 비판을 받고 있다. 그 예로 IOC 위원장이었던 에이버리 브런디지와 후안 안토니오 사마란치가 대표적인 사람이다. 브런디지는 20년 넘게 IOC 위원장직을 맡았고 임기 중에 올림픽을 정치적으로 휘말려들지 않게 하기 위해 보호했다. 그러나 그는 남아프리카 공화국 대표단에게 아파르트헤이트와 관련된 이슈를 건드리고 반유대정책을 함으로써 비난을 받았다. 사마란치 위원장 시기 때는 족벌 정치와 부패로 비난받았다. 사마란치가 스페인에서 프랑코 정권에 협력했다는 것도 비판의 이유가 되었다.\\n1998년에 몇몇 IOC위원들이 2002년 솔트레이크 시티 동계 올림픽 유치 과정에서 미국에게 미국을 올림픽 개최지로 뽑아달라는 뇌물청탁을 받았다는 것이 폭로되었다. 이에 IOC는 사퇴한 IOC위원 4명과 강제 퇴출된 6명에 대한 조사를 했다. 이 스캔들은 이후에 개최지 선정에서 이와 같은 불미스러운 일이 일어나지 않게 하기 위해서 IOC가 개혁에 착수하도록 하는 긍정적인 역할을 하기도 했다.\\nBBC 다큐멘터리인 \\'파노라마\\'에서는 \\'매수된 올림픽\\'이란 주제로 2004년 8월에 방송을 내보내기도 했다. 이때 이 프로그램에서는 2012년 하계 올림픽의 개최지 선정과 관련된 뇌물에 대해서 조사했다. 이 다큐멘터리에서는 특정 후보 도시가 IOC 위원들에게 뇌물수수하는 것이 가능했다고 주장했으며, 특히 파리 시장이었던 베르트랑 들라노에(Bertrand Delanoë)는 영국의 총리인 토니 블레어와 런던올림픽유치위원회가 입후보 규정을 위반했다고 비난했다. 그는 당시 프랑스 대통령이었던 자크 시라크를 목격자로 내세웠지만 시라크 대통령은 이 분쟁에 휘말려드는 것을 주의했으며 인터뷰를 삼갔다. 결국 베르트랑 들라노에의 주장에 대한 조사는 체계적으로 이루어지지는 않았다. 2006년 동계 올림픽을 유치했던 토리노도 이 논쟁에서 빠져나갈 수 없었다. 이번에는 스위스 국적의 IOC위원 마크 호들러(Marc Hodler)가 이 논쟁의 중심이 되었는데, 이 위원은 스위스 시온의 경쟁 도시였던 토리노가 IOC위원들에게 뇌물수수를 했다고 말했고, 이 발언으로 광범위한 조사가 이루어졌다. 이 언행이 많은 IOC위원들이 시온에 대해 언짢게 생각하게 되고 토리노가 개최지로 선정되도록 도와주는 역할을 했을 가능성도 제기되고 있다.\\n\\n올림픽 경기 종목\\n올림픽 경기 종목은 총 33개부문 52개 종목에서 약 400개의 경기로 이루어져있다. 예를 들어서 하계 올림픽 부문인 레슬링은 자유형과 그레코로만형의 두 종목으로 나뉜다. 여기에서 10경기는 남자부, 4경기는 여자부로 열리며 분류기준은 체중이다. 하계 올림픽은 26개, 동계 올림픽은 7개 부문으로 이루어져있다. 하계 올림픽에서는 육상, 수영, 펜싱, 체조가 1회 대회때부터 한번도 빠짐없이 정식종목이었으며, 동계 올림픽에서는 크로스컨트리, 피겨 스케이팅, 아이스 하키, 노르딕 복합, 스키 점프, 스피드 스케이팅이 1924년 동계 올림픽부터 빠짐없이 정식종목이었다. 배드민턴, 농구, 배구와 같은 정식종목들은 처음에는 시범종목이었으며 그 후에 정식종목으로 승인 되었다. 야구처럼 예전에는 정식종목 이었지만 지금은 정식 종목에서 빠진 종목도 있다.\\n\\n각 올림픽 종목들은 IOC로부터 승인을 받은 국제경기연맹의 관리를 받는다. 35개의 연맹이 IOC에서 승인을 받았으며, 승인을 받았지만 현재 정식종목이 아닌 종목을 감독하는 연맹도 있다. IOC의 승인을 받았지만 올림픽 종목이 아닌 스포츠들은 올림픽 종목으로 고려되지는 않으나, 올림픽이 끝난 후 처음으로 열리는 IOC총회 때마다 정식종목이 되도록 신청을 할 수는 있다. IOC 총회 때 정식종목 선정은 총회에 참석중인 IOC위원들의 투표를 통해 이루어지며, 재적 위원 수의 과반수 이상 찬성표를 얻어야 정식종목으로 인정을 받는다. IOC의 승인을 받은 스포츠이나 찬성표를 받지 못해 정식종목이 되지 못한 스포츠로는 체스와 서핑과 같은 것이 있다.\\n\\n2004년 10월과 11월에 IOC는 \\'올림픽 프로그램 위원회\\'(Olympic Programme Commission)를 설립했다. 여기서는 올림픽 종목과 올림픽 종목이 아닌 스포츠를 모두 재검토하는 일을 한다. 이 위원회의 목표는 올림픽 종목에 더 체계적으로 다가가는 것이다. 위원회에서는 우선적으로 올림픽 종목으로 포함되기 위해서는 7개의 기준을 충족시켜야 한다고 말한다. 이 7개의 기준은 역사, 전통, 보편성, 인기도와 잠재성, 선수의 건강, 연맹의 스포츠를 관리할만한 능력, 스포츠를 여는 데에 필요한 비용이다. 예를 들면 2012년 하계 올림픽의 정식종목 후보에 7개 조건을 포함한 비(非)올림픽 스포츠가 올랐고 그 내용은, 골프, 가라테, 럭비, 인라인 스케이팅, 스쿼시였다. 이 스포츠들은 IOC 상임이사회에서 재검토되어 2005년 7월에 열린 싱가포르 총회에서 최종 결정하기로 했다. 결국 5개 중 2개(가라테와 스쿼시) 가 최종 후보로 올라왔으나 가라테와 스쿼시 둘 다 2/3의 미만의 찬성표로 정식종목이 되지는 못한다. 그 후 2016년 올림픽 정식종목에는 7개의 스포츠가 정식종목 신청을 했는데, 내용은 가라테, 골프, 스쿼시, 야구, 소프트볼, 7인제 럭비, 인라인 스케이팅이었다. 2009년 8월 13일, 신청된 7개의 스포츠 중 단 2개만 최종후보로 선정되었는데, 이는 7인제 럭비와 골프였다. 같은해인 2009년 10월에 열린 IOC 총회에서 골프와 럭비는 과반수 이상의 득표를 얻어서 2016년 하계 올림픽과 2020년 하계 올림픽의 정식종목으로 채택되었다.\\n2002년에 열린 제114차 IOC 총회에서는 하계 올림픽 종목은 최대 28부문 301개 경기에 10,500명이 참가하는 것으로 제한하기로 결정했다.그 후 3년 뒤인 제117차 IOC 총회에서는 정식종목이었던 야구와 소프트볼을 정식 종목에서 제외시킨다. 이 결과에 대한 이견이 없었으므로 2012년 올림픽 때는 26개부문에서 경기가 열린다. 2016년과 2020년 올림픽 때는 럭비와 골프가 추가되어 다시 28개부문에서 경기가 열린다.\\n프로 NHL선수들은 1998년부터 아이스 하키종목에 출전할 수 있게 되었다. (나가노 올림픽 결승전 러시아 vs 체코).\\n영국 명문 공립 학교의 이념은 쿠베르탱에게 큰 영향을 끼쳤다. 영국 공립 학교는 스포츠를 교육의 중요한 부분이라 생각해서 \\'건전한 신체에 건전한 정신을\\'이라는 의미를 가진 라틴어 mens sana in corpore sano를 표어로 삼았다. 이 이념에 의하면 신사들은 특정한 분야에서만 우수해서는 안되고 모든 분야에서 고르게 잘해야 하고, 공정한 결과에는 승복해야 하며, 연습이나 훈련은 속이는 것과 마찬가지로 여겼다. 전문적으로 스포츠를 연습한 사람은 취미로 연습한 사람에 비해 공평하지 않다고 생각한 것이다.\\n\\n현대 올림픽에서는 프로 선수의 참가 불허가 많은 분쟁을 가져왔다. 1912년 하계 올림픽의 근대 5종 경기와 10종 경기에서 우승한 짐 소프는 올림픽에 나가기 전에 준프로야구선수로 활동했다는 게 나중에 밝혀져 메달이 박탈되었다. 소프는 후에 동정적 여론의 힘을 업고 1983년에 메달을 돌려받게 된다. 1936년 동계 올림픽 때 스위스와 오스트리아 스키선수들은 돈을 벌기 위해 스포츠를 했는데 이러한 행동이 아마추어 정신에 위배된다고 결정되어 그들은 스키종목에 참가할 수 없었다.\\n20세기에 이르러서 계급구조가 붕괴되면서 이른바 귀족적인 신사라는 아마추어 선수에 대한 정의는 시대에 뒤처지는 말이 되게 된다. 일부 국가들은 \\'정식 아마추어 선수\\'를 \\'키워서\\' 순수한 아마추어 정신을 벗어나고 있었고, 자신이 내는 비용으로 연습하는 선수들의 불리함에 대한 목소리가 나오기 시작했다. 하지만 IOC는 아마추어 정신에 관한 입장을 고수했다. 1970년대 초에는 아마추어 정신이 올림픽헌장에서 폐지되어야 한다는 말이 나오기 시작했다. 결국 프로선수들의 출전은 국제경기연맹(IF)에서 결정짓도록 되었다. 2008년 기준으로 아마추어 선수만 출전하고 있는 올림픽 종목은 복싱이 유일하며 남자 축구에서는 나이가 23세 이상인 선수를 3명까지만 선발할 수 있다. 이는 아마추어 정신을 지키기 위한 일환으로 볼 수 있다.\\n\\n논란\\n올림픽에서 첫 번째 보이콧은 1956년 하계 올림픽에서 시작되었다. 네덜란드, 스페인, 스위스는 소련의 헝가리 침공에 항의해 참가를 거부했다. 캄보디아, 이집트, 이라크, 레바논은 제2차 중동 전쟁 때문에 보이콧했다. 1972년과 1976년 올림픽에는 많은 아프리카의 국가들이 남아프리카 공화국과 로디지아에서 일어나는 인종 차별정권에 대한 항의의 표시로 올림픽 참가를 거부했다. 이 보이콧에는 뉴질랜드도 관계가 되어있는데, 뉴질랜드 럭비 국가 대표팀이 당시 아파르트헤이트정책을 쓰던 남아프리카 공화국과 경기를 했음에도 불구하고 뉴질랜드의 올림픽 참가가 허용되었기 때문이었다. 국제 올림픽 위원회는 이 두 보이콧에 대해 심각하게 고민했으나 후자의 뉴질랜드의 경우는 럭비가 올림픽 종목이 아니라는 이유를 내세워 뉴질랜드의 올림픽 참가 금지 요청을 거부했다. 당시 아프리카에 속해 있던 20개국과 가이아나, 이라크는 경기를 끝낸 선수들이 있었지만 탄자니아가 이끄는 올림픽 보이콧에 가세했다. 중화민국(타이완)도 1976년 몬트리올 올림픽 참가를 보이콧했는데, 그 이유는 중화인민공화국(중국)이 몬트리올 올림픽 조직위원회에게 타이완을 \\'중화민국\\'의 이름으로 참가하지 못하도록 압박을 가했기 때문이다. 타이완은 이것에 반발해서 중화민국의 국기와 중화민국의 국가를 계속 쓸 것이라고 밝혔다. 타이완은 1984년까지 올림픽에 참가하지 않았으며 그 후 참가할 때는 중화 타이베이 올림픽기와 특별한 찬가를 사용한다. 1980년과 1984년 올림픽 때는 냉전의 당사국들이 각각 반대진영에서 개최된 올림픽에 불참했다. 1980년에 열린 모스크바 올림픽 때는 소련의 아프가니스탄 침공에 대한 항의의 표시로 미국을 비롯한 65개국이 불참해서 1956년 이후 가장 적은 국가의 수인 81개국만 참가하는 대회가 되었다. 1984년에 열린 L.A 올림픽때는 루마니아와 유고슬라비아를 제외한 소련과 동구권의 14개 국가가 자국 선수들의 안전을 보장받지 못한다는 이유로 올림픽에 불참했다. 소련의 한 관계자는 그들이 올림픽 보이콧을 한 것에 대해 다음과 같은 발언을 통해 지지했다.\\n\"미국에서 광적인 애국심과 반소련 세력이 점점 늘어나고 있다.\"\\n동구권에서 보이콧을 한 국가들은 올림픽을 대신할 대회로 프렌드십 게임을 7월과 8월에 했다.\\n2008년에는 티베트와 다르푸르에 관한 중국의 인권문제를 두고 그에 대한 항의 표시로 중국산 물품의 불매운동과 2008 올림픽 불참에 대한 요구가 컸으나 보이콧을 한 나라는 없었다. 2008년 8월, 조지아 정부는 러시아가 2008년 남오세티야 전쟁에 참전한 것과 관련하여 러시아의 소치에서 열릴 2014년 동계 올림픽을 보이콧하자고 요청했다. 이에 대해 국제 올림픽 위원회는 \"앞으로 개최될 때까지 6년이나 남았는데 시작하기도 전에 섣불리 이른 판단을 하는 것은 옳지 않다.\"라고 말했다.\\n\\n쿠베르탱이 말했던 원래 이념과는 반대로 올림픽이 정치 혹은 체제 선전의 장으로 이용되는 경우가 있었다. 1936년 하계 올림픽을 개최할 때 당시의 나치독일은 나치는 자비롭고 평화를 위한다는 것을 설명하고 싶어했다. 또 이 올림픽에서 아리안족의 우월함을 보여줄 생각이었으나 이는 흑인이었던 제시 오언스가 금메달을 4개나 따내면서 실현되지는 못했다. 소련은 헬싱키에서 열린 1952년 하계 올림픽 때 처음으로 참가했다. 그 전에는 소련이 조직한 스파르타키아다라는 대회에 1928년부터 참가했었다. 다른 공산주의 국가들은 1920년대와 1930년대의 전쟁 기간 사이에 노동자 올림픽(Socialist Workers\\' Sport International)을 조직했는데, 이는 올림픽을 자본가와 귀족들의 대회로 여기고 그에 대한 대안으로 고안된 대회였다. 그 이후 소련은 1956년 하계 올림픽부터 1988년 하계 올림픽까지 엄청난 스포츠강국의 면모를 보여주며 올림픽에서의 명성을 드높였다.\\n선수 개인이 자신의 정치적 성향에 대해 표현하기도 했다. 멕시코 시티에서 열린 1968년 하계 올림픽의 육상부문 200m 경기에서 각각 1위와 3위를 한 미국의 토미 스미스와 존 카를로스는 시상식 때 블랙 파워 설루트(Black Power salute , 흑인 차별 반대 행위)를 선보였으며 2위를 한 피터 노먼도 상황을 깨닫고 스미스와 카를로스의 행위를 지지한다는 뜻에서 급하게 인권을 위한 올림픽 프로젝트(OPHR) 배지를 달았다. 이 사건에 대해서 IOC 위원장이었던 에이버리 브런디지는 미국 올림픽 위원회에 이 두 선수를 미국으로 돌려보내거나 미국 육상팀 전부를 돌려보내는 둘 중 하나의 선택을 하게 했고, 미국 올림픽 위원회는 두 선수를 미국으로 돌려 보낸다.\\n현재 이란 정부는 이스라엘과의 어떤 경기 경쟁이든 피하고 있다. 2008년 하계 올림픽 때 이란의 수영 선수는 이스라엘 수영 선수와 같이 경기한다는 이유로 경기를 포기했으며, 2004년 하계 올림픽에서도 이란의 유도 선수는 이스라엘 선수와 경기한다는 일정이 잡혔을 때 경기를 포기했다. 이 선수는 공식적으로는 시합전에 계체량을 재서 체중이 초과되어 실격 되었으나 이란정부로부터 125,000달러나 되는 돈을 받았다고 한다.\\n\\n20세기 초반, 많은 운동 선수들은 기록향상을 위해 약물을 복용하기 시작했다. 예를 들어 1904년 하계 올림픽 마라톤에서 우승한 미국 선수 토머스 J. 힉스는 코치에게서 스트리크닌과 브랜디를 받았다. 올림픽에서 약물을 과다 복용으로 사망한 사례도 한 번 있었다. 1960년 로마 대회 때 사이클 개인도로 경기 중에 덴마크 선수인 크누드 에네마르크 옌센이 자전거에서 떨어져서 사망했다. 검시관들의 조사에 의하면 그의 죽음의 원인은 암페타민 과다 복용이라고 했다. 이에 1960년대 중반부터 각 경기 연맹은 약물 복용을 금지하기 시작했으며 1967년에는 IOC도 약물 복용 금지에 동참했다.\\n올림픽에서 약물 복용 양성 반응이 나와서 메달을 박탈당한 첫 번째 사례로는 1968년 하계 올림픽의 근대 5종 경기에 출전해 동메달을 딴 한스 군나르 리렌바르가 있다. 그는 경기 후 도핑검사 결과 알코올을 복용한 것으로 확인되어 메달을 박탈당했다. 도핑 양성 반응으로 메달을 박탈당한 것으로 가장 유명한 사람은 1988년 하계 올림픽 육상 100m 경기에서 금메달을 땄으나 도핑 검사 결과 스타노졸롤을 복용한 것으로 확인돼 금메달을 박탈당한 캐나다 선수인 벤 존슨이 있다. 이에 따라 금메달은 2위를 했던 칼 루이스가 대신 받았다.\\n1990년대 후반, 여러 뜻있는 사람들이 도핑과의 전쟁을 선포하면서 1999년에 세계반도핑기구(WADA)를 설립한다. 2000년 하계 올림픽과 2002년 동계 올림픽 때는 약물 양성 반응을 보인 선수들이 급격히 증가했고, 역도와 크로스컨트리에서는 몇몇 선수들이 도핑 테스트에 걸려서 실격되기도 했다. 2006년 동계 올림픽 때는 메달리스트 한 명이 양성반응을 보여 메달을 반납해야 했다. IOC가 만든 약물 반응 판정(현재 올림픽 도핑테스트의 기준이 됨)은 인정을 받게 되었고 이제는 다른 경기 연맹에서도 벤치마킹을 할 정도가 되었다. 2008년 베이징 올림픽 기간중에는 3,667명의 선수들이 세계반도핑기구의 검사를 받았으며 소변과 혈액 검사로 약물 복용 검사를 했다. 몇몇 선수들은 국가 올림픽 위원회(NOC)에 의해 올림픽이 시작되기 전에 출전금지 조치를 당했고, 올림픽 기간중에는 단 3명만이 도핑 검사에 걸렸다.\\n쿠베르탱의 생각과는 달리, 올림픽이 세계에 완벽한 평화를 가져다주지는 못했다. 실제로 제1차 세계대전으로 인해 독일 베를린에서 열리기로 했던 제6회 1916년 하계 올림픽이 취소되었고, 제2차 세계대전 때는 일본 도쿄에서 열리기로 했던 제12회 1940년 하계 올림픽, 삿포로에서 열리기로 했던 1940년 동계 올림픽, 영국 런던에서 열리기로 했던 제13회 1944년 하계 올림픽, 이탈리아 코르티나담페초에서 열릴 예정인 1944년 동계 올림픽이 취소되었다. 베이징에서 열린 2008년 하계 올림픽 개막식날 조지아와 러시아 간의 2008년 남오세티아 전쟁이 일어나기도 했다. 부시 대통령과 푸틴 대통령이 이 올림픽을 보러 왔으며 중국 주석인 후진타오가 주최한 오찬에 참석해서 이 현안에 대해 논의하기도 했다. 조지아 대표인 니노 살루크바체와 러시아 대표인 나탈리야 파데리나가 여자 10m 공기권총 경기에서 각각 동메달과 은메달을 땄을 때 이 일은 베이징 올림픽의 유명한 사건 중 하나로 남게 되었다. 살루크바체와 파데리나는 시상식이 끝난 뒤 서로 포옹을 하며 국적에 상관없이 기쁨을 나누었다.\\n테러도 올림픽에서 공포의 대상이었다. 뮌헨 참사로 알려진 1972년에 서독 바이에른의 뮌헨에서 열린 하계 올림픽때의 사건은 테러리스트인 검은 9월단이 일으킨 사건으로서 이스라엘 선수 11명을 인질로 붙잡았다가 전원이 사망한 사건이다. 당시 미숙한 진압으로 인해 인질 9명(선수 1명과 코치 1명은 인질로 잡기 이전에 살해), 테러범 5명, 독일 경찰관 1명이 사망했으며 이 진압 작전 이전에는 인질들은 단 한 명도 죽지 않았다. 애틀란타에서 열린 1996년 하계 올림픽 때는 센테니얼 올림픽 공원(Centennial Olympic Park)에서 폭발 사건이 일어나 2명이 죽고 111명이 다치는 사건이 발생했다. 이 사건의 주모자 에릭 로버트 루돌프는 종신형을 선고받았다. 참고로 마라톤 역시 전쟁에서 유래한 것이다.\\n\\n개최지 선정\\n올림픽 개최지는 해당 올림픽 개최 7년 전에 IOC 위원들의 투표로 결정된다. 개최지 선정에는 약 2년이 걸린다. 유치를 희망하는 도시는 우선 자국의 올림픽 위원회에 신청을 해야 한다. 만약 한 국가에서 두 도시 이상이 유치를 희망한다면, 한 국가당 한 도시만 후보가 될 수 있다는 규칙에 따라 내부적으로 후보 도시를 결정해야 한다. 후보 도시가 결정되면 후보 도시가 소속된 국가의 올림픽 위원회는 IOC에 개최 신청을 하고, 신청 후에는 올림픽 개최에 대한 질의 응답서를 보내야 한다. 이 질의응답서에서 신청한 도시는 올림픽 헌장을 준수하며 IOC 상임이사회에 의한 다른 규정들을 지킬 것이라는 확신을 주어야 한다. 이 질의응답서는 전문가들이 검토하여 신청 도시들의 잠재성과 계획을 평가한다. 이 전문적인 평가를 바탕으로 IOC 상임이사회에서는 신청도시 중에서 후보도시를 고른다.\\n후보도시로 선택되면 그 도시들은 IOC에 보내는 후보도시에 관한 문서에 그들의 계획을 더욱 상세하고 방대한 양으로 적어서 보내야 한다. 평가조사단들이 이 후보도시들을 평가한다. 평가조사단은 후보도시들을 방문해서 지역 관계자들과 회견을 갖고 경기장 시설을 세심하게 조사한 뒤 개최지 투표를 하기 한달전에 조사를 바탕으로 한 공식 보고를 한다. 회견을 하는 동안에도 후보도시들은 자신들이 올림픽을 개최하는 데 충분한 자금이 조달될 수 있는지 등을 입증할 수 있어야 한다. 평가조사단의 업무가 끝나면 후보지의 국가 위원들은 IOC 정기총회에 참석한다. 이 총회에서 IOC 위원들은 올림픽 개최지를 선정하게 되며 후보지의 국가에 소속된 위원들은 자국의 후보지가 탈락하지 않는 이상 투표를 할 수 없다. 투표가 끝난후에 개최지로 선정된 곳의 유치위원회가 IOC와 개최도시 계약서에 서명을 하면 공식적으로 올림픽 개최도시(개최국)으로 인정된다.\\n2016년까지 올림픽은 23개국 44개 도시에서 열렸으며 유럽과 북아메리카대륙 이외의 대륙에서는 고작 8번 밖에 개최하지 못했다. 1988년 하계 올림픽이 대한민국의 서울에서 열린것을 시작으로 그 후 아시아와 오세아니아 대륙에서 올림픽이 4번이나 열렸으며, 이는 그 이전의 현대 올림픽사와 비교해보면 엄청나게 늘어난 수치였다. 2016년 하계 올림픽이 개최된 브라질의 리우데자네이루는 남미에서 열리는 첫 번째 올림픽이다. 아직 아프리카에서는 올림픽이 한 번도 개최되지 않았다. 2008년 하계 올림픽 때 가장 많은 선수가 참여한 나라는 중국으로 639명이 참가했으며 그 다음은 미국과 러시아로 각각 596명과 455명이 참가했다.\\n미국은 5번의 하계 올림픽과 4번의 동계 올림픽을 개최하면서 최다 올림픽을 개최한 나라이다. 영국은 2012년에 3번째 올림픽을 개최하였다. 독일, 오스트레일리아, 그리스는 하계 올림픽을 2번 개최한 국가이다. 동계 올림픽에서는 이탈리아가 2026년 밀라노-코르티나담페초 개최지로 선정되어 3번 개최될 예정이다. 또한 프랑스가 3번을 개최했으며 2024년 하계올림픽 개최예정으로 영국에 이번 두 번째로 한 도시에서 3번 올림픽 개최하며 하계올림픽3번 개최하였다. 프랑스는 동계, 하계 올림픽 각 3번씩 총 6번 개최로 9번으로 최다개최국인 미국 다음으로 두 번째로 많이 개최한 국가가 된다. 스위스, 오스트리아, 노르웨이, 일본, 이탈리아는 2번씩 개최했다. 일본은 하계,동계 각 2번씩 총 4번으로 미국, 프랑스 다음 세번째로 많이 개최한 국가이다. 2010년에 밴쿠버에서 열린 2010년 동계 올림픽은 캐나다에서 열리는 두 번째 동계 올림픽이고, 동/하계 올림픽을 합쳐 캐나다에서 3번째로 개최되는 올림픽이다.\\n\\n우승자와 메달리스트\\n개인 혹은 팀으로 경기에 출전해서 1위, 2위, 3위를 한 선수는 메달을 받는다. 1912년까지는 우승자에게 순금으로 된 금메달을 주었으며 그 후에는 도금된 금메달을 준다. 하지만, 2010 동계 올림픽에서는 전자제품 부속품을 녹여서 넣었다. 이러한 경우처럼 순금 외에 다른 물질을 넣을 경우에는 순금이 반드시 6g 이상을 함유하고 있어야 한다. 2위를 한 선수는 은메달을, 3위를 한 선수는 동메달을 받는다. 토너먼트로 진행되는 종목의 경우에는(복싱, 태권도 등) 3위를 구분하지 않고 준결승에서 패해서 3/4위전으로 간 선수들에게 모두 동메달을 수여한다. 1896년 하계 올림픽에서는 메달이 2개만 수여됐는데 1위에게 은메달을 주었고 2위에게 동메달을 주었다. 이때 3위에게는 아무것도 없었다. 현재의 메달 수여 방식은 1904년 하계 올림픽 때부터 시작되었다. 1948년부터는 4, 5, 6위를 한 선수에게는 인증서를 수여했다. 1984년 대회부터는 7, 8위를 한 선수에게도 인증서를 수여했다. 아테네에서 열린 2004년 하계 올림픽 때는 1, 2, 3위 선수에게 메달과 함께 올리브 화환도 같이 수여했다. 국가 올림픽 위원회(NOC)와 방송사에서는 자국의 메달 현황을 실시간으로 전달하기도 한다.')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.documents import Document\n",
    "\n",
    "with open(path, 'rt') as f:\n",
    "    load_doc = f.read()\n",
    "\n",
    "d = Document(page_content=load_doc, metadata={\"category\":\"올림픽\", \"path\":path})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2bbbd08-6afc-4f2f-985b-c96da7c3b943",
   "metadata": {},
   "source": [
    "### PDF\n",
    "- PyPDF, Pymupdf 등 다양한 PDF 문서를 읽어들이는 파이썬의  3rd party library들을 이용해 pdf 문서를 Load 한다.\n",
    "    - https://python.langchain.com/docs/integrations/document_loaders/#pdfs\n",
    "- 각 PDF Loader 특징\n",
    "    -  PyMuPDFLoader\n",
    "        -   텍스트 뿐 아니라 이미지, 주석등의 정보를 추출하는데 성능이 좋다.\n",
    "        -   PyMuPDF 라이브러리 기반\n",
    "    - PyPDFLoader\n",
    "        - 텍스트를 빠르게 추출 할 수있다.\n",
    "        - PyPDF2 라이브러리 기반. 경량 라이브러리로 빠르고 큰 파일도 효율적으로 처리한다.\n",
    "    - PDFPlumberLoader\n",
    "        - 표와 같은 복잡한 구조의 데이터 처리하는데 강력한 성능을 보여준다. 텍스트, 이미지, 표 등을 모두 추출할 수 있다. \n",
    "        - PDFPlumber 라이브러리 기반\n",
    "- 설치 패키지\n",
    "    - DocumentLoader와 연동하는 라이브러리들을 설치 해야 한다.\n",
    "    - `pip install pypdf -qU`\n",
    "    - `pip install pymupdf -qU`\n",
    "    - `pip install pdfplumber -qU`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6378f01b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "\n",
    "# 1. 객체 생성 -> raw 데이터 연결\n",
    "path = \"data/novel/금_따는_콩밭_김유정.pdf\"\n",
    "\n",
    "loader = PyPDFLoader(path)\n",
    "\n",
    "docs = loader.load()  # List[Document]\n",
    "len(docs)  # 페이지당 하나의 문서(Document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a9647515-7c2d-447d-a4e4-d70a18e4e025",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 \n",
      "위키백과\n",
      "위키백과에  이  글\n",
      "과  관련된 \n",
      "자료가  있습니다 .\n",
      "금  따는  콩밭\n",
      "🙝 🙟 \n",
      "땅속  저  밑은  늘  음침하\n",
      "다 .\n",
      "고달픈  간드렛불 , 맥없이\n",
      "푸르끼하다 .\n",
      "밤과  달라서  낮엔  되우  흐릿하였다 .\n",
      "겉으로  황토  장벽으로  앞뒤좌우가  콕  막힌  좁직한  구뎅이 .\n",
      "흡사히  무덤  속같이  귀중중하다 . 싸늘한  침묵 , 쿠더브레한\n",
      "흙내와  징그러운  냉기만이  그  속에  자욱하다 .\n",
      "곡괭이는  뻔질  흙을  이르집는다 . 암팡스러이  내려쪼며 ,\n",
      "퍽  퍽  퍼억 .\n",
      "이렇게  메떨어진  소리뿐 . 그러나  간간  우수수  하고  벽이  헐\n",
      "린다 .\n",
      "영식이는  일손을  놓고  소맷자락을  끌어당기어  얼굴의  땀을\n",
      "훑는다 . 이놈의  줄이  언제나  잡힐는지  기가  찼다 . 흙  한줌을\n",
      "집어  코밑에  바짝  들여대고  손가락으로  샅샅이  뒤져본다 . 완\n",
      "연히  버력은  좀  변한  듯싶다 . 그러나  불통버력이  아주  다  풀\n",
      "린  것도  아니었다 . 밀똥버력이라야  금이  온다는데  왜  이리\n",
      "안  나오는지 .\n",
      "곡괭이를  다시  집어든다 . 땅에  무릎을  꿇고  궁뎅이를  번쩍\n",
      "든  채  식식거린다 . 곡괭이는  무작정  내려찍는다 . 바닥에서\n"
     ]
    }
   ],
   "source": [
    "print(docs[1].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cdbd7f13-c4d5-4db7-b5d7-27de7984624f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'producer': 'Wikisource',\n",
       " 'creator': 'Wikisource',\n",
       " 'creationdate': '2024-11-24T07:05:35+00:00',\n",
       " 'author': 'Unknown',\n",
       " 'moddate': '2024-11-24T07:05:37+00:00',\n",
       " 'title': '금 따는 콩밭',\n",
       " 'source': 'data/novel/금_따는_콩밭_김유정.pdf',\n",
       " 'total_pages': 23,\n",
       " 'page': 1,\n",
       " 'page_label': '2'}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs[1].metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bed2776",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3db535f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_community.document_loaders import PyMuPDFLoader\n",
    "\n",
    "loader = PyMuPDFLoader(path)\n",
    "\n",
    "docs = loader.load()\n",
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "904bf667",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "위키백과\n",
      "위키백과에 이 글\n",
      "과 관련된\n",
      "자료가 있습니다.\n",
      "금 따는 콩밭\n",
      "🙝🙟\n",
      "땅속 저 밑은 늘 음침하\n",
      "다.\n",
      "고달픈 간드렛불, 맥없이\n",
      "푸르끼하다.\n",
      "밤과 달라서 낮엔 되우 흐릿하였다.\n",
      "겉으로 황토 장벽으로 앞뒤좌우가 콕 막힌 좁직한 구뎅이.\n",
      "흡사히 무덤 속같이 귀중중하다. 싸늘한 침묵, 쿠더브레한\n",
      "흙내와 징그러운 냉기만이 그 속에 자욱하다.\n",
      "곡괭이는 뻔질 흙을 이르집는다. 암팡스러이 내려쪼며,\n",
      "퍽 퍽 퍼억.\n",
      "이렇게 메떨어진 소리뿐. 그러나 간간 우수수 하고 벽이 헐\n",
      "린다.\n",
      "영식이는 일손을 놓고 소맷자락을 끌어당기어 얼굴의 땀을\n",
      "훑는다. 이놈의 줄이 언제나 잡힐는지 기가 찼다. 흙 한줌을\n",
      "집어 코밑에 바짝 들여대고 손가락으로 샅샅이 뒤져본다. 완\n",
      "연히 버력은 좀 변한 듯싶다. 그러나 불통버력이 아주 다 풀\n",
      "린 것도 아니었다. 밀똥버력이라야 금이 온다는데 왜 이리\n",
      "안 나오는지.\n",
      "곡괭이를 다시 집어든다. 땅에 무릎을 꿇고 궁뎅이를 번쩍\n",
      "든 채 식식거린다. 곡괭이는 무작정 내려찍는다. 바닥에서\n"
     ]
    }
   ],
   "source": [
    "print(docs[1].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0a9baec3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'producer': 'Wikisource',\n",
       " 'creator': 'Wikisource',\n",
       " 'creationdate': '2024-11-24T07:05:35+00:00',\n",
       " 'source': 'data/novel/금_따는_콩밭_김유정.pdf',\n",
       " 'file_path': 'data/novel/금_따는_콩밭_김유정.pdf',\n",
       " 'total_pages': 23,\n",
       " 'format': 'PDF 1.4',\n",
       " 'title': '금 따는 콩밭',\n",
       " 'author': 'Unknown',\n",
       " 'subject': '',\n",
       " 'keywords': '',\n",
       " 'moddate': '2024-11-24T07:05:37+00:00',\n",
       " 'trapped': '',\n",
       " 'modDate': \"D:20241124070537+00'00'\",\n",
       " 'creationDate': \"D:20241124070535+00'00'\",\n",
       " 'page': 0}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs[0].metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "196a703e-dd86-4cb5-82bf-8b6726aea0e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b507b334-e33b-435f-8a50-7dd31fa6da6b",
   "metadata": {},
   "source": [
    "### Web\n",
    "\n",
    "- WebBaseLoader 이용\n",
    "  - 입력받은 URL의 웹 문서를 읽어 문서로 로드한다. 웹 크롤링작업 없이 웹상의 문서를 가져올 수있다.\n",
    "  - 내부적으로 BeautifulSoup을 이용해 웹문서를 parsing한다.\n",
    "- https://python.langchain.com/docs/how_to/document_loader_web/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "94e5a711",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting bs4\n",
      "  Downloading bs4-0.0.2-py2.py3-none-any.whl.metadata (411 bytes)\n",
      "Collecting beautifulsoup4 (from bs4)\n",
      "  Using cached beautifulsoup4-4.13.4-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting soupsieve>1.2 (from beautifulsoup4->bs4)\n",
      "  Using cached soupsieve-2.7-py3-none-any.whl.metadata (4.6 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.0.0 in c:\\users\\tjddm\\miniconda3\\envs\\lang_env\\lib\\site-packages (from beautifulsoup4->bs4) (4.14.0)\n",
      "Downloading bs4-0.0.2-py2.py3-none-any.whl (1.2 kB)\n",
      "Using cached beautifulsoup4-4.13.4-py3-none-any.whl (187 kB)\n",
      "Using cached soupsieve-2.7-py3-none-any.whl (36 kB)\n",
      "Installing collected packages: soupsieve, beautifulsoup4, bs4\n",
      "\n",
      "   ------------- -------------------------- 1/3 [beautifulsoup4]\n",
      "   ------------- -------------------------- 1/3 [beautifulsoup4]\n",
      "   ---------------------------------------- 3/3 [bs4]\n",
      "\n",
      "Successfully installed beautifulsoup4-4.13.4 bs4-0.0.2 soupsieve-2.7\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install bs4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6a44adf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "\n",
    "url = [\n",
    "    \"https://m.sports.naver.com/wfootball/article/421/0008308548\",\n",
    "    \"https://m.sports.naver.com/wfootball/article/450/0000131435\"\n",
    "]\n",
    "\n",
    "my_user_agent = \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/137.0.0.0 Safari/537.36\"\n",
    "\n",
    "loader = WebBaseLoader(\n",
    "    web_path=url, # 개별 페이지 -> str, 여러페이지 -> list[str]\n",
    "    header_template={\n",
    "        \"user-agent\":my_user_agent\n",
    "    }\n",
    ")\n",
    "\n",
    "docs = loader.load()\n",
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b580ba5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'source': 'https://m.sports.naver.com/wfootball/article/421/0008308548',\n",
       " 'title': '[단독]쿠팡플레이, 스포츠패스 첫 가격 월 1만원…15일부터 시행',\n",
       " 'language': 'ko'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs[0].metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "da98b0ba-97ac-445d-85c8-1e000299f926",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[단독]쿠팡플레이, 스포츠패스 첫 가격 월 1만원…15일부터 시행NAVER스포츠메뉴홈야구해외야구축구해외축구농구배구N골프일반e스포츠아웃도어NEW뉴스영상일정순위포토홈 바로가기NAVER스포츠마이팀팀 추가응원하는 팀을 구독해보세요!스포츠야구해외야구축구해외축구농구배구N골프일반e스포츠아웃도어콘텐츠오늘의 경기승부예측연재이슈톡대학스포츠랭킹기타고객센터공식 블로그메뉴 닫기본문 바로가기[단독]쿠팡플레이, 스포츠패스 첫 가격 월 1만원…15일부터 시행입력2025.06.12. 오후 2:00수정2025.06.12. 오후 3:39기사원문김정현 기자양새롬 기자공감좋아요0슬퍼요0화나요0팬이에요0후속기사 원해요0텍스트 음성 변환 서비스본문 듣기를 종료하였습니다.글자 크기 변경공유하기쿠팡 와우 회원, 월 총 요금  '1만 7890원'(쿠팡플레이 갈무리)/뉴스1(서울=뉴스1) 김정현 양새롬 기자 = 쿠팡플레이가 부가서비스인 '스포츠 패스'의 금액을 월 1만 원으로 확정했다.12일 업계에 따르면 쿠팡플레이는 오는 15일 해외 스포츠 등의 콘텐츠를 유료 부가 서비스로 제공하는 스포츠 패스의 요금을 월 1만 원으로 결정했다. 공식 가격은 1만 2000원이나, 출시 할인가로 추정된다.쿠팡 와우 멤버십 구독료인 월 7890원에 스포츠패스 금액을 더하면 월 이용금액은 1만 7890원이 된다. 할인가가 종료될 경우 월 구독료만 2만 원 수준이다.이번 패스를 통해 볼수 있는 스포츠 리그는 △FIFA대회(FIFA클럽월드컵)△유럽축구리그(프리미어리그 2025~2026 시즌, 라리가, 분데스리가, 분데스리가2, 리그1, EFL 챔피언십 EFL리그원, 에레디비시) △유럽축구 토너먼트(FA컵, 카라바오컵, 커뮤니티쉴드, 코파 델레이, 수페르코파데 에스파냐, DFB-포칼, DFL-슈퍼컵, 쿠프드프랑스, 트로페데 샹피옹, 버투트로피) △아시아축구(AFC아시안컵, AFC챔피언스리그 엘리트, AFC챔피언스리그2, 기타AFC주관 국제 대회) △세계축구(월드컵남미 예선, 클럽 친선경기, 해외 국가 친선경기) 등이다.축구 외에도 △레이싱(F1, F1 아카데미, 나스카) △골프(LIV 골프) △농구(남자 농구 아시아컵, 여자 농구 아시아컵) △미식 축구(NFL) 등도 스포츠 패스를 별도 구독해야 시청 가능하다. 올 가을부터는 NBA 경기도 독점 제공할 예정이다.쿠팡플레이는 대한민국 축구 대표팀, 한국 프로 축구, 이벤트 매치(쿠팡플레이 시리즈)는 별도 패스 가입 없이 와우 회원들이 시청할 수 있도록 할 예정이다. (쿠팡플레이 홈페이지 갈무리) /뉴스1이같은 정보는 쿠팡플레이 공식 홈페이지를 통해 '스포츠 패스' 페이지가 노출되며 알려졌다.2만 원에 육박하는 가격 정보가 알려지자 국내 스포츠 커뮤니티에서는 \"축구만 보는데 관심없는 중계도 묶어서 비싸게 판매하는 대신 선택 폭을 늘렸으면 한다\", \"돈 받는 건 좋은데 화질 개선에 대한 이야기는 없나\" 등의 반응을 보이고 있다.쿠팡플레이 관계자는 \"해당 가격 정보는 사실과 다르며, 스포츠 패스의 공식 가격 및 세부 내용은 추후 쿠팡플레이를 통해 정확히 안내드릴 예정\"이라고 말했다.한편 쿠팡플레이는 선택형 부가서비스 '패스(PASS)'를 6월 중 도입한다고 밝힌 바 있다.김정현 기자구독구독자 0응원수 0해킹 숨겼던 예스24, 거짓말하다 또 적발…KISA \"협조 없어\"삼성 갤럭시Z폴드7 '3차 티저' 공개…카메라 업그레이드 암시양새롬 기자구독구독자 0응원수 0SKT, 유심 교체예약 완료까지 열흘 남았는데…52만 명 이탈SKT 유심교체 700만 명 완료…잔여예약자 264만 명Copyright ⓒ 뉴스1. All rights reserved. 무단 전재 및 재배포,  AI학습 이용 금지.기사 섹션 분류 가이드기사 섹션 분류 안내스포츠 기사 섹션(종목) 정보는 언론사 분류와 기술 기반의 자동 분류 시스템을 따르고 있습니다. 오분류에 대한 건은 네이버스포츠로 제보 부탁드립니다.오분류 제보하기닫기K팝·K트롯 팬들의 놀이터, 스타1픽세상에 이런 일이...[사건의 재구성]주요뉴스해당 언론사에서 선정하며 언론사 페이지(아웃링크)로 이동해 볼 수 있습니다.상간녀의 '역공'…\"남편 바람나면 이유 있는 것\"\"고엽제로 거동도 불편한데\"…참전 용사 폭행 충격\"'니네 집 몇 평이야?' 작으면 무시…애들이 이사 가자 하네요\"\"KTX 양말 벗고 냄새 맡고 퍼덕\"…옆자리 승객 결국은지원, '9세 연하' 본인 스타일리스트와 재혼…가족들만 초대 '스몰 웨딩'좋아요0슬퍼요0화나요0팬이에요0후속기사 원해요0기사 공유하기\n"
     ]
    }
   ],
   "source": [
    "print(docs[0].page_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb94a006",
   "metadata": {},
   "source": [
    "- 페이지의 일부분만 가져오기.\n",
    "- BeautifulSoup의 SoupStrainer 를 이용.\n",
    "    - BeautifulSoup(\"html문서\", parse_only=Strainer객체)\n",
    "        - Strainer객체에 지정된 영역에서만 내용 찾는다.\n",
    "    - Strainer(\"태그명\") -> 지정한 태그 내에서만 찾는다.\n",
    "    - Strainer(name=\"태그명\", attrs={속성명:속성값}) -> 지정한 태그 중 속성명=속성값인 것 내에서만 찾는다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be21355c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import bs4\n",
    "\n",
    "loader = WebBaseLoader(\n",
    "    web_path=url,\n",
    "    # WebBaseLoader가 bs4를 사용. bs4에 전달할 파라미터를 설정하는 변수\n",
    "    bs_kwargs={\n",
    "        \"parse_only\":bs4.SoupStrainer(attrs={\"class\":\"_article_content\"})\n",
    "    }\n",
    ")\n",
    "\n",
    "docs = loader.load()\n",
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "facaa491",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "쿠팡 와우 회원, 월 총 요금  '1만 7890원'(쿠팡플레이 갈무리)/뉴스1(서울=뉴스1) 김정현 양새롬 기자 = 쿠팡플레이가 부가서비스인 '스포츠 패스'의 금액을 월 1만 원으로 확정했다.12일 업계에 따르면 쿠팡플레이는 오는 15일 해외 스포츠 등의 콘텐츠를 유료 부가 서비스로 제공하는 스포츠 패스의 요금을 월 1만 원으로 결정했다. 쿠팡 와우 멤버십 구독료인 월 7890원에 스포츠패스 금액을 더하면 월 이용금액은 1만 7890원이 된다.이번 패스를 통해 볼수 있는 스포츠 리그는 △FIFA대회(FIFA클럽월드컵)△유럽축구리그(프리미어리그 2025~2026 시즌, 라리가, 분데스리가, 분데스리가2, 리그1, EFL 챔피언십 EFL리그원, 에레디비시) △유럽축구 토너먼트(FA컵, 카라바오컵, 커뮤니티쉴드, 코파 델레이, 수페르코파데 에스파냐, DFB-포칼, DFL-슈퍼컵, 쿠프드프랑스, 트로페데 샹피옹, 버투트로피) △아시아축구(AFC아시안컵, AFC챔피언스리그 엘리트, AFC챔피언스리그2, 기타AFC주관 국제 대회) △세계축구(월드컵남미 예선, 클럽 친선경기, 해외 국가 친선경기) 등이다.앞서 쿠팡플레이는 선택형 부가서비스 '패스(PASS)'를 6월 중 도입한다고 밝힌 바 있다.\n"
     ]
    }
   ],
   "source": [
    "print(docs[0].page_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd26b68d",
   "metadata": {},
   "source": [
    "### ArxivLoader\n",
    "- https://github.com/lukasschwab/arxiv.py\n",
    "- [arXiv-아카이브](https://arxiv.org/) 는 미국 코렐대학에서 운영하는 **무료 논문 저장소**로, 물리학, 수학, 컴퓨터 과학, 생물학, 금융, 경제 등 **과학, 금융 분야의 논문**들을 공유한다.\n",
    "- `ArxivLoader` 를 사용해 원하는 주제의 논문들을 arXiv에서 가져와 load할 수 있다.\n",
    "- **arXiv API**를 사용해 논문을 가져올 수 있다.\n",
    "  - https://python.langchain.com/api_reference/community/document_loaders/langchain_community.document_loaders.arxiv.ArxivLoader.html\n",
    "- 설치\n",
    "  - `pip install langchain-community -qU`\n",
    "  - `pip install arxiv -qU`\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f45cfa67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'itertools.islice'>\n"
     ]
    }
   ],
   "source": [
    "import arxiv \n",
    "\n",
    "# 검색 기준 설정.\n",
    "search = arxiv.Search(\n",
    "    query=\"RAG\", # 검색어\n",
    "    max_results=2, # 검색 결과 최대 개수.\n",
    "    sort_by=arxiv.SortCriterion.Relevance\n",
    ")\n",
    "# 정렬기준 - Relevance: 검색어 관련성이 높은 순서\n",
    "#          - LastUpdatedDate: 논문이 마지막으로 수정된 날짜 기준.\n",
    "#          - SubmittedDate: 처음 제출된 날짜 기준.\n",
    "\n",
    "# 검색\n",
    "client = arxiv.Client()\n",
    "result = client.results(search)\n",
    "print(type(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6072b39b",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc1 = next(result)  # 첫번째 문서 for page in result:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a491e5c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "논문제목: Modular RAG: Transforming RAG Systems into LEGO-like Reconfigurable Frameworks\n",
      "저자: [arxiv.Result.Author('Yunfan Gao'), arxiv.Result.Author('Yun Xiong'), arxiv.Result.Author('Meng Wang'), arxiv.Result.Author('Haofen Wang')]\n",
      "논문 PDF URL: http://arxiv.org/pdf/2407.21059v1\n"
     ]
    }
   ],
   "source": [
    "print(\"논문제목:\", doc1.title)\n",
    "print(\"저자:\", doc1.authors)\n",
    "# print(\"요약: \", doc1.summary)\n",
    "print(\"논문 PDF URL:\", doc1.pdf_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "297d24d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 다운로드\n",
    "import os\n",
    "os.makedirs(\"papers\", exist_ok=True)\n",
    "\n",
    "client = arxiv.Client()\n",
    "result = client.results(search)\n",
    "\n",
    "for idx, paper in enumerate(result, start=10):\n",
    "    paper.download_pdf(\"papers\", f\"{idx}.pdf\")\n",
    "# doc1.download_pdf(다운받을 디렉토리, 파일명명)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f2f14dfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pymupdf\n",
      "  Downloading pymupdf-1.26.1-cp39-abi3-win_amd64.whl.metadata (3.4 kB)\n",
      "Downloading pymupdf-1.26.1-cp39-abi3-win_amd64.whl (18.5 MB)\n",
      "   ---------------------------------------- 0.0/18.5 MB ? eta -:--:--\n",
      "   -- ------------------------------------- 1.3/18.5 MB 7.4 MB/s eta 0:00:03\n",
      "   ----------- ---------------------------- 5.5/18.5 MB 15.2 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 13.4/18.5 MB 23.3 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 15.5/18.5 MB 19.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 18.5/18.5 MB 19.8 MB/s eta 0:00:00\n",
      "Installing collected packages: pymupdf\n",
      "Successfully installed pymupdf-1.26.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install pymupdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5acac658",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_community.document_loaders import ArxivLoader\n",
    "\n",
    "loader = ArxivLoader(\n",
    "    query=\"Advanced RAG\", \n",
    "    top_k_results=1, # 몇개 검색할지 지정.\n",
    ")\n",
    "\n",
    "docs = loader.load()\n",
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e761a39f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Published': '2024-07-26',\n",
       " 'Title': 'Modular RAG: Transforming RAG Systems into LEGO-like Reconfigurable Frameworks',\n",
       " 'Authors': 'Yunfan Gao, Yun Xiong, Meng Wang, Haofen Wang',\n",
       " 'Summary': 'Retrieval-augmented Generation (RAG) has markedly enhanced the capabilities\\nof Large Language Models (LLMs) in tackling knowledge-intensive tasks. The\\nincreasing demands of application scenarios have driven the evolution of RAG,\\nleading to the integration of advanced retrievers, LLMs and other complementary\\ntechnologies, which in turn has amplified the intricacy of RAG systems.\\nHowever, the rapid advancements are outpacing the foundational RAG paradigm,\\nwith many methods struggling to be unified under the process of\\n\"retrieve-then-generate\". In this context, this paper examines the limitations\\nof the existing RAG paradigm and introduces the modular RAG framework. By\\ndecomposing complex RAG systems into independent modules and specialized\\noperators, it facilitates a highly reconfigurable framework. Modular RAG\\ntranscends the traditional linear architecture, embracing a more advanced\\ndesign that integrates routing, scheduling, and fusion mechanisms. Drawing on\\nextensive research, this paper further identifies prevalent RAG\\npatterns-linear, conditional, branching, and looping-and offers a comprehensive\\nanalysis of their respective implementation nuances. Modular RAG presents\\ninnovative opportunities for the conceptualization and deployment of RAG\\nsystems. Finally, the paper explores the potential emergence of new operators\\nand paradigms, establishing a solid theoretical foundation and a practical\\nroadmap for the continued evolution and practical deployment of RAG\\ntechnologies.'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs[0].metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b2111ade",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "Modular RAG: Transforming RAG Systems into\n",
      "LEGO-like Reconfigurable Frameworks\n",
      "Yunfan Gao, Yun Xiong, Meng Wang, Haofen Wang\n",
      "Abstract—Retrieval-augmented\n",
      "Generation\n",
      "(RAG)\n",
      "has\n",
      "markedly enhanced the capabilities of Large Language Models\n",
      "(LLMs) in tackling knowledge-intensive tasks. The increasing\n",
      "demands of application scenarios have driven the evolution\n",
      "of RAG, leading to the integration of advanced retrievers,\n",
      "LLMs and other complementary technologies, which in turn\n",
      "has amplified the intricacy of RAG systems. However, the rapid\n",
      "advancements are outpacing the foundational RAG paradigm,\n",
      "with many methods struggling to be unified under the process\n",
      "of “retrieve-then-generate”. In this context, this paper examines\n",
      "the limitations of the existing RAG paradigm and introduces\n",
      "the modular RAG framework. By decomposing complex RAG\n",
      "systems into independent modules and specialized operators, it\n",
      "facilitates a highly reconfigurable framework. Modular RAG\n",
      "transcends the traditional linear architecture, embracing a\n",
      "more advanced design that integrates routing, scheduling, and\n",
      "fusion mechanisms. Drawing on extensive research, this paper\n",
      "further identifies prevalent RAG patterns—linear, conditional,\n",
      "branching, and looping—and offers a comprehensive analysis\n",
      "of their respective implementation nuances. Modular RAG\n",
      "presents\n",
      "innovative\n",
      "opportunities\n",
      "for\n",
      "the\n",
      "conceptualization\n",
      "and deployment of RAG systems. Finally, the paper explores\n",
      "the potential emergence of new operators and paradigms,\n",
      "establishing a solid theoretical foundation and a practical\n",
      "roadmap for the continued evolution and practical deployment\n",
      "of RAG technologies.\n",
      "Index Terms—Retrieval-augmented generation, large language\n",
      "model, modular system, information retrieval\n",
      "I. INTRODUCTION\n",
      "L\n",
      "ARGE Language Models (LLMs) have demonstrated\n",
      "remarkable capabilities, yet they still face numerous\n",
      "challenges, such as hallucination and the lag in information up-\n",
      "dates [1]. Retrieval-augmented Generation (RAG), by access-\n",
      "ing external knowledge bases, provides LLMs with important\n",
      "contextual information, significantly enhancing their perfor-\n",
      "mance on knowledge-intensive tasks [2]. Currently, RAG, as\n",
      "an enhancement method, has been widely applied in various\n",
      "practical application scenarios, including knowledge question\n",
      "answering, recommendation systems, customer service, and\n",
      "personal assistants. [3]–[6]\n",
      "During the nascent stages of RAG , its core framework is\n",
      "constituted by indexing, retrieval, and generation, a paradigm\n",
      "referred to as Naive RAG [7]. However, as the complexity\n",
      "of tasks and the demands of applications have escalated, the\n",
      "Yunfan Gao is with Shanghai Research Institute for Intelligent Autonomous\n",
      "Systems, Tongji University, Shanghai, 201210, China.\n",
      "Yun Xiong is with Shanghai Key Laboratory of Data Science, School of\n",
      "Computer Science, Fudan University, Shanghai, 200438, China.\n",
      "Meng Wang and Haofen Wang are with College of Design and Innovation,\n",
      "Tongji University, Shanghai, 20092, China. (Corresponding author: Haofen\n",
      "Wang. E-mail: carter.whfcarter@gmail.com)\n",
      "limitations of Naive RAG have become increasingly apparent.\n",
      "As depicted in Figure 1, it predominantly hinges on the\n",
      "straightforward similarity of chunks, result in poor perfor-\n",
      "mance when confronted with complex queries and chunks with\n",
      "substantial variability. The primary challenges of Naive RAG\n",
      "include: 1) Shallow Understanding of Queries. The semantic\n",
      "similarity between a query and document chunk is not always\n",
      "highly consistent. Relying solely on similarity calculations\n",
      "for retrieval lacks an in-depth exploration of the relationship\n",
      "between the query and the document [8]. 2) Retrieval Re-\n",
      "dundancy and Noise. Feeding all retrieved chunks directly\n",
      "into LLMs is not always beneficial. Research indicates that\n",
      "an excess of redundant and noisy information may interfere\n",
      "with the LLM’s identification of key information, thereby\n",
      "increasing the risk of generating erroneous and hallucinated\n",
      "responses. [9]\n",
      "To overcome the aforementioned limitations, Advanced\n",
      "RAG paradigm focuses on optimizing the retrieval phase,\n",
      "aiming to enhance retrieval efficiency and strengthen the\n",
      "utilization of retrieved chunks. As shown in Figure 1 ,typical\n",
      "strategies involve pre-retrieval processing and post-retrieval\n",
      "processing. For instance, query rewriting is used to make\n",
      "the queries more clear and specific, thereby increasing the\n",
      "accuracy of retrieval [10], and the reranking of retrieval results\n",
      "is employed to enhance the LLM’s ability to identify and\n",
      "utilize key information [11].\n",
      "Despite the improvements in the practicality of Advanced\n",
      "RAG, there remains a gap between its capabilities and real-\n",
      "world application requirements. On one hand, as RAG tech-\n",
      "nology advances, user expectations rise, demands continue to\n",
      "evolve, and application settings become more complex. For\n",
      "instance, the integration of heterogeneous data and the new\n",
      "demands for system transparency, control, and maintainability.\n",
      "On the other hand, the growth in application demands has\n",
      "further propelled the evolution of RAG technology.\n",
      "As shown in Figure 2, to achieve more accurate and efficient\n",
      "task execution, modern RAG systems are progressively inte-\n",
      "grating more sophisticated function, such as organizing more\n",
      "refined index base in the form of knowledge graphs, integrat-\n",
      "ing structured data through query construction methods, and\n",
      "employing fine-tuning techniques to enable encoders to better\n",
      "adapt to domain-specific documents.\n",
      "In terms of process design, the current RAG system has\n",
      "surpassed the traditional linear retrieval-generation paradigm.\n",
      "Researchers use iterative retrieval [12] to obtain richer con-\n",
      "text, recursive retrieval [13] to handle complex queries, and\n",
      "adaptive retrieval [14] to provide overall autonomy and flex-\n",
      "ibility. This flexibility in the process significantly enhances\n",
      "arXiv:2407.21059v1  [cs.CL]  26 Jul 2024\n",
      "2\n",
      "Fig. 1. Cases of Naive RAG and Advanced RAG.When faced with complex\n",
      "questions, both encounter limitations and struggle to provide satisfactory\n",
      "answers. Despite the fact that Advanced RAG improves retrieval accuracy\n",
      "through hierarchical indexing, pre-retrieval, and post-retrieval processes, these\n",
      "relevant documents have not been used correctly.\n",
      "the expressive power and adaptability of RAG systems, en-\n",
      "abling them to better adapt to various application scenarios.\n",
      "However, this also makes the orchestration and scheduling of\n",
      "workflows more complex, posing greater challenges to system\n",
      "design. Specifically, RAG currently faces the following new\n",
      "challenges:\n",
      "Complex data sources integration. RAG are no longer\n",
      "confined to a single type of unstructured text data source but\n",
      "have expanded to include various data types, such as semi-\n",
      "structured data like tables and structured data like knowledge\n",
      "graphs [15]. Access to heterogeneous data from multiple\n",
      "sources can provide the system with a richer knowledge\n",
      "background, and more reliable knowledge verification capa-\n",
      "bilities [16].\n",
      "New demands for system interpretability, controllability,\n",
      "Fig. 2.\n",
      "Case of current Modular RAG.The system integrates diverse data\n",
      "and more functional components. The process is no longer confined to linear\n",
      "but is controlled by multiple control components for retrieval and generation,\n",
      "making the entire system more flexible and complex.\n",
      "3\n",
      "and maintainability. With the increasing complexity of sys-\n",
      "tems, system maintenance and debugging have become more\n",
      "challenging. Additionally, when issues arise, it is essential to\n",
      "quickly pinpoint the specific components that require opti-\n",
      "mization.\n",
      "Component selection and optimization. More neural net-\n",
      "works are involved in the RAG system, necessitating the\n",
      "selection of appropriate components to meet the needs of spe-\n",
      "cific tasks and resource configurations. Moreover, additional\n",
      "components enhance the effectiveness of RAG but also bring\n",
      "new collaborative work requirements [17]. Ensuring that these\n",
      "models perform as intended and work efficiently together to\n",
      "enhance the overall system performance is crucial.\n",
      "Workflow orchestration and scheduling. Components\n",
      "may need to be executed in a specific order, processed in paral-\n",
      "lel under certain conditions, or even judged by the LLM based\n",
      "on different outputs. Reasonable planning of the workflow is\n",
      "essential for improving system efficiency and achieving the\n",
      "desired outcomes [18].\n",
      "To address the design, management, and maintenance chal-\n",
      "lenges posed by the increasing complexity of RAG systems,\n",
      "and to meet the ever-growing and diverse demands and ex-\n",
      "pectations, this paper proposes Modular RAG architecture.\n",
      "In modern computing systems, modularization is becoming\n",
      "a trend. It can enhance the system’s scalability and maintain-\n",
      "ability and achieve efficient task execution through process\n",
      "control.\n",
      "The Modular RAG system consists of multiple independent\n",
      "yet tightly coordinated modules, each responsible for handling\n",
      "specific functions or tasks. This architecture is divided into\n",
      "three levels: the top level focuses on the critical stages of\n",
      "RAG, where each stage is treated as an independent module.\n",
      "This level not only inherits the main processes from the\n",
      "Advanced RAG paradigm but also introduces an orchestration\n",
      "module to control the coordination of RAG processes. The\n",
      "middle level is composed of sub-modules within each module,\n",
      "further refining and optimizing the functions. The bottom level\n",
      "consists of basic units of operation—operators. Within the\n",
      "Modular RAG framework, RAG systems can be represented\n",
      "in the form of computational graphs, where nodes represent\n",
      "specific operators. The comparison of the three paradigms is\n",
      "shown in the Figure 3. Modular RAG evolves based on the\n",
      "previous development of RAG. The relationships among these\n",
      "three paradigms are ones of inheritance and development.\n",
      "Advanced RAG is a special case of Modular RAG, while Naive\n",
      "RAG is a special case of Advanced RAG.\n",
      "The advantages of Modular RAG are significant, as it\n",
      "enhances the flexibility and scalability of RAG systems. Users\n",
      "can flexibly combine different modules and operators accord-\n",
      "ing to the requirements of data sources and task scenarios. In\n",
      "summary, the contributions of this paper are as follows:\n",
      "• This paper proposes a new paradigm called modular\n",
      "RAG, which employs a three-tier architectural design\n",
      "comprising modules, sub-modules, and operators to de-\n",
      "fine the RAG system in a unified and structured manner.\n",
      "This design not only enhances the system’s flexibility and\n",
      "scalability but also, through the independent design of\n",
      "operators, strengthens the system’s maintainability and\n",
      "comprehensibility.\n",
      "• Under the framework of Modular RAG, the orchestration\n",
      "of modules and operators forms the RAG Flow, which\n",
      "can flexibly express current RAG methods. This paper has\n",
      "further summarized six typical flow patterns and specific\n",
      "methods have been analyzed to reveal the universality of\n",
      "modular RAG in practical scenarios.\n",
      "• The Modular RAG framework offers exceptional flexi-\n",
      "bility and extensibility. This paper delves into the new\n",
      "opportunities brought by Modular RAG and provides a\n",
      "thorough discussion on the adaptation and expansion of\n",
      "new methods in different application scenarios, offering\n",
      "guidance for future research directions and practical ex-\n",
      "ploration.\n",
      "II. RELATED WORK\n",
      "The development of RAG technology can be summarized\n",
      "in three stages. Initially, retrieval-augmented techniques were\n",
      "introduced to improve the performance of pre-trained lan-\n",
      "guage models on knowledge-intensive tasks [19], [20]. In\n",
      "specific implementations, Retro [21] optimized pre-trained\n",
      "autoregressive models through retrieval augmentation, while\n",
      "Atlas [22] utilized a retrieval-augmented few-shot fine-tuning\n",
      "method, enabling language models to adapt to diverse tasks.\n",
      "IRCOT [23] further enriched the reasoning process during\n",
      "the inference phase by combining chain-of-thought and multi-\n",
      "step retrieval processes. Entering the second stage, as the\n",
      "language processing capabilities of LLMs significantly im-\n",
      "proved, retrieval-augmented techniques began to serve as a\n",
      "means of supplementing additional knowledge and providing\n",
      "references, aiming to reduce the hallucination. For instance,\n",
      "RRR [24] improved the rewriting phase, and LLMlingua [25]\n",
      "removed redundant tokens in retrieved document chunks.\n",
      "With the continuous progress of RAG technology, research\n",
      "has become more refined and focused, while also achieving\n",
      "innovative integration with other technologies such as graph\n",
      "neural networks [26] and fine-tuning techniques [27]. The\n",
      "overall pipeline has also become more flexible, such as using\n",
      "LLMs to proactively determine the timing of retrieval and\n",
      "generation [14], [28].\n",
      "The development of RAG technology has been acceler-\n",
      "ated by LLM technology and practical application needs.\n",
      "Researchers are examining and organizing the RAG frame-\n",
      "work and development pathways from different perspectives.\n",
      "Building upon the enhanced stages of RAG, Gao et al., [2] sub-\n",
      "divided RAG into enhancement during pre-training, inference,\n",
      "and fine-tuning stages. Based on the main processes of RAG,\n",
      "relevant works on RAG were organized from the perspectives\n",
      "of retrieval, generation, and augmentation methods. Huang\n",
      "et al., [29] categorize RAG methods into four main classes:\n",
      "pre-retrieval, retrieval, post-retrieval, generation, and provide\n",
      "a detailed discussion of the methods and techniques within\n",
      "each class. Hu et al., [30] discuss Retrieval-Augmented Lan-\n",
      "guage Models (RALMs) form three key components, including\n",
      "retrievers, language models, augmentations, and how their\n",
      "interactions lead to different model structures and applications.\n",
      "4\n",
      "Fig. 3. Comparison between three RAG paradigms. Modular RAG has evolved from previous paradigms and aligns with the current practical needs of RAG\n",
      "systems.\n",
      "They emphasize the importance of considering robustness,\n",
      "accuracy, and relevance when evaluating RALMs and pro-\n",
      "pose several evaluation methods. Ding et al., [31] provide a\n",
      "comprehensive review from the perspectives of architecture,\n",
      "training strategies, and applications. They specifically discuss\n",
      "four training methods of RALMs: training-free methods, in-\n",
      "dependent training methods, sequence training methods, and\n",
      "joint training methods, and compare their advantages and\n",
      "disadvantages. Zhao et al., [32]analyze the applications of\n",
      "RAG technology in various fields such as text generation,\n",
      "code generation, image generation, and video generation from\n",
      "the perspective of augmented intelligence with generative\n",
      "capabilities.\n",
      "The current collation of RAG systems primarily focuses\n",
      "on methods with a fixed process, mainly concerned with\n",
      "optimizing the retrieval and generation stages. However, it has\n",
      "not turned its attention to the new characteristics that RAG\n",
      "research is continuously evolving, namely the characteristics\n",
      "of process scheduling and functional componentization. There\n",
      "is currently a lack of comprehensive analysis of the overall\n",
      "RAG system, which has led to research on paradigms lagging\n",
      "behind the development of RAG technology.\n",
      "III. FRAMEWORK AND NOTATION\n",
      "For query Q = {qi}, a typical RAG system mainly consists\n",
      "of three key components. 1) Indexing. Given documents D =\n",
      "{d1, d2, . . . , dn} , where di represents the document chunk.\n",
      "Indexing is the process of converting di into vectors through\n",
      "an embedding model fe(·) , and then store vectors in vector\n",
      "database.\n",
      "I = {e1, e2, . . . , en}\n",
      "and\n",
      "ei = fe(di) ∈Rd\n",
      "(1)\n",
      "Notation\n",
      "Description\n",
      "q\n",
      "The original query\n",
      "y\n",
      "The output of LLM\n",
      "D\n",
      "A document retrieval repository composed of chunks di.\n",
      "R(q, D)\n",
      "Retriever,find similar chunks from D based on q.\n",
      "F\n",
      "RAG Flow\n",
      "P\n",
      "RAG Flow pattern\n",
      "fqe\n",
      "Query expansion function\n",
      "fqc\n",
      "Query transform function\n",
      "fcomp\n",
      "Chunk compression function\n",
      "fsel\n",
      "Chunk selection function\n",
      "fr\n",
      "Routing function\n",
      "M\n",
      "Module in modular RAG\n",
      "op\n",
      "The specific operators within the Module.\n",
      "TABLE I\n",
      "IMPORTANT NOTATION\n",
      "2) Retrieval . Transform the query into a vector using the\n",
      "same encoding model, and then filter out the top k document\n",
      "chunks that are most similar based on vector similarity.\n",
      "R : topk\n",
      "di∈D\n",
      "Sim(q, di) →Dq\n",
      "(2)\n",
      "Dq = {d1, d2, . . . , dk} represents the relevant documents for\n",
      "question q. The similarity function Sim(·) commonly used are\n",
      "dot product or cosine similarity.\n",
      "Sim(q, di) = eq · edi\n",
      "or\n",
      "eq · edi\n",
      "∥eq∥· ∥edi∥\n",
      "(3)\n",
      "3) Generation. After getting the relevant documents. The\n",
      "query q and the retrieved document Dq chunks are inputted\n",
      "together to the LLM to generate the final answer, where [·, ·]\n",
      "stands for concatenation.\n",
      "y = LLM([Dq, q])\n",
      "(4)\n",
      "5\n",
      "With the evolution of RAG technology, more and more func-\n",
      "tional components are being integrated into systems. Modular\n",
      "RAG paradigm includes three levels, ranging from large to\n",
      "small:\n",
      "L1 Module (M = {Ms}). The core process in RAG\n",
      "system.\n",
      "L2 Sub-module (Ms = {Op}).The functional modules in\n",
      "module.\n",
      "L3 Operator (Op = {fθi}). The the specific functional\n",
      "implementation in a module or sub-module. As a result, a\n",
      "Modular RAG system can be represented as:\n",
      "G = {q, D, M, {Ms}, {Op}}\n",
      "(5)\n",
      "The arrangement between modules and operators constitutes\n",
      "the RAG Flow F = (Mϕ1, . . . , Mϕn) where ϕ stands for\n",
      "the set of module parameters. A modular rag flow can be\n",
      "decomposed into a graph of sub-functions. In the simplest\n",
      "case,the graph is a linear chain.\n",
      "NaiveRAG : q\n",
      "R(q,D)\n",
      "−−−−−−−−−−−→\n",
      "T ext−Embedding Dq\n",
      "LLM([q,Dq])\n",
      "−−−−−−−−−−−→\n",
      "OpenAI/GP T −4 y\n",
      "(6)\n",
      "IV. MODULE AND OPERATOR\n",
      "This chapter will specifically introduce modules and op-\n",
      "erators under the Modular RAG framework. Based on the\n",
      "current stage of RAG development, we have established\n",
      "six main modules: Indexing, Pre-retrieval, Retrieval, Post-\n",
      "retrieval, Generation, and Orchestration.\n",
      "A. Indexing\n",
      "Indexing is the process of split document into manageable\n",
      "chunks and it is a key step in organizing a system. Indexing\n",
      "faces three main challenges. 1) Incomplete content represen-\n",
      "tation.The semantic information of chunks is influenced by the\n",
      "segmentation method, resulting in the loss or submergence of\n",
      "important information within longer contexts. 2) Inaccurate\n",
      "chunk similarity search. As data volume increases, noise in\n",
      "retrieval grows, leading to frequent matching with erroneous\n",
      "data, making the retrieval system fragile and unreliable. 3)\n",
      "Unclear reference trajectory. The retrieved chunks may orig-\n",
      "inate from any document, devoid of citation trails, potentially\n",
      "resulting in the presence of chunks from multiple different\n",
      "documents that, despite being semantically similar, contain\n",
      "content on entirely different topics.\n",
      "1) Chunk Optimization: The size of the chunks and the\n",
      "overlap between the chunks play a crucial role in the overall\n",
      "effectiveness of the RAG system. Given a chunk di, its chunk\n",
      "size is denoted as Li = |di|, and the overlap is denoted as\n",
      "Lo\n",
      "i = |di ∩di+1|. Larger chunks can capture more context,\n",
      "but they also generate more noise, requiring longer processing\n",
      "time and higher costs. While smaller chunks may not fully\n",
      "convey the necessary context, they do have less noise [17].\n",
      "Sliding Window using overlapping chunks in a sliding win-\n",
      "dow enhances semantic transitions. However, it has limitations\n",
      "such as imprecise context size control, potential truncation of\n",
      "words or sentences, and lacking semantic considerations.\n",
      "Metadata Attachment. Chunks can be enriched with meta-\n",
      "data like page number, file name, author, timestamp, sum-\n",
      "mary, or relevant questions. This metadata allows for filtered\n",
      "retrieval, narrowing the search scope.\n",
      "Small-to-Big [33] separate the chunks used for retrieval\n",
      "from those used for synthesis. Smaller chunks enhance re-\n",
      "trieval accuracy, while larger chunks provide more context.\n",
      "One approach is to retrieve smaller summarized chunks and\n",
      "reference their parent larger chunks. Alternatively, individual\n",
      "sentences could be retrieved along with their surrounding text.\n",
      "2) Structure Organization: One effective method for en-\n",
      "hancing information retrieval is to establish a hierarchical\n",
      "structure for the documents. By constructing chunks structure,\n",
      "RAG system can expedite the retrieval and processing of\n",
      "pertinent data.\n",
      "Hierarchical Index. In the hierarchical structure of docu-\n",
      "ments, nodes are arranged in parent-child relationships, with\n",
      "chunks linked to them. Data summaries are stored at each\n",
      "node, aiding in the swift traversal of data and assisting the\n",
      "RAG system in determining which chunks to extract. This\n",
      "approach can also mitigate the illusion caused by chunk\n",
      "extraction issues. The methods for constructing a structured\n",
      "index primarily include: 1) Structural awareness based on\n",
      "paragraph and sentence segmentation in docs. 2) Content\n",
      "awareness based on inherent structure in PDF, HTML, and\n",
      "Latex. 3) Semantic awareness based on semantic recognition\n",
      "and segmentation of text.\n",
      "KG Index [34]. Using Knowledge Graphs (KGs) to struc-\n",
      "ture documents helps maintain consistency by clarifying con-\n",
      "nections between concepts and entities, reducing the risk of\n",
      "mismatch errors. KGs also transform information retrieval\n",
      "into instructions intelligible to language models, improving re-\n",
      "trieval accuracy and enabling contextually coherent responses.\n",
      "This enhances the overall efficiency of the RAG system.\n",
      "For example, organizing a corpus in the format of graph\n",
      "G = {V, E, X}, where node V = {vi}n\n",
      "i=1 represent document\n",
      "structures (e.g.passage, pages, table) , edge E ⊂V × V rep-\n",
      "resent semantic or lexical similarity and belonging relations,\n",
      "and node features X = {Xi}n\n",
      "i=1 represent text or markdown\n",
      "content for passage.\n",
      "B. Pre-retrieval\n",
      "One of the primary challenges with Naive RAG is its\n",
      "direct reliance on the user’s original query as the basis for\n",
      "retrieval. Formulating a precise and clear question is difficult,\n",
      "and imprudent queries result in subpar retrieval effectiveness.\n",
      "The primary challenges in this module include: 1) Poorly\n",
      "worded queries. The question itself is complex, and the\n",
      "language is not well-organized. 2) Language complexity and\n",
      "ambiguity. Language models often struggle when dealing\n",
      "with specialized vocabulary or ambiguous abbreviations with\n",
      "multiple meanings. For instance, they may not discern whether\n",
      "LLM refers to Large Language Model or a Master of Laws in\n",
      "a legal context.\n",
      "1) Query Expansion : Expanding a single query into mul-\n",
      "tiple queries enriches the content of the query, providing\n",
      "6\n",
      "further context to address any lack of specific nuances, thereby\n",
      "ensuring the optimal relevance of the generated answers.\n",
      "fqe(q) = {q1, q2, . . . , qn}\n",
      "∀qi ∈{q1, q2, . . . , qn}, qi /∈Q\n",
      "(7)\n",
      "Multi-Query uses prompt engineering to expand queries\n",
      "via LLMs, allowing for parallel execution. These expansions\n",
      "are meticulously designed to ensure diversity and coverage.\n",
      "However, this approach can dilute the user’s original intent.\n",
      "To mitigate this, the model can be instructed to assign greater\n",
      "weight to the original query.\n",
      "Sub-Query. By decomposing and planning for complex\n",
      "problems, multiple sub-problems are generated. Specifically,\n",
      "least-to-most prompting [35] can be employed to decom-\n",
      "pose the complex problem into a series of simpler sub-\n",
      "problems. Depending on the structure of the original problem,\n",
      "the generated sub-problems can be executed in parallel or\n",
      "sequentially. Another approach involves the use of the Chain-\n",
      "of-Verification (CoVe) [36]. The expanded queries undergo\n",
      "validation by LLM to achieve the effect of reducing hallu-\n",
      "cinations.\n",
      "2) Query Transformation: Retrieve and generate based on\n",
      "a transformed query instead of the user’s original query.\n",
      "fqt(q) = q′\n",
      "(8)\n",
      "Rewrite. Original queries often fall short for retrieval in\n",
      "real-world scenarios. To address this, LLMs can be prompted\n",
      "to rewrite. Specialized smaller models can also be employed\n",
      "for this purpose [24]. The implementation of the query rewrite\n",
      "method in Taobao has significantly improved recall effective-\n",
      "ness for long-tail queries, leading to an increase in GMV [10].\n",
      "HyDE [37]. In order to bridge the semantic gap between\n",
      "questions and answers, it constructs hypothetical documents\n",
      "(assumed answers) when responding to queries instead of\n",
      "directly searching the query. It focuses on embedding simi-\n",
      "larity from answer to answer rather than seeking embedding\n",
      "similarity for the problem or query. In addition, it also in-\n",
      "cludes reverse HyDE, which generate hypothetical query for\n",
      "each chunks and focuses on retrieval from query to query.\n",
      "Step-back Prompting [38]. The original query is abstracted\n",
      "into a high-level concept question (step-back question). In the\n",
      "RAG system, both the step-back question and the original\n",
      "query are used for retrieval, and their results are combined\n",
      "to generate the language model’s answer.\n",
      "3) Query Construction: In addition to text data, an in-\n",
      "creasing amount of structured data, such as tables and graph\n",
      "data, is being integrated into RAG systems. To accommodate\n",
      "various data types, it is necessary to restructure the user’s\n",
      "query. This involve converting the query into another query\n",
      "language to access alternative data sources, with common\n",
      "methods including Text-to-SQL or Text-to-Cypher . In many\n",
      "scenarios, structured query languages (e.g., SQL, Cypher)\n",
      "are often used in conjunction with semantic information and\n",
      "metadata to construct more complex queries.\n",
      "fqc(q) = q∗, q∗∈Q∗= {SQL, Cypher, . . . }\n",
      "(9)\n",
      "C. Retrieval\n",
      "The retrieval process is pivotal in RAG systems. By lever-\n",
      "aging powerful embedding models, queries and text can be\n",
      "efficiently represented in latent spaces, which facilitates the\n",
      "establishment of semantic similarity between questions and\n",
      "documents, thereby enhancing retrieval. Three main consider-\n",
      "ations that need to be addressed include retrieval efficiency,\n",
      "quality, and the alignment of tasks, data and models.\n",
      "1) Retriever Selection: With the widespread adoption of\n",
      "RAG technology, the development of embedding models has\n",
      "been in full swing. In addition to traditional models based\n",
      "on statistics and pre-trained models based on the encoder\n",
      "structure, embedding models fine-tuned on LLMs have also\n",
      "demonstrated powerful capabilities [39]. However, they often\n",
      "come with more parameters, leading to weaker inference\n",
      "and retrieval efficiency. Therefore, it is crucial to select the\n",
      "appropriate retriever based on different task scenarios.\n",
      "Sparse Retriever uses statistical methods to convert queries\n",
      "and documents into sparse vectors. Its advantage lies in its\n",
      "efficiency in handling large datasets, focusing only on non-zero\n",
      "elements. However, it may be less effective than dense vectors\n",
      "in capturing complex semantics. Common methods include\n",
      "TF-IDF and BM25.\n",
      "Dense Retriever employs pre-trained language models\n",
      "(PLMs) to provide dense representations of queries and doc-\n",
      "uments. Despite higher computational and storage costs, it\n",
      "offers more complex semantic representations. Typical models\n",
      "include BERT structure PLMs, like ColBERT, and multi-task\n",
      "fine-tuned models like BGE [40] and GTE [41].\n",
      "Hybrid Retriever is to use both sparse and dense retrievers\n",
      "simultaneously. Two embedding techniques complement each\n",
      "other to enhance retrieval effectiveness. Sparse retriever can\n",
      "provide initial screening results. Additionally, sparse models\n",
      "enhance the zero-shot retrieval capabilities of dense models,\n",
      "particularly in handling queries with rare entities, thereby\n",
      "increasing system robustness.\n",
      "2) Retriever Fine-tuning: In cases where the context may\n",
      "diverge from pre-trained corpus, particularly in highly special-\n",
      "ized fields like healthcare, law, and other domains abundant in\n",
      "proprietary terminology. While this adjustment demands addi-\n",
      "tional effort, it can substantially enhance retrieval efficiency\n",
      "and domain alignment.\n",
      "Supervised Fine-Tuning (SFT). Fine-tuning a retrieval\n",
      "model based on labeled domain data is typically done using\n",
      "contrastive learning. This involves reducing the distance be-\n",
      "tween positive samples while increasing the distance between\n",
      "negative samples. The commonly used loss calculation is\n",
      "shown in the following:\n",
      "L(DR) = −1\n",
      "T\n",
      "T\n",
      "X\n",
      "i=1\n",
      "log\n",
      "e(sim(qi,d+\n",
      "i ))\n",
      "e(sim(qi,d+\n",
      "i )) + PN\n",
      "j=1 e(sim(qi,d−\n",
      "i ))\n",
      "(10)\n",
      "where d+\n",
      "i is the positive sample document corresponding to\n",
      "the i-th query, d−\n",
      "i\n",
      "is several negative sample, T is the total\n",
      "number of queries, N is the number of negative samples, and\n",
      "DR is the fine-tuning dataset.\n",
      "LM-supervised Retriever (LSR). In contrast to directly\n",
      "constructing a fine-tuning dataset from the dataset, LSR uti-\n",
      "7\n",
      "lizes the LM-generated results as supervisory signals to fine-\n",
      "tune the embedding model during the RAG process.\n",
      "PLSR(d|q, y) =\n",
      "ePLM(y|d,q)/β\n",
      "P\n",
      "d′∈D ePLM(y|d,q)/β)\n",
      "(11)\n",
      "PLM(y|d, q) is LM probability of the ground truth output y\n",
      "given the input context d and query q, and β is a hyper-\n",
      "paramter.\n",
      "Adapter. At times, fine-tuning a large retriever can be\n",
      "costly, especially when dealing with retrievers based on LLMs\n",
      "like gte-Qwen. In such cases, it can mitigate this by incorpo-\n",
      "rating an adapter module and conducting fine-tuning. Another\n",
      "benefit of adding an adapter is the ability to achieve better\n",
      "alignment with specific downstream tasks [42].\n",
      "D. Post-retrieval\n",
      "Feeding all retrieved chunks directly into the LLM is not an\n",
      "optimal choice. Post-processing the chunks can aid in better\n",
      "leveraging the contextual information. The primary challenges\n",
      "include: 1) Lost in the middle. Like humans, LLM tends\n",
      "to remember only the beginning or the end of long texts,\n",
      "while forgetting the middle portion [43]. 2) Noise/anti-fact\n",
      "chunks. Retrieved noisy or factually contradictory documents\n",
      "can impact the final retrieval generation [44].\n",
      "3) Context\n",
      "Window. Despite retrieving a substantial amount of relevant\n",
      "content, the limitation on the length of contextual information\n",
      "in large models prevents the inclusion of all this content.\n",
      "1) Rerank: Rerank the retrieved chunks without altering\n",
      "their content or length, to enhance the visibility of the more\n",
      "crucial document chunks. Given the retrieved set Dq and a\n",
      "re-ranking method frerank to obtain the re-ranked set:\n",
      "Dq\n",
      "r = frerank(q, Dq) = {d′\n",
      "1, d′\n",
      "2, . . . , d′\n",
      "k}\n",
      "wheref(d′\n",
      "1) ≥f(d′\n",
      "2) ≥. . . ≥f(d′\n",
      "k).\n",
      "(12)\n",
      "Rule-base rerank. Metrics are calculated to rerank chunks\n",
      "according to certain rules. Common metrics include: diversity,\n",
      "relevance and MRR (Maximal Marginal Relevance) [45]. The\n",
      "idea is to reduce redundancy and increase result diversity.\n",
      "MMR selects phrases for the final key phrase list based on a\n",
      "combined criterion of query relevance and information novelty.\n",
      "Model-base rerank. Utilize a language model to reorder the\n",
      "document chunks, commonly based on the relevance between\n",
      "the chunks and the query. Rerank models have become an\n",
      "important component of RAG systems, and relevant model\n",
      "technologies are also being iteratively upgraded. The scope\n",
      "reordering has also been extended to multimodal data such as\n",
      "tables and images [46].\n",
      "2) Compression: A common misconception in the RAG\n",
      "process is the belief that retrieving as many relevant docu-\n",
      "ments as possible and concatenating them to form a lengthy\n",
      "retrieval prompt is beneficial. However, excessive context can\n",
      "introduce more noise, diminishing the LLM’s perception of\n",
      "key information. A common approach to address this is to\n",
      "compress and select the retrieved content.\n",
      "Dq\n",
      "c = fcomp(q, Dq),\n",
      "where|dqc\n",
      "i | < |dq\n",
      "i |\n",
      "∀dq\n",
      "i ∈Dq\n",
      "(13)\n",
      "(Long)LLMLingua [47]. By utilizing aligned and trained\n",
      "small language models, such as GPT-2 Small or LLaMA-\n",
      "7B, the detection and removal of unimportant tokens from\n",
      "the prompt is achieved, transforming it into a form that is\n",
      "challenging for humans to comprehend but well understood by\n",
      "LLMs. This approach presents a direct and practical method\n",
      "for prompt compression, eliminating the need for additional\n",
      "training of LLMs while balancing language integrity and\n",
      "compression ratio.\n",
      "3) Selection: Unlike compressing the content of document\n",
      "chunks, Selection directly removes irrelevant chunks.\n",
      "Dq\n",
      "s = fsel(Dq) = {di ∈D | ¬P(di)}\n",
      "(14)\n",
      "Where fsel is the function for deletion operation and P(di) is\n",
      "a conditional predicate indicating that document (di) satisfies\n",
      "a certain condition. If document (di) satisfies (P(di)), it will\n",
      "be deleted. Conversely, documents for which (¬P(di)) is true\n",
      "will be retained.\n",
      "Selective Context. By identifying and removing redundant\n",
      "content in the input context, the input is refined, thus improv-\n",
      "ing the language model’s reasoning efficiency. In practice, se-\n",
      "lective context assesses the information content of lexical units\n",
      "based on the self-information computed by the base language\n",
      "model. By retaining content with higher self-information, this\n",
      "method offers a more concise and efficient textual representa-\n",
      "tion, without compromising their performance across diverse\n",
      "applications. However, it overlooks the interdependence be-\n",
      "tween compressed content and the alignment between the\n",
      "targeted language model and the small language model utilized\n",
      "for prompting compression [48].\n",
      "LLM-Critique. Another straightforward and effective ap-\n",
      "proach involves having the LLM evaluate the retrieved content\n",
      "before generating the final answer. This allows the LLM\n",
      "to filter out documents with poor relevance through LLM\n",
      "critique. For instance, in Chatlaw [49], the LLM is prompted\n",
      "to self-suggestion on the referenced legal provisions to assess\n",
      "their relevance.\n",
      "E. Generation\n",
      "Utilize the LLM to generate answers based on the user’s\n",
      "query and the retrieved contextual information. Select an\n",
      "appropriate model based on the task requirements, considering\n",
      "factors such as the need for fine-tuning, inference efficiency,\n",
      "and privacy protection.\n",
      "1) Generator Fine-tuning: In addition to direct LLM usage,\n",
      "targeted fine-tuning based on the scenario and data character-\n",
      "istics can yield better results. This is also one of the greatest\n",
      "advantages of using an on-premise setup LLMs.\n",
      "Instruct-Tuning. When LLMs lack data in a specific do-\n",
      "main, additional knowledge can be provided to the LLM\n",
      "through fine-tuning. General fine-tuning dataset can also be\n",
      "used as an initial step. Another benefit of fine-tuning is the\n",
      "ability to adjust the model’s input and output. For example, it\n",
      "can enable LLM to adapt to specific data formats and generate\n",
      "responses in a particular style as instructed [50].\n",
      "Reinforcement learning. Aligning LLM outputs with hu-\n",
      "man or retriever preferences through reinforcement learning is\n",
      "8\n",
      "a potential approach [51]. For instance, manually annotating\n",
      "the final generated answers and then providing feedback\n",
      "through reinforcement learning. In addition to aligning with\n",
      "human preferences, it is also possible to align with the\n",
      "preferences of fine-tuned models and retrievers.\n",
      "Dual Fine-tuing Fine-tuning both generator and retriever\n",
      "simultaneously to align their preferences. A typical approach,\n",
      "such as RA-DIT [27], aligns the scoring functions between\n",
      "retriever and generator using KL divergence. Retrieval likeli-\n",
      "hood of each retrieved document d is calculated as :\n",
      "PR(d|q) =\n",
      "e(sim(d,q))/γ\n",
      "P\n",
      "d∈Dq e(sim(d,q)/γ\n",
      "(15)\n",
      "PLM(y|d, q) is the LM probability of the ground truth output y\n",
      "given the input context d, question q, and γ is a hyperparamter.\n",
      "The overall loss is calculated as:\n",
      "L = 1\n",
      "|T|\n",
      "T\n",
      "X\n",
      "i=1\n",
      "KL(PR(d|q)||PLSR(d|q, y|))\n",
      "(16)\n",
      "2) Verification : Although RAG enhances the reliability\n",
      "of LLM-generated answers, in many scenarios, it requires to\n",
      "minimize the probability of hallucinations. Therefore, it can\n",
      "filter out responses that do not meet the required standards\n",
      "through additional verification module. Common verification\n",
      "methods include knowledge-base and model-base .\n",
      "yk = fverify(q, Dq, y)\n",
      "(17)\n",
      "Knowledge-base verification refers to directly validating the\n",
      "responses generated by LLMs through external knowledge.\n",
      "Generally, it extracts specific statements or triplets from re-\n",
      "sponse first. Then, relevant evidence is retrieved from verified\n",
      "knowledge base such as Wikipedia or specific knowledge\n",
      "graphs. Finally, each statement is incrementally compared with\n",
      "the evidence to determine whether the statement is supported,\n",
      "refuted, or if there is insufficient information [52].\n",
      "Model-based verification refers to using a small language\n",
      "model to verify the responses generated by LLMs [53].\n",
      "Given the input question, the retrieved knowledge, and the\n",
      "generated answer, a small language model is trained to de-\n",
      "termine whether the generated answer correctly reflects the\n",
      "retrieved knowledge. This process is framed as a multiple-\n",
      "choice question, where the verifier needs to judge whether the\n",
      "answer reflects correct answer . If the generated answer does\n",
      "not correctly reflect the retrieved knowledge, the answer can\n",
      "be iteratively regenerated until the verifier confirms that the\n",
      "answer is correct.\n",
      "F. Orchestration\n",
      "Orchestration pertains to the control modules that govern the\n",
      "RAG process. Unlike the traditional, rigid approach of a fixed\n",
      "process, RAG now incorporates decision-making at pivotal\n",
      "junctures and dynamically selects subsequent steps contingent\n",
      "upon the previous outcomes. This adaptive and modular ca-\n",
      "pability is a hallmark of modular RAG, distinguishing it from\n",
      "the more simplistic Naive and Advance RAG paradigm.\n",
      "1) Routing: In response to diverse queries, the RAG system\n",
      "routes to specific pipelines tailored for different scenario, a\n",
      "feature essential for a versatile RAG architecture designed\n",
      "to handle a wide array of situations. A decision-making\n",
      "mechanism is necessary to ascertain which modules will be\n",
      "engaged, based on the input from the model or supplementary\n",
      "metadata. Different routes are employed for distinct prompts\n",
      "or components. This routing mechanism is executed through\n",
      "a function, denoted as fr(·), which assigns a score αi to\n",
      "each module. These scores dictate the selection of the active\n",
      "subset of modules. Mathematically, the routing function is\n",
      "represented as:\n",
      "fr : Q →F\n",
      "(18)\n",
      "where fr(·) maps the identified query to its corresponding\n",
      "RAG flow.\n",
      "Metadata routing involves extracting key terms, or entities,\n",
      "from the query, applying a filtration process that uses these\n",
      "keywords and associated metadata within the chunks to refine\n",
      "the routing parameters. For a specific RAG flow, denoted as\n",
      "Fi, the pre-defined routing keywords are represented as the\n",
      "set Ki = {ki1, ki2, . . . , kin}. The keyword identified within\n",
      "the query qi is designated as K′\n",
      "i. The matching process for\n",
      "the query q is quantified by the key score equation:\n",
      "scorekey(qi, Fj) =\n",
      "1\n",
      "|K′\n",
      "j||Ki ∩K′\n",
      "j|\n",
      "(19)\n",
      "This equation calculates the overlap between the pre-defined\n",
      "keywords and those identified in the query, normalized by the\n",
      "count of keywords in K′\n",
      "j. The final step is to determine the\n",
      "most relevant flow for the query q:\n",
      "Fi(q) = argmaxFj∈Fscore(q, Fj)\n",
      "(20)\n",
      "Semantic routing routes to different modules based on the\n",
      "semantic information of the query. Given a pre-defined intent\n",
      "Θ = {θ1, θ2, . . . , θn}, the possibility of intent for query q is\n",
      "PΘ(θ|q) =\n",
      "ePLM (θ|q)\n",
      "P\n",
      "θ∈Θ ePLM (θ|q)) . Routing to specific RAG flow is\n",
      "determined by the semantic score:\n",
      "socresemantic(q, Fj) = argmaxθj∈ΘP(Θ)\n",
      "(21)\n",
      "The function δ(·) serves as a mapping function that assigns\n",
      "an intent to a distinct RAG flow Fi = δ(θi)\n",
      "Hybrid Routing can be implemented to improve query\n",
      "routing by integrating both semantic analysis and metadata-\n",
      "based approaches, which can be defined as follows:\n",
      "αi = a·scorekey(q, Fj)+(1−α)·maxθj∈Θsocresemantic(q, Fj)\n",
      "(22)\n",
      "a is a weighting factor that balances the contribution of the\n",
      "key-based score and the semantic score.\n",
      "2) Scheduling: The RAG system evolves in complexity\n",
      "and adaptability, with the ability to manage processes through\n",
      "a sophisticated scheduling module. The scheduling module\n",
      "plays a crucial role in the modular RAG , identifying critical\n",
      "junctures that require external data retrieval, assessing the\n",
      "adequacy of the responses, and deciding on the necessity for\n",
      "further investigation. It is commonly utilized in scenarios that\n",
      "involve recursive, iterative, and adaptive retrieval, ensuring\n",
      "9\n",
      "that the system makes informed decisions on when to cease\n",
      "generation or initiate a new retrieval loop.\n",
      "Rule judge. The subsequent steps are dictated by a set of\n",
      "established rules. Typically, the system evaluates the quality of\n",
      "generated answers through scoring mechanisms. The decision\n",
      "to proceed or halt the process is contingent upon whether these\n",
      "scores surpass certain predetermined thresholds, often related\n",
      "to the confidence levels of individual tokens, which can be\n",
      "defined as follow:\n",
      "yt =\n",
      "(\n",
      "ˆst\n",
      "if all tokens of ˆst have probs ≥τ\n",
      "st = LM([Dqt, x, y<t])\n",
      "otherwise\n",
      "Here, ˆst represents the tentative answer, and st is the output\n",
      "from the language model. The condition for accepting ˆst is that\n",
      "all tokens within it must have associated probabilities greater\n",
      "than or equal to the threshold τ. If this condition is not met,\n",
      "the system reverts to generating a new answer.\n",
      "LLM judge. The LLM independently determines the sub-\n",
      "sequent course of action. Two primary approaches facilitate\n",
      "this capability. The first method leverages LLM ’s in-context\n",
      "learning capability, and make judgments through prompt\n",
      "engineering. A significant advantage of this method is the\n",
      "elimination of model fine-tuning. Nonetheless, the format of\n",
      "the judgment output is contingent upon the LLM’s adherence\n",
      "to the provided instructions.\n",
      "The second approach involves the LLM generating specific\n",
      "tokens that initiate targeted actions through fine-tuning. This\n",
      "technique, with roots in the Toolformer [50], has been inte-\n",
      "grated into frameworks like Self-RAG [28]. This allows for a\n",
      "more direct control mechanism over the LLM’s actions, en-\n",
      "hancing the system’s responsiveness to specific triggers within\n",
      "the conversational context. However, it requires generating a\n",
      "large number of compliant instruction sets to fine-tune LLM.\n",
      "Knowledge-guide scheduling. Beyond the confines of rule-\n",
      "based methods and the complete reliance on LLMs for process\n",
      "control, a more adaptable intermediate approach emerges with\n",
      "knowledge-guided scheduling [26]. These methods harness\n",
      "the power of knowledge graphs, to steer the retrieval and\n",
      "generation processes. Specifically, it involves extracting infor-\n",
      "mation relevant to the question from a knowledge graph and\n",
      "constructing a reasoning chain. This reasoning chain consists\n",
      "of a series of logically interconnected nodes, each containing\n",
      "critical information for the problem-solving process. Based\n",
      "on the information from the nodes in this reasoning chain,\n",
      "information retrieval and content generation can be performed\n",
      "separately. By integrating this approach, it enhance not only\n",
      "the efficacy and precision of problem-solving but also the\n",
      "clarity of the explanations provided.\n",
      "3) Fusion: As RAG process has evolved beyond a linear\n",
      "pipeline, it frequently necessitates broadening the retrieval\n",
      "scope or enhancing diversity by exploring multiple pipelines.\n",
      "Consequently, after the expansion into various branches, the\n",
      "fusion module effectively integrates the information, ensuring\n",
      "a comprehensive and coherent response. The fusion module’s\n",
      "reliance is not just for merging answers but also for ensuring\n",
      "that the final output is both rich in content and reflective of\n",
      "the multifaceted nature of the inquiry.\n",
      "LLM fusion.One of the most straightforward methods for\n",
      "multi-branch aggregation is to leverage the powerful capa-\n",
      "bilities of LLMs to analyze and integrate information from\n",
      "different branches. However, this approach also faces some\n",
      "challenges, particularly when dealing with long answers that\n",
      "exceeds the LLM’s context window limitation. To mitigate this\n",
      "issue, it is common practice to first summarize each branch’s\n",
      "answer, extracting the key information before inputting it into\n",
      "the LLM, thus ensuring that the most important content is\n",
      "retained even within length constraints.\n",
      "Weighted ensemble\n",
      "is based on the weighted values of\n",
      "different tokens generated from multiple branches, leading to\n",
      "the comprehensive selection of the final output. This approach\n",
      "can be calculated as :\n",
      "p(y|q, Dq) =\n",
      "X\n",
      "d∈Dq\n",
      "p(y|d, q) · λ(d, q)\n",
      "(23)\n",
      "The weight λ(d, q) is determined by the similarity score\n",
      "between the document d and the input query q. This weight is\n",
      "calculated using the softmax function, which ensures that the\n",
      "weights are normalized and sum up to one.\n",
      "λ(d, q) =\n",
      "es(d,q)\n",
      "P\n",
      "d∈Dq es(d,q)\n",
      "(24)\n",
      "RRF (Reciprocal Rank Fusion) is an ensemble technique\n",
      "that synthesizes multiple retrieval result rankings into a co-\n",
      "hesive, unified list [54]. It employs a tailored weighted aver-\n",
      "aging approach to enhance collective predictive performance\n",
      "and ranking precision. The method’s strength is its dynamic\n",
      "weight assignment, which is informed by the interplay among\n",
      "branches. RRF is especially potent in scenarios characterized\n",
      "by model or source heterogeneity, where it can markedly\n",
      "amplify the accuracy of predictions.\n",
      "V. RAG FLOW AND FLOW PATTERN\n",
      "The collaboration between operators forms the workflow\n",
      "of the module, which we refer to as RAG flow F\n",
      "=\n",
      "(Mϕ1, . . . , Mϕn), where ϕ stands for the set of module param-\n",
      "eters. A modular rag flow can be decomposed into a graph of\n",
      "sub-functions. Through control logic, the operators can execute\n",
      "in a predetermined pipeline, while also performing conditional,\n",
      "branching or looping when necessary. In the simplest case. the\n",
      "graph is a linear chain.\n",
      "After conducting an in-depth analysis of current RAG meth-\n",
      "ods, we have identified a set of common RAG flow patterns,\n",
      "denoted as P. These patterns transcend various application\n",
      "domains and demonstrate a high level of consistency and\n",
      "reusability, revealing the prevalent structures and behaviors in\n",
      "process design. A RAG flow pattern can be defined as P =\n",
      "{Mϕ1 : {Op1} →Mϕ2 : {Op2} →. . . →Mϕn : {Opn}}\n",
      "A. Linear Pattern\n",
      "The modules in the modular RAG system are organized in\n",
      "a linear way, and can be described as Algorithm 1.\n",
      "Plinear = {M1 →M2 →. . . →Mn}\n",
      "(25)\n",
      "10\n",
      "Fig. 4.\n",
      "Linear RAG flow pattern. Each module is processed in a fixed\n",
      "sequential order.\n",
      "Fig. 5. RRR [24] is a typical linear flow that introduces a learnable query\n",
      "rewrite module before retrieval. This module employs reinforcement based on\n",
      "the output results of the LLM.\n",
      "The linear flow pattern is the simplest and most com-\n",
      "monly used pattern. As shown in Figure 4, the full linear\n",
      "RAG flow pattern mainly includes pre-retrieval processing,\n",
      "retrieval, post-retrieval processing, and generation modules.\n",
      "Plinearfull\n",
      "= {Mindexing\n",
      "→Mpre-retrieval\n",
      "→Mretrieval\n",
      "→\n",
      "Mpost-retrieval →Mgenerate}. If there are no pre-retrieval and\n",
      "post-retrieval modules, it follows the Naive RAG paradigm.\n",
      "Algorithm 1 Linear RAG Flow Pattern\n",
      "Require: original query q, documents D, retriever R, lan-\n",
      "guage model LLM, pre-processing function fpre, post-\n",
      "processing function fpost\n",
      "Ensure: final output ˆy\n",
      "1: Initialize:\n",
      "2: q′ ←fpre(q) // Pre-process the original query\n",
      "3: Dq′ ←R(q′, D) // Retrieve documents related to the pre-\n",
      "processed query\n",
      "4: ˆDq′ ←fpost(q′, Dq′) // Post-process the retrieved docu-\n",
      "ments\n",
      "5: ˆy ←LLM([q, ˆDq′]) // Generate output using the lan-\n",
      "guage model with the original query and post-processed\n",
      "documents\n",
      "6: return ˆy // Return the final output\n",
      "Common linear RAG flow involves a query transform\n",
      "module (such as rewrite or HyDE operators) at the pre-retrieval\n",
      "stage and utilize rerank at the post-retrieval stage. Rewrite-\n",
      "Retrieve-Read (RRR) [24] is a typical linear structure. As\n",
      "illustrated in Figure 5, the query rewrite module frewrite is a\n",
      "smaller trainable language model fine-tuned on T5-large, and\n",
      "in the context of reinforcement learning, the optimization of\n",
      "the rewriter is formalized as a Markov decision process, with\n",
      "the final output of the LLM serving as the reward. The retriever\n",
      "utilizes a sparse encoding model, BM25.\n",
      "B. Conditional Pattern\n",
      "The RAG flow with conditional structure involves select-\n",
      "ing different RAG pipeline based on different conditions,\n",
      "as illustrated in Figure 6. A detailed definition is shown in\n",
      "Algorithm 2. Typically, pipleline selection is accomplished\n",
      "Fig. 6. The conditional flow pattern. There is a routing module that controls\n",
      "which RAG flow the query is directed to. Typically, different flows are used for\n",
      "various configurations to meet the general requirements of the RAG system.\n",
      "Fig. 7.\n",
      "Pre-retrieval branching flow pattern.Each branch performs retrieval\n",
      "and generation separately, and then they are aggregated at the end.\n",
      "through a routing module that determines the next module\n",
      "in the flow.\n",
      "Pconditional = {Mi\n",
      "fr\n",
      "−→Mj ∨Mk}\n",
      "(26)\n",
      "Where\n",
      "fr\n",
      "−→represents that based on routing function fr(·), the\n",
      "flow can go to module Mj or Mk.\n",
      "Algorithm 2 Conditional RAG Flow Pattern\n",
      "Require: original query q, documents D, language model\n",
      "LM, retriever R, routing function fr\n",
      "Ensure: final output ˆy\n",
      "1: Initialize:\n",
      "2: q′ ←QueryTransform(q) // Pre-process the initial query\n",
      "if needed\n",
      "3: D′ ←R(q′, D) // Retrieve or update documents related\n",
      "to the query\n",
      "4: Mnext ←fr(q′, D′) // Determine the next module using\n",
      "the routing function\n",
      "5: if Mnext = Mj then\n",
      "6:\n",
      "ˆy ←Mj(q′, D′) // Execute module Mj\n",
      "7: else if Mnext = Mk then\n",
      "8:\n",
      "ˆy ←Mk(q′, D′) Mk\n",
      "9: end if\n",
      "10: return ˆy\n",
      "Pipeline selection is determined by the nature of the ques-\n",
      "tion, directing different flows tailored to specific scenarios. For\n",
      "example, the tolerance for responses generated by LLMs varies\n",
      "across questions related to serious issues, political matters,\n",
      "or entertainment topics. These routing flow often diverge in\n",
      "terms of retrieval sources, retrieval processes, configurations,\n",
      "models, and prompts.\n",
      "11\n",
      "Fig. 8. Post-retrieval branching flow pattern.Only one retrieval performed, and\n",
      "then generation is carried out separately for each retrieved document chunks,\n",
      "followed by aggregation.\n",
      "C. Branching\n",
      "In many cases, the RAG flow system may have multiple\n",
      "parallel running branches , usually to increase the diver-\n",
      "sity of generated results. Assuming multiple branches bi are\n",
      "generated in module B\n",
      "= Msplit(·) = {b1, b2, . . . , bm}.\n",
      "For each branch bi ∈B, the same or different RAG pro-\n",
      "cesses can be executed, passing through multiple processing\n",
      "modules {M1, M2, . . . , Mk} to obtain branch output result\n",
      "pi\n",
      "= Mik(. . . Mi2(Mi1(bi)) . . .). The results of multiple\n",
      "branches are aggregated using an aggregation function to\n",
      "obtain intermediate output results. ˆO = Mmerge({pi | bi ∈\n",
      "B}). However, aggregation is not necessarily the end of the\n",
      "RAG flow, as it can continue to connect to other modules,\n",
      "Mjn(. . . Mj2(Mj1( ˆO)) . . .). For example, after aggregating\n",
      "multiple model responses, they can continue through a val-\n",
      "idation module. Therefore, the entire branch flow pattern can\n",
      "be represented as:\n",
      "Pbranch =Mjn(. . . Mj1(Mmerge({Mik\n",
      "(. . . Mi1(bi) . . .) | bi ∈Msplit(q)})) . . .)\n",
      "(27)\n",
      "Algorithm 3 Pre-retrieval Branching Flow Pattern\n",
      "Require: original query q, documents D, query expand mod-\n",
      "ule Mexpand, retriever Mretrieve, language model LLM,\n",
      "merge module Mmerge\n",
      "Ensure: final output ˆy\n",
      "1: Initialize:\n",
      "2: Q′ ←Mexpand(q) // Expand the original query to multiple\n",
      "sub-queries\n",
      "3: for all q′\n",
      "i ∈Q′ do\n",
      "4:\n",
      "D′\n",
      "i ←Mretrieve(q′\n",
      "i, D) // Retrieve documents for each\n",
      "sub-query\n",
      "5:\n",
      "Gi ←∅// Initialize an empty set for generated results\n",
      "of the sub-query\n",
      "6:\n",
      "for all d′\n",
      "ij ∈D′\n",
      "i do\n",
      "7:\n",
      "yij ←LLM([q′\n",
      "i, d′\n",
      "ij]) // Generate results for each\n",
      "document of the sub-query\n",
      "8:\n",
      "Oi ←Oi ∪{yij} // Add generated results to the set\n",
      "9:\n",
      "end for\n",
      "10:\n",
      "ˆy ←Mmerge(Oi) // Merge generated results of the sub-\n",
      "query into the final result\n",
      "11: end for\n",
      "12: return ˆy\n",
      "The RAG flow with a branching structure differs from\n",
      "the conditional approach in that it involves multiple parallel\n",
      "branches, as opposed to selecting one branch from multiple\n",
      "options in the conditional approach. Structurally, it can be\n",
      "categorized into two types, which are depicted in Figure 7\n",
      "and Figure 8.\n",
      "Pre-Retrieval Branching (Multi-Query, Parallel Retrieval).\n",
      "As shown in Algorithm 3, the process involves initially taking\n",
      "a query q and expanding it through a module Mexpand to gen-\n",
      "erate multiple sub-queries Q′. Each sub-query q′\n",
      "i is then used\n",
      "to retrieve relevant documents via Mretrieve, forming document\n",
      "sets D′\n",
      "i. These document sets, along with the corresponding\n",
      "sub-queries, are fed into a generation module Mgenerate to\n",
      "produce a set of answers Gi. Ultimately, all these generated\n",
      "answers are combined using a merging module Mmerge to\n",
      "form the final result y. This entire flow can be mathematically\n",
      "represented as:\n",
      "Pbranchpre =Mmerge(q′\n",
      "i∈Mexpand(q){Mgenerate(q′\n",
      "i, d′\n",
      "ij) |\n",
      "d′\n",
      "ij ∈Mretrieve(q′\n",
      "i)})\n",
      "(28)\n",
      "Post-Retrieval Branching (Single Query, Parallel Genera-\n",
      "tion). As shown in Algorithm 4, in the post-retrieval branching\n",
      "pattern, the process starts with a single query q which is\n",
      "used to retrieve multiple document chunks through a retrieval\n",
      "module Mretrieve, resulting in a set of documents Dq. Each\n",
      "document dq\n",
      "i from this set is then independently processed by\n",
      "a generation module Mgenerate to produce a set of generated\n",
      "results G. These results are subsequently merged using a\n",
      "merge module Mmerge to form the final result y. The process\n",
      "can be succinctly represented as y = Mmerge(Oi), where Oi is\n",
      "the collection of all generated results from each document dq\n",
      "i\n",
      "in Dq. Therefore, the entire process can be represented as:\n",
      "Pbranchpost = Mmerge({Mgenerate(dq\n",
      "i ) | dq\n",
      "i ∈Mretrieve(q)})\n",
      "(29)\n",
      "Algorithm 4 Post-retrieval Branching Flow Pattern\n",
      "Require: original query q, documents D, retriever R, lan-\n",
      "guage model LLM, merge module Mmerge\n",
      "Ensure: final output ˆy\n",
      "1: Initialize:\n",
      "2: q′ ←fpre(q) // Pre-process the original query\n",
      "3: Dq′ ←R(q′, D) // Retrieve a set of documents based on\n",
      "the pre-processed query\n",
      "4: G ←∅// Initialize an empty set to store generated results\n",
      "5: for all di ∈Dq′ do\n",
      "6:\n",
      "yi ←LLM([q, di]) // Generate results independently\n",
      "for each document chunk using the language model\n",
      "7:\n",
      "Oi ←Oi ∪{yi} // Add the generated result to the set\n",
      "of results\n",
      "8: end for\n",
      "9: ˆy ←Mmerge(Oi) // Merge all generated results using the\n",
      "merge function\n",
      "10: return ˆy\n",
      "REPLUG [55] embodies a classic post-retrieval branching\n",
      "structure, wherein the probability of each token is predicted\n",
      "for each branch. Through weighted possibility ensemble, the\n",
      "different branches are aggregated, and the final generation\n",
      "12\n",
      "Fig. 9. The RAG flow in REPLUG [55], which follows a typical post-retrieval\n",
      "branching pattern. Each retrieved chunks undergoes parallel generation, and\n",
      "then they are aggregated using a weighted probability ensemble.\n",
      "result is used to fine-tune the retriever, known as Contriever,\n",
      "through feedback.\n",
      "D. Loop Pattern\n",
      "The RAG flow with a loop structure, as an important char-\n",
      "acteristic of Modular RAG, involves interdependent retrieval\n",
      "and generation steps. It typically includes a scheduling module\n",
      "for flow control. The modular RAG system can be abstracted\n",
      "as a directed graph G = (V, E), where V is the set of vertices\n",
      "representing the various modules Mi in the system, and E is\n",
      "the set of edges representing the control flow or data flow be-\n",
      "tween modules. If there is a vertex sequence Mi1, Mi2, ..., Min\n",
      "such that Min can reach Mi1 (i.e., Min →Mi1), then this\n",
      "RAG system forms a loop. If Mj is the successor module of\n",
      "Mi and Mi decides whether to return to Mj or a previous\n",
      "module Mk through a Judge module, it can be represented\n",
      "as: Mi\n",
      "Judge\n",
      "−−−→Mj\n",
      "or\n",
      "Mi\n",
      "Judge\n",
      "−−−→Mk where Mk is the\n",
      "predecessor module of Mj. If Mi return to Mj, it can be\n",
      "represented as: ∃Judge(Mi, Mj)\n",
      "s.t.\n",
      "(Mi, Mj) ∈E\n",
      "and\n",
      "Judge(Mi, Mj) = true. If the Judge module not to return\n",
      "to any previous module, it can be represented as: ∀Mi ∈\n",
      "V,\n",
      "Judge(Mi, Mj) = false for all Mj that are predecessors\n",
      "of Mi. Loop pattern can be further categorized into iterative,\n",
      "recursive, and adaptive (active) retrieval approaches.\n",
      "Iterative retrieval At times, a single retrieval and genera-\n",
      "tion may not effectively address complex questions requiring\n",
      "extensive knowledge. Therefore, an iterative approach can be\n",
      "used in RAG (see Algorithm 5), typically involving a fixed\n",
      "number of iterations for retrieval. At step t, given the query\n",
      "qt and the previous output sequence y<t = [y0, . . . , yt−1] ,\n",
      "iterations proceed under the condition that t is less than the\n",
      "maximum allowed iterations T. In each loop, it retrieves a\n",
      "document chunks Dt−1 using the last output yt−1 and the\n",
      "current query qt. Subsequently, a new output yt is generated.\n",
      "The continuation of the iteration is determined by a Judge\n",
      "module, which makes its decision based on the yt, y<t, qt,\n",
      "and the Dt−1.\n",
      "An\n",
      "exemplary\n",
      "case\n",
      "of\n",
      "iterative\n",
      "retrieval\n",
      "is\n",
      "ITER-\n",
      "RETGEN [56] (Figure 11), which iterates retrieval-augmented\n",
      "generation and generation-augmented retrieval. Retrieval-\n",
      "augmented generation outputs a response to a task input based\n",
      "on all retrieved knowledge. In each iteration, ITER-RETGEN\n",
      "leverages the model output from the previous iteration as a\n",
      "specific context to help retrieve more relevant knowledge.\n",
      "Fig. 10. Loop flow pattern. Typically, a RAG system performs multiple rounds\n",
      "of retrieval and generation. It can be categorized into three forms: iterative,\n",
      "recursive, and adaptive.\n",
      "Algorithm 5 Iterative RAG Flow Pattern\n",
      "Require: original query q, documents D, maximum iterative\n",
      "times T, language model LLM, retriever R, initial output\n",
      "y<1 = ∅\n",
      "Ensure: final output ˆy\n",
      "1: Initialize:\n",
      "2: qt ←q // Initialize query for the first iteration\n",
      "3: y<1 ←∅// Initialize previous outputs as empty\n",
      "4: t ←1 // Initialize iteration step\n",
      "5: while t ≤T do\n",
      "6:\n",
      "qt ←QueryTransform(y<t−1, qt−1) // Generate query\n",
      "based on previous output and original query\n",
      "7:\n",
      "Dt ←R(yt−1||qt, D) // Retrieve or update documents\n",
      "related to the current query\n",
      "8:\n",
      "yt ←LLM([y<t−1, qt, Dt]) // Generate output using\n",
      "the language model\n",
      "9:\n",
      "y<t ←[y<t−1, yt] // Update the list of previous outputs\n",
      "10:\n",
      "if Judge(yt, q) = false then\n",
      "11:\n",
      "break\n",
      "12:\n",
      "end if\n",
      "13:\n",
      "t ←t + 1 // Increment iteration step\n",
      "14: end while\n",
      "15: yfinal = synthesizeOutput(y≤t) // Synthesize final output\n",
      "from the list of outputs\n",
      "16: return ˆy\n",
      "13\n",
      "Fig. 11. ITER-RETGEN [56] is a typical iterative structure. Multiple rounds\n",
      "of retrieval and generation are performed within the limit of the maximum\n",
      "number of iterations.\n",
      "Termination of the loop is determined by a predefined number\n",
      "of iterations.\n",
      "Recursive retrieval The characteristic feature of recursive\n",
      "retrieval (see Algorithm 6), as opposed to iterative retrieval, is\n",
      "its clear dependency on the previous step and its continuous\n",
      "deepening of retrieval. Typically, it follows a tree-like structure\n",
      "and there is a clear termination mechanism as an exit condition\n",
      "for recursive retrieval. In RAG systems, recursive retrieval usu-\n",
      "ally involves query transform, relying on the newly rewritten\n",
      "query for each retrieval.\n",
      "Algorithm 6 Recursive RAG Flow Pattern\n",
      "Require: initial query q, document D, retriever R, language\n",
      "model LM, maximum recursive depth Kmax\n",
      "Ensure: final output ˆy\n",
      "1: Initialize:\n",
      "2:\n",
      "Q ←{q}\n",
      "3:\n",
      "k ←0 // Initialize recursion depth\n",
      "4: while Q ̸= ∅and k < Kmax do\n",
      "5:\n",
      "Q′ ←∅// To store queries for the next recursion level\n",
      "6:\n",
      "for all q ∈Q do\n",
      "7:\n",
      "Dq ←R(q, D) // Retrieve or update documents\n",
      "related to the current query\n",
      "8:\n",
      "Y\n",
      "←LM([q, Dq]) // Generate outputs using the\n",
      "language model\n",
      "9:\n",
      "Q′′ ←deriveNewQueries(q, Dq, Y ) // Derive new\n",
      "queries from generated outputs\n",
      "10:\n",
      "for all q′ ∈Q′′ do\n",
      "11:\n",
      "if q′ /∈Q′ and q′ /∈Q then\n",
      "12:\n",
      "Q′ ←Q′ ∪{q′}\n",
      "13:\n",
      "end if\n",
      "14:\n",
      "end for\n",
      "15:\n",
      "end for\n",
      "16:\n",
      "Q ←Q′ // Update the set of queries for the next\n",
      "recursion\n",
      "17:\n",
      "k ←k + 1 // Increment recursion depth\n",
      "18: end while\n",
      "19: ˆy = synthesizeOutput(Y ) // Synthesize final output from\n",
      "generated outputs\n",
      "20: return ˆy\n",
      "A typical implementation of recursive retrieval, such as\n",
      "ToC [13] (see Figure 12 ), involves recursively executing RAC\n",
      "(Recursive Augmented Clarification) to gradually insert sub-\n",
      "nodes into the clarification tree from the initial ambiguous\n",
      "question (AQ). At each expansion step, paragraph re-ranking\n",
      "is performed based on the current query to generate a disam-\n",
      "Fig. 12.\n",
      "RAG flow of ToC [13]. A typical characteristic of this process is\n",
      "that each recursive retrieval uses the new query generated from the previous\n",
      "step, thereby progressively deepening analysis of the original complex query.\n",
      "biguous Question (DQ). The exploration of the tree concludes\n",
      "upon reaching the maximum number of valid nodes or the\n",
      "maximum depth. Once the clarification tree is constructed,\n",
      "ToC gathers all valid nodes and generates a comprehensive\n",
      "long-text answer to address AQ.\n",
      "Adaptive (Active) retrieval With the advancement of RAG,\n",
      "there has been a gradual shift beyond passive retrieval to the\n",
      "emergence of adaptive retrieval (see Algorithm 7) , also known\n",
      "as active retrieval, which is partly attributed to the powerful\n",
      "capabilities of LLM. This shares a core concept with LLM\n",
      "Agent [57]. RAG systems can actively determine the timing\n",
      "of retrieval and decide when to conclude the entire process and\n",
      "produce the final result. Based on the criteria for judgment,\n",
      "this can be further categorized into Prompt-base and Tuning-\n",
      "base approaches.\n",
      "Algorithm 7 Active RAG Flow Pattern\n",
      "Require: original query Q, documents D, maximum iterative\n",
      "times T, language model LLM, retriever R\n",
      "Ensure: final output ˆy\n",
      "1: Initialize:\n",
      "2: t ←1 // Initialize loop step\n",
      "3: qt ←q // Initialize query for the first iteration\n",
      "4: y<1 ←∅// Initialize previous outputs as empty\n",
      "5: while t ≤T do\n",
      "6:\n",
      "Qt ←QueryTransform(y<t−1, qt−1) // Derive new\n",
      "query from previous output and query\n",
      "7:\n",
      "if Evaluate(Qt, y<t−1) then\n",
      "8:\n",
      "Dt ←R(qt, D) // Retrieve documents based on the\n",
      "new query\n",
      "9:\n",
      "yt ←LLM([qt, Dt]) // Generate output using the\n",
      "language model\n",
      "10:\n",
      "else\n",
      "11:\n",
      "yt ←∅// Set output as empty if query evaluation is\n",
      "false\n",
      "12:\n",
      "end if\n",
      "13:\n",
      "y<t ←[y<t−1, yt] // Update the list of previous outputs\n",
      "14:\n",
      "if isOutputAcceptable(yt, y<t, qt) = false then\n",
      "15:\n",
      "break // Break if the output is not acceptable\n",
      "16:\n",
      "end if\n",
      "17:\n",
      "t ←t + 1 // Increment iteration step\n",
      "18: end while\n",
      "19: ˆy = synthesizeOutput(y≤t) // Synthesize final output from\n",
      "the list of outputs\n",
      "20: return ˆy\n",
      "Prompt-base. The prompt-base approach involves control-\n",
      "ling the flow using Prompt Engineering to direct LLM. A\n",
      "14\n",
      "Fig. 13. RAG flow of FLARE [14]. The generated provisional answer will\n",
      "undergo confidence assessment. If it does not meet the required confidence\n",
      "level, the process will return to the retrieval stage and generate anew. The\n",
      "assessment criteria are implemented through prompt\n",
      "Fig. 14.\n",
      "RAG flow of SELF-RAG [28]. First, it prompt GPT-4 to obtain\n",
      "a suitable instruct fine-tuning dataset to fine-tune the deployed open-source\n",
      "LLM. This allows the model to output four specific tokens during generation,\n",
      "which are used to control the RAG process.\n",
      "typical implementation example is FLARE [14]. Its core\n",
      "concept is that LLMs should only retrieve when essential\n",
      "knowledge is lacking, to avoid unnecessary or inappropriate\n",
      "retrieval in an enhanced LM. FLARE iteratively generates the\n",
      "next provisional sentence and checks for the presence of low-\n",
      "probability tokens. If found, the system retrieves relevant docu-\n",
      "ments and regenerates the sentence. Tuning-base. The tuning-\n",
      "based approach involves fine-tuning LLM to generate special\n",
      "tokens, thereby triggering retrieval or generation. This concept\n",
      "can be traced back to Toolformer [50], where the generation of\n",
      "specific content assists in invoking tools. In RAG systems, this\n",
      "approach is used to control both retrieval and generation steps.\n",
      "A typical case is Self-RAG [28](see Figure 14). Given an\n",
      "input prompt and the preceding generation result, first predict\n",
      "whether the special token Retrieve is helpful for enhancing\n",
      "the continued generation through retrieval. Then, if retrieval\n",
      "is needed, the model generates a critique token to evaluate the\n",
      "retrieved passage’s relevance. and a critique token to evaluate\n",
      "if the information in the response is supported by the retrieved\n",
      "passage. Finally, a critique token evaluates the overall utility of\n",
      "the response and selects the optimal result as the final output.\n",
      "E. Tuning Pattern\n",
      "RAG is continuously integrating with more LLM-related\n",
      "technologies. In Modular RAG, many components are com-\n",
      "posed of trainable language models. Through fine-tuning, the\n",
      "performance of the components and the compatibility with\n",
      "the overall flow can be further optimized. This section will\n",
      "introduce three main patterns of fine-tuning stages, namely\n",
      "retriever fine-tuning, generator fine-tuning, and dual fine-\n",
      "tuning.\n",
      "Fig. 15.\n",
      "Retriever fine-tuning pattern, mainly includes direct SFT, adding\n",
      "trainable adapter, LM-supervised retrieval and LLM Reward RL.\n",
      "1) Retriever FT: In the RAG flow, common methods for\n",
      "fine-tuning the retriever is shown in Figure 15 ,which include:\n",
      "• Direct supervised fine-tuning of the retriever. Construct-\n",
      "ing a specialized dataset for retrieval and fine-tuning the\n",
      "dense retriever. For example, using open-source retrieval\n",
      "datasets or constructing one based on domain-specific\n",
      "data.\n",
      "• Adding trainable adapter modules. Sometimes, direct\n",
      "fine-tuning of the API-base embedding model (e.g., Ope-\n",
      "nAI Ada-002 and Cohere) is not feasible. Incorporating\n",
      "an adapter module can enhance the representation of\n",
      "your data. Additionally, the adapter module facilitates\n",
      "better alignment with downstream tasks, whether for task-\n",
      "specific (e.g., PRCA [42]) or general purposes (e.g.,\n",
      "AAR [58]).\n",
      "• LM-supervised Retrieval (LSR). Fine-tuning the retriever\n",
      "based on the results generated by LLM.\n",
      "• LLM Reward RL. Still using the LLM output results as\n",
      "the supervisory signal. Employing reinforcement learning\n",
      "to align the retriever with the generator. The whole re-\n",
      "trieval process is disassembled in the form of a generative\n",
      "Markov chain.\n",
      "2) Generator FT: The primary methods for fine-tuning a\n",
      "generator in RAG flow is shown in Figure 16, which include:\n",
      "• Direct supervised fine-tuning. Fine-tuning through an\n",
      "external dataset can supplement the generator with ad-\n",
      "ditional knowledge. Another benefit is the ability to\n",
      "customize input and output formats. By setting the Q&A\n",
      "format, LLM can understand specific data formats and\n",
      "output according to instructions.\n",
      "• Distillation. When using on-premise deployment of open-\n",
      "source models, a simple and effective Optimization\n",
      "method is to use GPT-4 to batch construct fine-tuning\n",
      "data to enhance the capabilities of the open-source model.\n",
      "• RL from LLM/human feedback. Reinforcement learning\n",
      "based on feedback from the final generated answers. In\n",
      "addition to using human evaluations, powerful LLMs can\n",
      "also serve as an evaluative judge.\n",
      "3) Dual FT: In the RAG system, fine-tuning both the\n",
      "retriever and the generator simultaneously is a unique feature\n",
      "of the RAG system. It is important to note that the emphasis\n",
      "of system fine-tuning is on the coordination between the\n",
      "retriever and the generator. An exemplary implementation is\n",
      "RA-DIT [27], which fine-tunes both the LLM and the retriever.\n",
      "The LM-ft component updates the LLM to maximize the\n",
      "15\n",
      "Fig. 16.\n",
      "Generator fine-tuning pattern, The main methods include SFT,\n",
      "distillation and RL from LLM/human feedback.\n",
      "Fig. 17.\n",
      "Dual fine-tuning pattern. In this mode, both the retriever and\n",
      "generator participate in fine-tuning, and their preferences will be aligned.\n",
      "likelihood of the correct answer given the retrieval-augmented\n",
      "instructions while the R-ft component updates the retriever\n",
      "to minimize the KL-Divergence between the retriever score\n",
      "distribution and the LLM preference.\n",
      "VI. DISCUSSION\n",
      "In this chapter, we explore the innovative horizons opened\n",
      "by the modular RAG paradigm. We examine its compatibility\n",
      "with cutting-edge methodologies in the progression of RAG\n",
      "technology, emphasizing its scalability. It not only fosters a\n",
      "fertile ground for model innovation but also paves the way for\n",
      "seamless adaptation to the dynamic requirements of various\n",
      "applications.\n",
      "A. Opportunities in Modular RAG\n",
      "The benefits of Modular RAG are evident, providing a\n",
      "fresh and comprehensive perspective on existing RAG-related\n",
      "work. Through modular organization, relevant technologies\n",
      "and methods are clearly summarized.\n",
      "From a research perspective. Modular RAG is highly\n",
      "scalable, it empowers researchers to introduce innovative mod-\n",
      "ules and operators, leveraging a deep understanding of RAG’s\n",
      "evolving landscape. This flexibility enables the exploration of\n",
      "new theoretical and practical dimensions in the field.\n",
      "From an application perspective. The modularity of RAG\n",
      "systems simplifies their design and implementation. Users can\n",
      "tailor RAG flows to fit their specific data, use cases, and\n",
      "downstream tasks, enhancing the adaptability of the system\n",
      "to diverse requirements. Developers can draw from existing\n",
      "flow architectures and innovate by defining new flows and\n",
      "patterns that are tailored to various application contexts and\n",
      "domains. This approach not only streamlines the development\n",
      "process but also enriches the functionality and versatility of\n",
      "RAG applications.\n",
      "B. Compatibility with new methods\n",
      "Modular RAG paradigm demonstrates exceptional compati-\n",
      "bility with new developments. To gain a deeper understanding\n",
      "of this, we list three typical scalability cases, which clearly\n",
      "shows that Modular RAG paradigm provides robust support\n",
      "and flexibility for the innovation and development of RAG\n",
      "technology.\n",
      "1) Recombination of the current modules: In this scenario,\n",
      "no new modules or operators are proposed; rather, specific\n",
      "problems are addressed through the combination of existing\n",
      "modules.DR-RAG [59] employs a two-stage retrieval strategy\n",
      "and classifier selection mechanism, incorporating a branching\n",
      "retrieval structure. In the first stage, retrieving chunks relevant\n",
      "to the query. In the second stage, the query is combined\n",
      "individually with each chunk retrieved in the first stage, and a\n",
      "parallel secondary retrieval is conducted. The retrieved content\n",
      "is then input into a classifier to filter out the most relevant\n",
      "dynamic documents. This ensures that the retrieved documents\n",
      "are highly relevant to the query while reducing redundant\n",
      "information. DR-RAG improved retrieval method significantly\n",
      "enhances the accuracy and efficiency of answers, bolstering\n",
      "RAG’s performance in multi-hop question-answering scenar-\n",
      "ios.\n",
      "2) New flow without adding new operators.: This refers\n",
      "to redesigning the processes for retrieval and generation to\n",
      "address more complex scenarios without proposing new mod-\n",
      "ules. The core idea of PlanRAG [18] lies in its introduction of\n",
      "a preliminary planning stage, a crucial step that occurs before\n",
      "retrieval and generation. Initially, the system employs a judge\n",
      "module to assess whether the current context necessitates the\n",
      "formulation of a new plan or adjustments to an existing one.\n",
      "When encountering a problem for the first time, the system\n",
      "initiates the planning process, while in subsequent interactions,\n",
      "it decides whether to execute re-planning based on previous\n",
      "plans and retrieved data.\n",
      "Next, the system devises an execution plan tailored to the\n",
      "query, treating this process as a logical decomposition of\n",
      "complex queries. Specifically, PlanRAG uses a query expan-\n",
      "sion module to extend and refine the query. For each derived\n",
      "sub-query, the system conducts targeted retrieval. Following\n",
      "retrieval, another judge module evaluates the current results to\n",
      "decide whether further retrieval is required or if it should return\n",
      "to the planning stage for re-planning. Through this strategy,\n",
      "PlanRAG is able to handle complex decision-making problems\n",
      "that require multi-step data analysis more efficiently.\n",
      "3) New flow derived from new operators.: New operators\n",
      "often introduce novel flow design, exemplified by Multi-Head\n",
      "RAG [60]. Existing RAG solutions do not focus on queries that\n",
      "may require retrieving multiple documents with significantly\n",
      "different content. Such queries are common but difficult to\n",
      "handle because embeddings of these documents may be far\n",
      "apart in the embedding space. Multi-Head RAG addresses this\n",
      "by designing a new retriever that uses the activations of the\n",
      "multi-head attention layers of the Transformer, rather than the\n",
      "decoder layers, as keys for retrieving multifaceted documents.\n",
      "Different attention heads can learn to capture different aspects\n",
      "of the data. By using the corresponding activation results,\n",
      "embeddings that represent different aspects of the data items\n",
      "and the query can be generated, thereby enhancing the retrieval\n",
      "accuracy for complex queries.\n",
      "16\n",
      "VII. CONCLUSION\n",
      "RAG is emerging as a pivotal technology for LLM applica-\n",
      "tions. As technological landscapes evolve and the intricacies of\n",
      "application requirements escalate, RAG systems are being en-\n",
      "hanced by integrating a diverse suite of technologies, thereby\n",
      "achieving a higher level of complexity and functionality. This\n",
      "paper introduces the innovative paradigm of Modular RAG.\n",
      "This approach systematically disassembles the complex archi-\n",
      "tecture of RAG systems into well-defined, discrete functional\n",
      "modules. Each module is meticulously characterized by its\n",
      "specific operational functions, ensuring clarity and precision.\n",
      "Therefore, the entire system is composed of those modules\n",
      "and operators, akin to Lego bricks. By conducting an in-\n",
      "depth analysis of numerous studies, the paper also distills\n",
      "common RAG design patterns and scrutinizes key case studies\n",
      "to illustrate these patterns in practice.\n",
      "Modular RAG not only offers a structured framework for\n",
      "the design and application of RAG systems but also en-\n",
      "ables a scenario-based customization of these systems. The\n",
      "modularity inherent in this design facilitates ease of tracking\n",
      "and debugging, significantly enhancing the maintainability and\n",
      "scalability of RAG systems. Furthermore, Modular RAG opens\n",
      "up new avenues for the future progression of RAG technology.\n",
      "It encourages the innovation of novel functional modules and\n",
      "the crafting of innovative workflows, thereby driving forward\n",
      "the frontiers of RAG systems.\n",
      "REFERENCES\n",
      "[1] Y. Zhang, Y. Li, L. Cui, D. Cai, L. Liu, T. Fu, X. Huang, E. Zhao,\n",
      "Y. Zhang, Y. Chen et al., “Siren’s song in the ai ocean: A survey on hal-\n",
      "lucination in large language models,” arXiv preprint arXiv:2309.01219,\n",
      "2023.\n",
      "[2] Y. Gao, Y. Xiong, X. Gao, K. Jia, J. Pan, Y. Bi, Y. Dai, J. Sun, and\n",
      "H. Wang, “Retrieval-augmented generation for large language models:\n",
      "A survey,” arXiv preprint arXiv:2312.10997, 2023.\n",
      "[3] Z. Xu, M. J. Cruz, M. Guevara, T. Wang, M. Deshpande, X. Wang,\n",
      "and Z. Li, “Retrieval-augmented generation with knowledge graphs\n",
      "for customer service question answering,” in Proceedings of the 47th\n",
      "International ACM SIGIR Conference on Research and Development in\n",
      "Information Retrieval, 2024, pp. 2905–2909.\n",
      "[4] C. Zhang, S. Wu, H. Zhang, T. Xu, Y. Gao, Y. Hu, and E. Chen,\n",
      "“Notellm: A retrievable large language model for note recommendation,”\n",
      "in Companion Proceedings of the ACM on Web Conference 2024, 2024,\n",
      "pp. 170–179.\n",
      "[5] R. Anantha, T. Bethi, D. Vodianik, and S. Chappidi, “Context tuning\n",
      "for retrieval augmented generation,” arXiv preprint arXiv:2312.05708,\n",
      "2023.\n",
      "[6] Y. Gao, T. Sheng, Y. Xiang, Y. Xiong, H. Wang, and J. Zhang, “Chat-\n",
      "rec: Towards interactive and explainable llms-augmented recommender\n",
      "system,” arXiv preprint arXiv:2303.14524, 2023.\n",
      "[7] J. Liu, “Building production-ready rag applications,” https://www.ai.\n",
      "engineer/summit/schedule/building-production-ready-rag-applications,\n",
      "2023.\n",
      "[8] D. S. Asudani, N. K. Nagwani, and P. Singh, “Impact of word embedding\n",
      "models on text analytics in deep learning environment: a review,”\n",
      "Artificial intelligence review, vol. 56, no. 9, pp. 10 345–10 425, 2023.\n",
      "[9] F. Cuconasu, G. Trappolini, F. Siciliano, S. Filice, C. Campagnano,\n",
      "Y. Maarek, N. Tonellotto, and F. Silvestri, “The power of noise:\n",
      "Redefining retrieval for rag systems,” arXiv preprint arXiv:2401.14887,\n",
      "2024.\n",
      "[10] W. Peng, G. Li, Y. Jiang, Z. Wang, D. Ou, X. Zeng, E. Chen et al.,\n",
      "“Large language model based long-tail query rewriting in taobao search,”\n",
      "arXiv preprint arXiv:2311.03758, 2023.\n",
      "[11] Y. Xi, J. Lin, W. Liu, X. Dai, W. Zhang, R. Zhang, R. Tang, and\n",
      "Y. Yu, “A bird’s-eye view of reranking: from list level to page level,”\n",
      "in Proceedings of the Sixteenth ACM International Conference on Web\n",
      "Search and Data Mining, 2023, pp. 1075–1083.\n",
      "[12] Z. Feng, X. Feng, D. Zhao, M. Yang, and B. Qin, “Retrieval-\n",
      "generation synergy augmented large language models,” arXiv preprint\n",
      "arXiv:2310.05149, 2023.\n",
      "[13] G. Kim, S. Kim, B. Jeon, J. Park, and J. Kang, “Tree of clarifica-\n",
      "tions: Answering ambiguous questions with retrieval-augmented large\n",
      "language models,” arXiv preprint arXiv:2310.14696, 2023.\n",
      "[14] Z. Jiang, F. F. Xu, L. Gao, Z. Sun, Q. Liu, J. Dwivedi-Yu, Y. Yang,\n",
      "J. Callan, and G. Neubig, “Active retrieval augmented generation,” arXiv\n",
      "preprint arXiv:2305.06983, 2023.\n",
      "[15] D. Edge, H. Trinh, N. Cheng, J. Bradley, A. Chao, A. Mody, S. Truitt,\n",
      "and J. Larson, “From local to global: A graph rag approach to query-\n",
      "focused summarization,” arXiv preprint arXiv:2404.16130, 2024.\n",
      "[16] Q. Leng, K. Uhlenhuth, and A. Polyzotis, “Best practices for\n",
      "llm evaluation of rag applications,” https://www.databricks.com/blog/\n",
      "LLM-auto-eval-best-practices-RAG, 2023.\n",
      "[17] X. Wang, Z. Wang, X. Gao, F. Zhang, Y. Wu, Z. Xu, T. Shi, Z. Wang,\n",
      "S. Li, Q. Qian et al., “Searching for best practices in retrieval-augmented\n",
      "generation,” arXiv preprint arXiv:2407.01219, 2024.\n",
      "[18] M. Lee, S. An, and M.-S. Kim, “Planrag: A plan-then-retrieval aug-\n",
      "mented generation for generative large language models as decision\n",
      "makers,” arXiv preprint arXiv:2406.12430, 2024.\n",
      "[19] D. Arora, A. Kini, S. R. Chowdhury, N. Natarajan, G. Sinha, and\n",
      "A. Sharma, “Gar-meets-rag paradigm for zero-shot information re-\n",
      "trieval,” arXiv preprint arXiv:2310.20158, 2023.\n",
      "[20] P. Lewis, E. Perez, A. Piktus, F. Petroni, V. Karpukhin, N. Goyal,\n",
      "H. K¨uttler, M. Lewis, W.-t. Yih, T. Rockt¨aschel et al., “Retrieval-\n",
      "augmented generation for knowledge-intensive nlp tasks,” Advances in\n",
      "Neural Information Processing Systems, vol. 33, pp. 9459–9474, 2020.\n",
      "[21] S. Borgeaud, A. Mensch, J. Hoffmann, T. Cai, E. Rutherford, K. Milli-\n",
      "can, G. B. Van Den Driessche, J.-B. Lespiau, B. Damoc, A. Clark et al.,\n",
      "“Improving language models by retrieving from trillions of tokens,” in\n",
      "International conference on machine learning. PMLR, 2022, pp. 2206–\n",
      "2240.\n",
      "[22] G. Izacard, P. Lewis, M. Lomeli, L. Hosseini, F. Petroni, T. Schick,\n",
      "J. Dwivedi-Yu, A. Joulin, S. Riedel, and E. Grave, “Few-shot\n",
      "learning with retrieval augmented language models,” arXiv preprint\n",
      "arXiv:2208.03299, 2022.\n",
      "[23] H. Trivedi, N. Balasubramanian, T. Khot, and A. Sabharwal, “Interleav-\n",
      "ing retrieval with chain-of-thought reasoning for knowledge-intensive\n",
      "multi-step questions,” arXiv preprint arXiv:2212.10509, 2022.\n",
      "[24] X. Ma, Y. Gong, P. He, H. Zhao, and N. Duan, “Query rewrit-\n",
      "ing for retrieval-augmented large language models,” arXiv preprint\n",
      "arXiv:2305.14283, 2023.\n",
      "[25] N. Anderson, C. Wilson, and S. D. Richardson, “Lingua: Addressing\n",
      "scenarios for live interpretation and automatic dubbing,” in Proceedings\n",
      "of the 15th Biennial Conference of the Association for Machine\n",
      "Translation in the Americas (Volume 2: Users and Providers Track and\n",
      "Government Track), J. Campbell, S. Larocca, J. Marciano, K. Savenkov,\n",
      "and A. Yanishevsky, Eds.\n",
      "Orlando, USA: Association for Machine\n",
      "Translation in the Americas, Sep. 2022, pp. 202–209. [Online].\n",
      "Available: https://aclanthology.org/2022.amta-upg.14\n",
      "[26] L. Luo, Y.-F. Li, G. Haffari, and S. Pan, “Reasoning on graphs: Faith-\n",
      "ful and interpretable large language model reasoning,” arXiv preprint\n",
      "arXiv:2310.01061, 2023.\n",
      "[27] X. V. Lin, X. Chen, M. Chen, W. Shi, M. Lomeli, R. James, P. Rodriguez,\n",
      "J. Kahn, G. Szilvasy, M. Lewis et al., “Ra-dit: Retrieval-augmented dual\n",
      "instruction tuning,” arXiv preprint arXiv:2310.01352, 2023.\n",
      "[28] A. Asai, Z. Wu, Y. Wang, A. Sil, and H. Hajishirzi, “Self-rag: Learning\n",
      "to retrieve, generate, and critique through self-reflection,” arXiv preprint\n",
      "arXiv:2310.11511, 2023.\n",
      "[29] Y. Huang and J. Huang, “A survey on retrieval-augmented text gen-\n",
      "eration for large language models,” arXiv preprint arXiv:2404.10981,\n",
      "2024.\n",
      "[30] Y. Hu and Y. Lu, “Rag and rau: A survey on retrieval-augmented\n",
      "language model in natural language processing,” arXiv preprint\n",
      "arXiv:2404.19543, 2024.\n",
      "[31] Y. Ding, W. Fan, L. Ning, S. Wang, H. Li, D. Yin, T.-S. Chua, and\n",
      "Q. Li, “A survey on rag meets llms: Towards retrieval-augmented large\n",
      "language models,” arXiv preprint arXiv:2405.06211, 2024.\n",
      "[32] P. Zhao, H. Zhang, Q. Yu, Z. Wang, Y. Geng, F. Fu, L. Yang, W. Zhang,\n",
      "and B. Cui, “Retrieval-augmented generation for ai-generated content:\n",
      "A survey,” arXiv preprint arXiv:2402.19473, 2024.\n",
      "[33] S.\n",
      "Yang,\n",
      "“Advanced\n",
      "rag\n",
      "01:\n",
      "Small-to-\n",
      "big\n",
      "retrieval,”\n",
      "https://towardsdatascience.com/\n",
      "advanced-rag-01-small-to-big-retrieval-172181b396d4, 2023.\n",
      "17\n",
      "[34] Y. Wang, N. Lipka, R. A. Rossi, A. Siu, R. Zhang, and T. Derr,\n",
      "“Knowledge graph prompting for multi-document question answering,”\n",
      "arXiv preprint arXiv:2308.11730, 2023.\n",
      "[35] D. Zhou, N. Sch¨arli, L. Hou, J. Wei, N. Scales, X. Wang, D. Schu-\n",
      "urmans, C. Cui, O. Bousquet, Q. Le et al., “Least-to-most prompting\n",
      "enables complex reasoning in large language models,” arXiv preprint\n",
      "arXiv:2205.10625, 2022.\n",
      "[36] S. Dhuliawala, M. Komeili, J. Xu, R. Raileanu, X. Li, A. Celikyilmaz,\n",
      "and J. Weston, “Chain-of-verification reduces hallucination in large\n",
      "language models,” arXiv preprint arXiv:2309.11495, 2023.\n",
      "[37] L. Gao, X. Ma, J. Lin, and J. Callan, “Precise zero-shot dense retrieval\n",
      "without relevance labels,” arXiv preprint arXiv:2212.10496, 2022.\n",
      "[38] H. S. Zheng, S. Mishra, X. Chen, H.-T. Cheng, E. H. Chi, Q. V. Le,\n",
      "and D. Zhou, “Take a step back: Evoking reasoning via abstraction in\n",
      "large language models,” arXiv preprint arXiv:2310.06117, 2023.\n",
      "[39] H. Cao, “Recent advances in text embedding: A comprehensive review\n",
      "of top-performing methods on the mteb benchmark,” arXiv preprint\n",
      "arXiv:2406.01607, 2024.\n",
      "[40] BAAI, “Flagembedding,” https://github.com/FlagOpen/FlagEmbedding,\n",
      "2023.\n",
      "[41] Z. Li, X. Zhang, Y. Zhang, D. Long, P. Xie, and M. Zhang, “Towards\n",
      "general text embeddings with multi-stage contrastive learning,” arXiv\n",
      "preprint arXiv:2308.03281, 2023.\n",
      "[42] H. Yang, Z. Li, Y. Zhang, J. Wang, N. Cheng, M. Li, and J. Xiao,\n",
      "“Prca: Fitting black-box large language models for retrieval question an-\n",
      "swering via pluggable reward-driven contextual adapter,” arXiv preprint\n",
      "arXiv:2310.18347, 2023.\n",
      "[43] N. F. Liu, K. Lin, J. Hewitt, A. Paranjape, M. Bevilacqua, F. Petroni, and\n",
      "P. Liang, “Lost in the middle: How language models use long contexts,”\n",
      "arXiv preprint arXiv:2307.03172, 2023.\n",
      "[44] Y. Lyu, Z. Li, S. Niu, F. Xiong, B. Tang, W. Wang, H. Wu, H. Liu,\n",
      "T. Xu, and E. Chen, “Crud-rag: A comprehensive chinese benchmark\n",
      "for retrieval-augmented generation of large language models,” arXiv\n",
      "preprint arXiv:2401.17043, 2024.\n",
      "[45] L. Xia, J. Xu, Y. Lan, J. Guo, and X. Cheng, “Learning maximal\n",
      "marginal relevance model via directly optimizing diversity evaluation\n",
      "measures,” in Proceedings of the 38th international ACM SIGIR con-\n",
      "ference on research and development in information retrieval, 2015, pp.\n",
      "113–122.\n",
      "[46] Cohere, “Say goodbye to irrelevant search results: Cohere rerank is\n",
      "here,” https://txt.cohere.com/rerank/, 2023.\n",
      "[47] H. Jiang, Q. Wu, X. Luo, D. Li, C.-Y. Lin, Y. Yang, and L. Qiu,\n",
      "“Longllmlingua: Accelerating and enhancing llms in long context sce-\n",
      "narios via prompt compression,” arXiv preprint arXiv:2310.06839, 2023.\n",
      "[48] R. Litman, O. Anschel, S. Tsiper, R. Litman, S. Mazor, and R. Man-\n",
      "matha, “Scatter: selective context attentional scene text recognizer,” in\n",
      "proceedings of the IEEE/CVF conference on computer vision and pattern\n",
      "recognition, 2020, pp. 11 962–11 972.\n",
      "[49] J. Cui, Z. Li, Y. Yan, B. Chen, and L. Yuan, “Chatlaw: Open-source\n",
      "legal large language model with integrated external knowledge bases,”\n",
      "arXiv preprint arXiv:2306.16092, 2023.\n",
      "[50] T. Schick, J. Dwivedi-Yu, R. Dess`ı, R. Raileanu, M. Lomeli, L. Zettle-\n",
      "moyer, N. Cancedda, and T. Scialom, “Toolformer: Language models\n",
      "can teach themselves to use tools,” arXiv preprint arXiv:2302.04761,\n",
      "2023.\n",
      "[51] L. Ouyang, J. Wu, X. Jiang, D. Almeida, C. Wainwright, P. Mishkin,\n",
      "C. Zhang, S. Agarwal, K. Slama, A. Ray et al., “Training language\n",
      "models to follow instructions with human feedback,” Advances in neural\n",
      "information processing systems, vol. 35, pp. 27 730–27 744, 2022.\n",
      "[52] S. J. Semnani, V. Z. Yao, H. C. Zhang, and M. S. Lam, “Wikichat:\n",
      "Stopping the hallucination of large language model chatbots by few-\n",
      "shot grounding on wikipedia,” arXiv preprint arXiv:2305.14292, 2023.\n",
      "[53] J.\n",
      "Baek,\n",
      "S.\n",
      "Jeong,\n",
      "M.\n",
      "Kang,\n",
      "J.\n",
      "C.\n",
      "Park,\n",
      "and\n",
      "S.\n",
      "J.\n",
      "Hwang,\n",
      "“Knowledge-augmented language model verification,” arXiv preprint\n",
      "arXiv:2310.12836, 2023.\n",
      "[54] G. V. Cormack, C. L. Clarke, and S. Buettcher, “Reciprocal rank\n",
      "fusion outperforms condorcet and individual rank learning methods,”\n",
      "in Proceedings of the 32nd international ACM SIGIR conference on\n",
      "Research and development in information retrieval, 2009, pp. 758–759.\n",
      "[55] W. Shi, S. Min, M. Yasunaga, M. Seo, R. James, M. Lewis, L. Zettle-\n",
      "moyer, and W.-t. Yih, “Replug: Retrieval-augmented black-box language\n",
      "models,” arXiv preprint arXiv:2301.12652, 2023.\n",
      "[56] Z. Shao, Y. Gong, Y. Shen, M. Huang, N. Duan, and W. Chen,\n",
      "“Enhancing retrieval-augmented large language models with iterative\n",
      "retrieval-generation synergy,” arXiv preprint arXiv:2305.15294, 2023.\n",
      "[57] S. Hong, X. Zheng, J. Chen, Y. Cheng, J. Wang, C. Zhang, Z. Wang,\n",
      "S. K. S. Yau, Z. Lin, L. Zhou et al., “Metagpt: Meta programming for\n",
      "multi-agent collaborative framework,” arXiv preprint arXiv:2308.00352,\n",
      "2023.\n",
      "[58] Z. Yu, C. Xiong, S. Yu, and Z. Liu, “Augmentation-adapted retriever\n",
      "improves generalization of language models as generic plug-in,” arXiv\n",
      "preprint arXiv:2305.17331, 2023.\n",
      "[59] Z. Hei, W. Wei, W. Ou, J. Qiao, J. Jiao, Z. Zhu, and G. Song,\n",
      "“Dr-rag: Applying dynamic document relevance to retrieval-augmented\n",
      "generation for question-answering,” arXiv preprint arXiv:2406.07348,\n",
      "2024.\n",
      "[60] M. Besta, A. Kubicek, R. Niggli, R. Gerstenberger, L. Weitzen-\n",
      "dorf, M. Chi, P. Iff, J. Gajda, P. Nyczyk, J. M¨uller et al., “Multi-\n",
      "head rag: Solving multi-aspect problems with llms,” arXiv preprint\n",
      "arXiv:2406.05085, 2024.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(docs[0].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bb309ef2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Document(metadata={'Entry ID': 'http://arxiv.org/abs/2407.21059v1', 'Published': datetime.date(2024, 7, 26), 'Title': 'Modular RAG: Transforming RAG Systems into LEGO-like Reconfigurable Frameworks', 'Authors': 'Yunfan Gao, Yun Xiong, Meng Wang, Haofen Wang'}, page_content='Retrieval-augmented Generation (RAG) has markedly enhanced the capabilities\\nof Large Language Models (LLMs) in tackling knowledge-intensive tasks. The\\nincreasing demands of application scenarios have driven the evolution of RAG,\\nleading to the integration of advanced retrievers, LLMs and other complementary\\ntechnologies, which in turn has amplified the intricacy of RAG systems.\\nHowever, the rapid advancements are outpacing the foundational RAG paradigm,\\nwith many methods struggling to be unified under the process of\\n\"retrieve-then-generate\". In this context, this paper examines the limitations\\nof the existing RAG paradigm and introduces the modular RAG framework. By\\ndecomposing complex RAG systems into independent modules and specialized\\noperators, it facilitates a highly reconfigurable framework. Modular RAG\\ntranscends the traditional linear architecture, embracing a more advanced\\ndesign that integrates routing, scheduling, and fusion mechanisms. Drawing on\\nextensive research, this paper further identifies prevalent RAG\\npatterns-linear, conditional, branching, and looping-and offers a comprehensive\\nanalysis of their respective implementation nuances. Modular RAG presents\\ninnovative opportunities for the conceptualization and deployment of RAG\\nsystems. Finally, the paper explores the potential emergence of new operators\\nand paradigms, establishing a solid theoretical foundation and a practical\\nroadmap for the continued evolution and practical deployment of RAG\\ntechnologies.')]\n"
     ]
    }
   ],
   "source": [
    "# 논문 요약만 조회\n",
    "summary_docs = loader.get_summaries_as_docs()\n",
    "print(summary_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fce9a191",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Entry ID': 'http://arxiv.org/abs/2407.21059v1',\n",
       " 'Published': datetime.date(2024, 7, 26),\n",
       " 'Title': 'Modular RAG: Transforming RAG Systems into LEGO-like Reconfigurable Frameworks',\n",
       " 'Authors': 'Yunfan Gao, Yun Xiong, Meng Wang, Haofen Wang'}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary_docs[0].metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cdcac9ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieval-augmented Generation (RAG) has markedly enhanced the capabilities\n",
      "of Large Language Models (LLMs) in tackling knowledge-intensive tasks. The\n",
      "increasing demands of application scenarios have driven the evolution of RAG,\n",
      "leading to the integration of advanced retrievers, LLMs and other complementary\n",
      "technologies, which in turn has amplified the intricacy of RAG systems.\n",
      "However, the rapid advancements are outpacing the foundational RAG paradigm,\n",
      "with many methods struggling to be unified under the process of\n",
      "\"retrieve-then-generate\". In this context, this paper examines the limitations\n",
      "of the existing RAG paradigm and introduces the modular RAG framework. By\n",
      "decomposing complex RAG systems into independent modules and specialized\n",
      "operators, it facilitates a highly reconfigurable framework. Modular RAG\n",
      "transcends the traditional linear architecture, embracing a more advanced\n",
      "design that integrates routing, scheduling, and fusion mechanisms. Drawing on\n",
      "extensive research, this paper further identifies prevalent RAG\n",
      "patterns-linear, conditional, branching, and looping-and offers a comprehensive\n",
      "analysis of their respective implementation nuances. Modular RAG presents\n",
      "innovative opportunities for the conceptualization and deployment of RAG\n",
      "systems. Finally, the paper explores the potential emergence of new operators\n",
      "and paradigms, establishing a solid theoretical foundation and a practical\n",
      "roadmap for the continued evolution and practical deployment of RAG\n",
      "technologies.\n"
     ]
    }
   ],
   "source": [
    "print(summary_docs[0].page_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a984953e",
   "metadata": {},
   "source": [
    "### Docling\n",
    "- IBM Research에서 개발한 오픈소스 문서처리 도구로 다양한 종류의 문서를 구조화된 데이터로 변환해 생성형 AI에서 활용할 수있도록 지원한다.\n",
    "- **주요기능**\n",
    "  - PDF, DOCX, PPTX, XLSX, HTML, 이미지 등 여러 형식을 지원\n",
    "  - PDF의 **페이지 레이아웃, 읽기 순서, 표 구조, 코드, 수식** 등을 분석하여 정확하게 읽어들인다.\n",
    "  - OCR을 지원하여 스캔된 PDF나 이미지에서 텍스트를 추출할 수있다.\n",
    "  - 읽어들인 내용을 markdown, html, json등 다양한 형식으로 출력해준다.\n",
    "- 설치 : `pip install langchain-docling ipywidgets -qU` \n",
    "- 참조\n",
    "  - docling 사이트: https://github.com/docling-project/docling\n",
    "  - 랭체인-docling https://python.langchain.com/docs/integrations/document_loaders/docling/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "406c0672-a932-4b55-bc39-1863e00ef3ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  DEPRECATION: Building 'pylatexenc' using the legacy setup.py bdist_wheel mechanism, which will be removed in a future version. pip 25.3 will enforce this behaviour change. A possible replacement is to use the standardized build interface by setting the `--use-pep517` option, (possibly combined with `--no-build-isolation`), or adding a `pyproject.toml` file to the source tree of 'pylatexenc'. Discussion can be found at https://github.com/pypa/pip/issues/6334\n"
     ]
    }
   ],
   "source": [
    "%pip install langchain-docling ipywidgets -qU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "96e423ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_docling import DoclingLoader\n",
    "from langchain_docling.loader import ExportType\n",
    "\n",
    "from huggingface_hub import login\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a639f1af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# huggingface-hub 로그인\n",
    "login(os.getenv(\"HUGGINGFACE_API_KEY\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "006cd80f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = \"papers/1.pdf\" #문서 경로. local file경로, url\n",
    "path = \"https://arxiv.org/pdf/2506.09669\"\n",
    "\n",
    "loader = DoclingLoader(file_path=path, export_type=ExportType.MARKDOWN)\n",
    "docs = loader.load()\n",
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6af181e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'source': 'https://arxiv.org/pdf/2506.09669'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs[0].metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6c6cd786-947d-49ae-933c-627ca714c06e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "## Query-Level Uncertainty in Large Language Models\n",
       "\n",
       "## Lihu Chen , Gaël Varoquaux 1 2\n",
       "\n",
       "- 1 Imperial College London, UK\n",
       "\n",
       "2 Soda, Inria Saclay, France lihu.chen@imperial.ac.uk gael.varoquaux@inria.fr\n",
       "\n",
       "## Abstract\n",
       "\n",
       "It is important for Large Language Models to be aware of the boundary of their knowledge, the mechanism of identifying known and unknown queries. This type of awareness can help models perform adaptive inference, such as invoking RAG, engaging in slow and deep thinking, or adopting the abstention mechanism, which is beneficial to the development of efficient and trustworthy AI. In this work, we propose a method to detect knowledge boundaries via Query-Level Uncertainty , which aims to determine if the model is able to address a given query without generating any tokens. To this end, we introduce a novel and training-free method called Internal Confidence , which leverages self-evaluations across layers and tokens. Empirical results on both factual QA and mathematical reasoning tasks demonstrate that our internal confidence can outperform several baselines. Furthermore, we showcase that our proposed method can be used for efficient RAG and model cascading, which is able to reduce inference costs while maintaining performance. The code is available at /github https://github.com/tigerchen52/ query\\_level\\_uncertainty\n",
       "\n",
       "## 1 Introduction\n",
       "\n",
       "Large language Models (LLMs) have their knowledge boundaries (Li et al., 2024; Yin et al., 2024; Ren et al., 2025), which means that there are certain problems that they cannot provide accurate outputs. It is crucial for LLMs to be self-aware of their limitations, i.e., know what I know and know what I don't know (Kadavath et al., 2022; Amayuelas et al., 2024).\n",
       "\n",
       "Possessing awareness of knowledge boundaries provides several advantages in developing efficient and trustworthy AI. First, if LLMs can identify known-unknown or simple-hard queries, they can smartly perform adaptive inference to balance the trade-offs between computational cost and out-\n",
       "\n",
       "Figure 1: Illustrating the difference between answerlevel and query-level uncertainty. Query-level uncertainty estimating known or unknown queries ( knowledge boundary ) before generating answers, which is useful for adaptive inference, e.g., efficient RAG and fast-slow reasoning.\n",
       "\n",
       "put quality. For queries beyond their parametric knowledge, they can choose to find relevant external knowledge via RAG (Lewis et al., 2020) or tool calls (Schick et al., 2023). When faced with hard problems, LLMs can engage in slow (or deep) thinking to improve their outputs, which is also known as test-time scaling (Snell et al., 2024; Zhang et al., 2025). Alternatively, another solution is to defer a complex problem to a larger model via model cascading (Dohan et al., 2022; Gupta et al., 2024). This adaptive inference ensures that computational resources are allocated effectively, which reduces costs while maintaining performance. Second, estimating whether a query is answerable enhances the honesty and trustworthiness of LLMs. When LLMs identify uncertain queries, they can use the abstention strategy (Wen et al., 2024) to withhold responses, which is important in high-stakes domains like healthcare (Tomani et al., 2024).\n",
       "\n",
       "In this work, we propose a new concept, QueryLevel Uncertainty , to estimate a model's knowledge with regard to a given query. The research question here is: Given a query, can we determine if the model is able to address it without generating any tokens? Most existing work focus on answerlevel uncertainty, which measures the uncertainty associated with a specific answer, helping us assess the reliability of outputs (Shorinwa et al., 2024; Vashurin et al., 2025). The main distinction here is that we shift from post-generation uncertainty to pre-generation uncertainty, which aims to measure how certain an LLM can solve this query, as shown in Figure 1.\n",
       "\n",
       "Prior studies propose learning a probe on internal states to predict uncertainties of queries (Gottesman and Geva, 2024; Kossen et al., 2024). Another branch of work attempts to teach LLMs to explicitly express 'I don't know' in their responses via fine-tuning methods (Amayuelas et al., 2024; Kapoor et al., 2024; Cohen et al., 2024; Zhang et al., 2024a). One potential issue of these studies is that they often require fine-tuning and training samples, which introduces additional overhead and may limit their generalizability. We aim to introduce a training-free approach to estimate querylevel uncertainty, which is simple yet effective.\n",
       "\n",
       "Our approach relies on self-evaluation across internal layers and tokens, which is called Internal Confidence . The proposed approach is based on a simple assumption: LLMs can self-evaluate their knowledge about a query by answering a yesno question. Inspired by the uncertainty method P(True) (Kadavath et al., 2022), we can compute the probability P(Yes) to indicate the model's confidence. To fully use latent knowledge within LLMs, we compute this kind of P(Yes) at each layer and token position. Following that, we aggregate these signals to obtain the final confidence score. This aggregation is motivated by prior work showing that leveraging logical consistency across layers can improve outputs (Burns et al., 2022; Chuang et al., 2023; Xie et al., 2024). Specifically, we perform a weighted sum across layers and tokens, and the weights are derived from attenuated encoding (Chen et al., 2023), which can control the influence of adjacent units.\n",
       "\n",
       "To validate the effectiveness of our proposed internal confidence, we conduct experiments on three datasets that cover factual QA and mathematical reasoning tasks. For comparison, we adapt the existing answer-level methods to compute the querylevel uncertainty. Experimental results demonstrate that our proposed internal confidence can distinguish known and unknown queries better than various baselines. In terms of applications, we showcase that our proposed method can help efficient\n",
       "\n",
       "RAG and model cascading. On the one hand, internal confidence can guide users to assess the tradeoffs between cost and quality when invoking additional services. On the other hand, it brings a 'benefit region', where inference overhead can be reduced without compromising performance.\n",
       "\n",
       "To conclude, we propose a simple yet effective, training-free method to estimate query-level uncertainty, which can determine if a model can address a given query without generating any tokens.\n",
       "\n",
       "## 2 Related Work\n",
       "\n",
       "## 2.1 Uncertainty Estimation\n",
       "\n",
       "Existing methods mainly focus on estimating the uncertainty of LLM-generated responses, which aim to provide a score to indicate the reliability of a query-answer pair (Geng et al., 2024; Shorinwa et al., 2024; Vashurin et al., 2025). These approaches often rely on internal states (Chen et al., 2024a) or textual responses (Kuhn et al., 2023), and commonly use calibration techniques to mitigate issues such as overconfidence (Zhang et al., 2024b) and biases (Chen et al., 2024b). Notably, these methods assess post-generation reliability, i.e., they evaluate uncertainty about a particular answer. In contrast, there is limited research on quantifying how well a model can address a query prior to token generation. For example, Gottesman and Geva (2024) propose training a lightweight probe on internal representations to estimate the model's knowledge about specific entities. Similarly, Semantic Entropy Probes (Kossen et al., 2024) suggest that internal model states can implicitly encode semantic uncertainty, even before any output is generated. To the best of our knowledge, this work is the first to formally define query-level uncertainty and investigate it systematically.\n",
       "\n",
       "## 2.2 Knowledge Boundary Detection\n",
       "\n",
       "LLMs should faithfully assess their level of confidence in answering a query. This knowledge boundary awareness (Li et al., 2024; Yin et al., 2024; Wang et al., 2024) is essential to build reliable AI systems, particularly in high-stakes domains such as healthcare and law. A pioneering study by Kadavath et al. (2022) explores whether language models can be trained to predict when they 'know' the answer to a given query, introducing the concept of 'I Know' (IK) prediction. Based on this idea, subsequent work has proposed methods to help LLMs become explicitly aware of their knowledge limitations through fine-tuning strategies (Amayuelas et al., 2024; Kapoor et al., 2024). Cohen et al. (2024) further advances this line of research by introducing a special [IDK] (' I don't know ') token into the model's vocabulary, allowing the direct expression of uncertainty in its output. Similarly, RTuning (Zhang et al., 2024a) tunes LLMs to refrain from responding to questions beyond their parametric knowledge. While these abstention-based approaches show benefits in mitigating hallucinations (Wen et al., 2024), they often require additional fine-tuning, which introduces overhead and may limit generalizability across models and tasks. In this work, we propose a training-free method to identify the knowledge boundary of an LLM, which offers a more generalizable and efficient alternative to detect the knowledge boundary of LLMs.\n",
       "\n",
       "## 3 Preliminary\n",
       "\n",
       "## 3.1 Aleatoric and Epistemic Uncertainty\n",
       "\n",
       "Uncertainty in machine learning is commonly categorized into two main types: aleatoric and epistemic uncertainty (Hora, 1996; Der Kiureghian and Ditlevsen, 2009; Hüllermeier and Waegeman, 2021). These distinctions are often overlooked in the context of LLM uncertainty estimation. Aleatoric uncertainty arises from inherent randomness in the data, such as ambiguous inputs or conflicting annotations. This type of uncertainty is irreducible, as it reflects intrinsic noise in the input data. In contrast, epistemic uncertainty stems from a lack of knowledge, often due to insufficient training data and limited model capacity. Unlike aleatoric uncertainty, epistemic uncertainty is reducible with additional data or advanced modeling. In this work, we focus specifically on epistemic uncertainty, with the goal of evaluating whether an LLM possesses sufficient knowledge to answer a given query. Although it is possible that a dataset may contain some ambiguous queries and noisy labels, we assume that the benchmark datasets used in our experiments are well-curated, and have minimal ambiguity. This assumption allows us to reasonably minimize the impact of aleatoric uncertainty, and study the epistemic uncertainty in a clear way.\n",
       "\n",
       "## 3.2 Uncertainty and Confidence\n",
       "\n",
       "In the context of LLMs, the terms uncertainty and confidence are often used interchangeably (antonyms). However, the two concepts have sub- tle differences. As noted by Lin et al. (2023), uncertainty is a holistic property of the entire predictive distribution, while confidence refers to the model's estimated confidence level associated with a specific answer. For example, given a query x = 'What is the capital of France' , estimating uncertainty requires the distribution over all possible answers, e.g., Paris, Toulouse, etc. , as explained by the semantic entropy framework (Kuhn et al., 2023). In contrast, the conditional probability P Y ( = Paris | x ) can serve as a confidence here to indicate the correctness of a specific answer. In the context of query-level uncertainty, we treat uncertainty and confidence as antonyms, as obtaining full probability distributions over all possible queries for a given model is infeasible.\n",
       "\n",
       "## 4 Problem Statement and Method\n",
       "\n",
       "In this section, we describe our problem definition and introduce our method, Internal Confidence , a score that reflects whether an LLM can address a query in its own knowledge, prior to generating tokens.\n",
       "\n",
       "## 4.1 Problem Statement\n",
       "\n",
       "Given a query (including prompt words) x = ( x , . . . , x 1 N ) , we aim to quantify the query-level uncertainty, U ( x ) , without generating an answer y . This is different from existing uncertainty methods that estimate the uncertainty associated with a specific generated answer, denoted as U ( x y , ) . We define that if an LLM can answer a query correctly in greedy decoding, the query falls within the knowledge boundary of the model, and its answer can be reliable. Otherwise, the query falls beyond the model's boundary, and it does not possess sufficient knowledge to answer it. We use this standard to evaluate the estimated query-level uncertainty, i.e., a lower uncertainty indicates a model is more likely to output the correct answer. Although different decoding strategies impact LLM outputs (Song et al., 2024), we aim to measure the internal knowledge of a model in a deterministic way.\n",
       "\n",
       "Here, we focus on queries with definite answers, which have broad applications such as factual QA and mathematical reasoning. While contentious queries with open answers are also important in areas such as politics and philosophy, they are out of the scope of this work.\n",
       "\n",
       "Figure 2: Left: the internal P(Yes) across tokens and layers. Middle: the AUC of P(Yes) across tokens and layers. Right: decay weights with different localities. Model: Llama-8B; Dataset: GSM8K validation set.\n",
       "\n",
       "## 4.2 Method\n",
       "\n",
       "Existing findings reveal that LLMs can express verbalized uncertainty in their responses (Tian et al., 2023; Xiong et al., 2024), which reflects that LLMs can evaluate the answer correctness in their own knowledge. Similarly, we can prompt an LLM to assess its confidence in answering a given query by using a yes-no format: 'Respond only with 'Yes' or 'No' to indicate whether you are capable of answering the {Query} accurately. Answer Yes or No:' . Following that, we can compute the probability P(Yes) at the last token ( x N ):\n",
       "\n",
       "<!-- formula-not-decoded -->\n",
       "\n",
       "where N is the index of the last token in the query, and L is the index of the last layer of the model. h ( L ) N ∈ R d is the hidden state and d is the dimensionality of the hidden representations. W unemb ∈ R |V|× d is the unembedding matrix that maps the hidden state h ( L ) N to logits over the vocabulary V . P(Yes) can serve as a query-level confidence score here, which is somehow correlated with verbalized uncertainty (Tian et al., 2023), but the main difference is that this method only makes a single forward pass of the query without generating any answer tokens.\n",
       "\n",
       "However, P(Yes) does fully use internal states of LLMs, which preserves rich latent information about estimating uncertainty (Azaria and Mitchell, 2023; Chen et al., 2024a). Furthermore, prior work demonstrates that using logical consistency across layers can improve outputs (Burns et al., 2022; Chuang et al., 2023; Xie et al., 2024). Therefore, we propose the Internal Confidence , which leverages latent knowledge across different layers and tokens. Let f θ denote the transformation function for computing hidden states, parameterized by θ . The hidden state for the query x n of the query at layer l is computed as:\n",
       "\n",
       "<!-- formula-not-decoded -->\n",
       "\n",
       "In total, the model contains N × L such latent representations, and we can use Equation 4.2 to compute the P(Yes) for each h ( ) l n .\n",
       "\n",
       "Figure 2a shows the average P(Yes) of Llama-8B on the mathematical queries (the validation set of GSM8K (Cobbe et al., 2021)), across layers and query tokens 1 . We observe that the probability increases gradually from low to high layers and from left to right positions, presenting diverse behaviors. If we treat each P ( Yes | h ( ) l n ) as a confidence score and evaluate Area Under the Curve (AUC), we can obtain an AUC heatmap to show how well the model can distinguish known and unknown queries. As shown in Figure 2b, the top right score is not optimal. Actually, the representation h (27) 5 can achieve the best AUC, and the performance gradually declines in regions surrounding this point. We refer to this optimal point as Decision Center . It is important to note that the location of the Decision Center is sensitive to both model architecture and task type.\n",
       "\n",
       "To improve the naive P(Yes), we can apply a weighted average centering around the decision center, which serves as an ensemble strategy to enhance calibration and expressivity (Zhang et al.,\n",
       "\n",
       "1 Here, we consider tokens after the {Query} , which means that a model has seen the entire query and is able to guess its knowledge gap.\n",
       "\n",
       "Table 1: Overall performances of different query-level uncertainty methods.\n",
       "\n",
       "|                                      | TriviaQA   | TriviaQA   | TriviaQA   | SciQ     | SciQ     | SciQ     | GSM8K    | GSM8K    | GSM8K    | Avg      | Avg      | Avg      |\n",
       "|--------------------------------------|------------|------------|------------|----------|----------|----------|----------|----------|----------|----------|----------|----------|\n",
       "| Method                               | ↑ AUC      | ↑ PRR      | ↓ ECE      | ↑ AUC    | ↑ PRR    | ↓ ECE    | ↑ AUC    | ↑ PRR    | ↓ ECE    | ↑ AUC    | ↑ PRR    | ↓ ECE    |\n",
       "| Phi-3.8B                             | Phi-3.8B   | Phi-3.8B   | Phi-3.8B   | Phi-3.8B | Phi-3.8B | Phi-3.8B | Phi-3.8B | Phi-3.8B | Phi-3.8B | Phi-3.8B | Phi-3.8B | Phi-3.8B |\n",
       "| Max ( - log p )                      | 55.5       | 10.0       | -          | 51.4     | 2.9      | -        | 55.0     | 11.3     | -        | 54.0     | 8.1      | -        |\n",
       "| Predictive Entropy                   | 58.9       | 17.9       | -          | 51.2     | 3.9      | -        | 63.6     | 25.7     | -        | 57.9     | 15.8     | -        |\n",
       "| Min-K Entropy                        | 59.9       | 20.0       | -          | 52.7     | 4.9      | -        | 60.4     | 17.9     | -        | 57.7     | 14.3     | -        |\n",
       "| Attentional Entropy                  | 60.6       | 21.4       | -          | 56.2     | 9.4      | -        | 52.4     | 4.4      | -        | 56.4     | 11.7     | -        |\n",
       "| Perplexity                           | 61.8       | 24.3       | -          | 57.7     | 16.6     | -        | 53.6     | 6.9      | -        | 57.7     | 15.9     | -        |\n",
       "| Internal Semantic Similarity         | 48.7       | -2.4       | 0.3        | 46.9     | -5.9     | 12.2     | 47.9     | -2.6     | 35.2     | 47.8     | -3.6     | 15.9     |\n",
       "| P(Yes)                               | 58.1       | 16.4       | 13.9       | 58.8     | 16.9     | 10.8     | 56.6     | 12.0     | 7.6      | 57.8     | 15.1     | 10.8     |\n",
       "| Internal Confidence ( w/ naive avg ) | 58.8       | 17.3       | 19.9       | 52.4     | 4.5      | 3.3      | 54.7     | 14.7     | 21.7     | 55.3     | 12.2     | 15.0     |\n",
       "| Internal Confidence                  | 56.2       | 13.1       | 13.9       | 57.2     | 15.2     | 8.2      | 57.2     | 12.9     | 6.0      | 56.9     | 13.7     | 9.4      |\n",
       "| Llama-8B                             | Llama-8B   | Llama-8B   | Llama-8B   | Llama-8B | Llama-8B | Llama-8B | Llama-8B | Llama-8B | Llama-8B | Llama-8B | Llama-8B | Llama-8B |\n",
       "| Max ( - log p )                      | 54.9       | 11.1       | -          | 51.4     | 1.9      | -        | 53.3     | 10.4     | -        | 53.2     | 7.8      | -        |\n",
       "| Predictive Entropy                   | 58.5       | 17.7       | -          | 51.4     | 3.2      | -        | 66.1     | 28.0     | -        | 58.7     | 16.3     | -        |\n",
       "| Min-K Entropy                        | 58.1       | 17.4       | -          | 53.5     | 7.9      | -        | 57.5     | 13.2     | -        | 56.4     | 12.8     | -        |\n",
       "| Attentional Entropy                  | 59.4       | 18.7       | -          | 57.7     | 15.2     | -        | 56.1     | 13.5     | -        | 57.7     | 15.8     | -        |\n",
       "| Perplexity                           | 58.6       | 17.1       | -          | 58.3     | 15.1     | -        | 53.2     | 4.3      | -        | 56.7     | 12.2     | -        |\n",
       "| Internal Semantic Similarity         | 44.1       | -14.4      | 24.4       | 46.1     | -7.1     | 30.8     | 52.7     | 6.7      | 45.9     | 47.6     | -4.9     | 33.7     |\n",
       "| P(Yes)                               | 66.4       | 33.0       | 27.5       | 51.3     | 2.4      | 23.7     | 62.2     | 24.8     | 11.6     | 60.0     | 20.1     | 20.9     |\n",
       "| Internal Confidence ( w/ naive avg ) | 67.2       | 34.4       | 14.9       | 58.6     | 15.4     | 21.5     | 59.1     | 18.7     | 29.2     | 61.6     | 22.8     | 21.9     |\n",
       "| Internal Confidence                  | 67.8       | 34.5       | 19.1       | 56.4     | 13.0     | 18.9     | 62.9     | 27.9     | 1.3      | 62.4     | 25.1     | 13.1     |\n",
       "| Qwen-14B                             | Qwen-14B   | Qwen-14B   | Qwen-14B   | Qwen-14B | Qwen-14B | Qwen-14B | Qwen-14B | Qwen-14B | Qwen-14B | Qwen-14B | Qwen-14B | Qwen-14B |\n",
       "| Max ( - log p )                      | 56.5       | 12.4       | -          | 54.1     | 6.9      | -        | 54.3     | 13.5     | -        | 55.0     | 10.9     | -        |\n",
       "| Predictive Entropy                   | 59.3       | 18.9       | -          | 53.2     | 6.9      | -        | 66.4     | 32.6     | -        | 59.6     | 19.5     | -        |\n",
       "| Min-K Entropy                        | 59.9       | 20.0       | -          | 55.7     | 11.3     | -        | 63.0     | 30.9     | -        | 59.5     | 20.7     | -        |\n",
       "| Attentional Entropy                  | 59.1       | 17.2       | -          | 59.4     | 19.2     | -        | 54.9     | 3.1      | -        | 57.8     | 13.2     | -        |\n",
       "| Perplexity                           | 59.1       | 17.8       | -          | 60.1     | 20.7     | -        | 54.0     | 7.3      | -        | 57.7     | 15.3     | -        |\n",
       "| Internal Semantic Similarity         | 51.0       | 2.5        | 2.0        | 45.5     | -7.7     | 14.9     | 47.5     | -4.6     | 33.1     | 48.0     | -3.3     | 16.7     |\n",
       "| P(Yes)                               | 63.2       | 25.8       | 31.9       | 61.0     | 22.4     | 23.9     | 54.7     | 7.5      | 5.8      | 59.6     | 18.6     | 20.5     |\n",
       "| Internal Confidence ( w/ naive avg ) | 63.3       | 27.6       | 8.0        | 60.5     | 20.5     | 15.3     | 61.7     | 28.4     | 36.3     | 61.8     | 25.5     | 19.9     |\n",
       "| Internal Confidence                  | 69.1       | 38.4       | 28.7       | 65.0     | 30.8     | 20.6     | 62.7     | 28.4     | 5.5      | 65.6     | 32.5     | 18.3     |\n",
       "\n",
       "2020; Stickland and Murray, 2020). We refer to this process as Internal Confidence (IC) , which can be denoted as:\n",
       "\n",
       "<!-- formula-not-decoded -->\n",
       "\n",
       "To reflect the observations that AUC performances gradually decay from the decision center, we adopt the Attenuated Encoding to compute the above two weight vectors (Chen et al., 2023)\n",
       "\n",
       "where w ( ) l n is the weight for each h ( ) l n . The equation describes a two-step aggregation process. First, we compute a weighted sum across layers for each individual token. Then, we apply a second weighted average over these token-level aggregated scores. Ideally, this process requires a layer weight matrix W layer ∈ R N × L for the first step and a token weight matrix W token ∈ R 1 × N for the second step. Through this aggregation, we are able to obtain a final confidence score.\n",
       "\n",
       "In a practical implementation, the decision center is static and fixed to the last token and last layer. However, it is possible to use a hold-out set to identify optimal positions tailored to specific models and tasks. We make this simplification to get rid of the requirement of training samples and aim to obtain better generalizability. Additionally, the layer weight vectors are shared across tokens, which means we need only two weight vectors: W layer ∈ R 1 × L and W token ∈ R 1 × N .\n",
       "\n",
       "<!-- formula-not-decoded -->\n",
       "\n",
       "where i is the index of the decision center, d i,j is the relative distance, and w &gt; 0 is a scalar parameter that controls the locality value. Locality is a metric that measures how much the weights of a weight vector are gathered in adjacent positions. Given a weight vector for the i -th position ϵ i = { ϵ i, 1 , ϵ i, 2 , ..., ϵ i,n } , the locality can be denoted as:\n",
       "\n",
       "<!-- formula-not-decoded -->\n",
       "\n",
       "Figure 2c shows the weights computed by Equation 4 with varied localities. This signifies that we can control the influence of neighboring layers and tokens during the averaging process.\n",
       "\n",
       "Our proposed internal confidence is training-free and efficient, as it requires only a single forward pass of a given query. Since model responses are usually longer than input prompts and invoking\n",
       "\n",
       "Figure 3: We use Internal Confidence of Phi-3.8B to predict whether the corresponding can distinguish known and unknown queries.\n",
       "\n",
       "external services like RAG adds significant overhead. We hope this pre-generation uncertainty can support adaptive reasoning.\n",
       "\n",
       "## 5 Experiments\n",
       "\n",
       "## 5.1 Settings\n",
       "\n",
       "Implementations We provide one positive and one negative example to prompt LLMs, and the target model should follow the examples to output answers. All LLMs use greedy decoding to have deterministic results. The decision center is fixed to the last layer and last token, and we set w = 1 0 . (Equation 4) for all models and datasets.\n",
       "\n",
       "edge and it falls in its knowledge boundary. For the first two datasets with short answers, we consider an answer to be correct if its Rouge-L (Lin and Och, 2004) of the ground truth is greater than 0.3, which is consistent with prior work (Kuhn et al., 2023). For the GSM8K dataset, we use an LLM evaluator, Mistal-Large (MistralAI, 2024), to assess both reasoning steps and final answer. After that, we can obtain a binary label for each query, which shows if a model is able to address the query.\n",
       "\n",
       "Models Three different sizes of LLMs are used in experiments: Phi-3-mini-4k-instruct (Abdin et al., 2024), Llama-3.1-8B-Instruct (Grattafiori et al., 2024), and Qwen2.5-14B-Instruct (Team, 2024). We aim to evaluate if internal confidence can be scaled to different model sizes. Note that internal confidence can be used for models without instruction tuning.\n",
       "\n",
       "Datasets We evaluate on two factual QA datasets and one mathematical reasoning dataset: TriviaQA (Joshi et al., 2017), SciQ (Welbl et al., 2017), and GSM8K (Cobbe et al., 2021). The first two tasks aim to assess factual knowledge stored in parameters, while GSM8K requires models to selfevaluate their reasoning capabilities. Ground truth of factual QA tasks is a short answer with some entity facts. GSM8k calls for a short answer, but the intermediate reasoning steps have been evaluated as well, following prior work (Kadavath et al., 2022).\n",
       "\n",
       "We ask a model to generate answers in a greedy decoding way. If the answer is aligned with ground truth, we regard that the model has sufficient knowl-\n",
       "\n",
       "Baselines We adapt existing answer-level methods to quantify the pre-generation uncertainty, e.g., logit-based uncertainty. Given a query (including prompt words) x = ( x , . . . , x 1 N ) , we can obtain a probability for each token P x ( n | x &lt;n ) by performing a forward pass. (1) The baseline Max ( -log p ) measures the query's uncertainty by assessing the least likely token in the query (Manakul et al., 2023). (2) Predictive Entropy is defined as the entropy over the entire query tokens (Malinin and Gales, 2021):\n",
       "\n",
       "<!-- formula-not-decoded -->\n",
       "\n",
       "(3) Min-K Entropy combines the thoughts of the Max ( -log p ) and predictive entropy , which select the top-K of tokens from the query with the minimum token probability (Shi et al., 2024). (4) Attentional Entropy is an adapted version of the predictive entropy by performing a weighted sum:\n",
       "\n",
       "<!-- formula-not-decoded -->\n",
       "\n",
       "where α n is the attentional weights for the token x n . The intuition here is that tokens contribute to the semantic meanings in a different way, and we should\n",
       "\n",
       "Figure 4: Left: We use estimated internal confidence scores to decide whether to invoke RAG. If the internal confidence exceeds a threshold, the model answers the query using its parametric knowledge. Otherwise, it relies on external knowledge for reasoning. The plot shows the accuracy of Phi-3.8B on the TriviaQA dataset under this setting. Right: We implement a model cascading seeting with Phi-3.8B (small) and Llama-8B (large) on the TriviaQA dataset. The internal confidence of the smaller model determines whether it answers the query or defers to the larger model when confidence is low.\n",
       "\n",
       "not treat all tokens equally (Duan et al., 2024). (5) Perplexity reflects how uncertain a model is when predicting the next token:\n",
       "\n",
       "<!-- formula-not-decoded -->\n",
       "\n",
       "(6) Internal Semantic Similarity measures the average similarity among hidden states of different layers { h (1) N , ..., h ( L ) N } , which is inspired by the lexical similarity (Fomicheva et al., 2020). (7) P(Yes) is the probability of self-evaluation, which is described in Equation 4.2. (8) Internal Confidence (w/ naive avg) is a variant of our proposed internal confidence. The distinction is we apply a naive average to aggregate all scores.\n",
       "\n",
       "observe that our proposed internal confidence can distinguish known and unknown queries better than other baselines (based on AUC and PRR) on average, especially for larger models such as Llama-8B and Qwen-14B. For example, the average AUC of Qwen-14B is 65.6, which is significantly higher than other baselines. Regarding the calibration (ECE), internal confidence can achieve lower error across models and tasks consistently. These findings indicate the effectiveness of internal confidence. Second, the variant, Internal Confidence ( w/ naive avg , leads to a decrease in general, which demonstrates that the benefit of using the attenuated encoding to obtain decay weights.\n",
       "\n",
       "Evaluation Metrics We evaluate uncertainty by assessing whether a method can distinguish known and unknown queries, which can be treated as ranking problems, i.e., a lower uncertainty means a model is more likely to know the answer to the query. Following prior work (Manakul et al., 2023; Kuhn et al., 2023), we adopt the metrics Area Under the Curve (AUC) and Prediction Rejection Ratio (PRR) (Malinin et al., 2017) to measure this. Additionally, we use the Expected Calibration Error (ECE) to assess the calibration of different methods.\n",
       "\n",
       "## 5.2 Internal Confidence Can Identify Known and Unknown Queries\n",
       "\n",
       "Table 1 shows the overall performances of various query-level uncertainty methods. First, we can\n",
       "\n",
       "Additionally, Figure 3 shows the how well the internal confidence can distinguish known and unknown queries across three tasks. While the results confirm that our training-free method can predict knowledge boundaries to some extent, there is still considerable room for improvement. We hope this initial effort encourages further research in this direction.\n",
       "\n",
       "## 5.3 Internal Confidence Makes LLM Reasoning More Efficiently\n",
       "\n",
       "Recent studies advance LLM reasoning by introducing additional resources, such as using RAG to obtain external knowledge (Lewis et al., 2020) and inference-time scaling to improve outputs (Snell et al., 2024). However, it is not always necessary to use additional resources, especially for simple queries. Here, we can use our proposed internal\n",
       "\n",
       "Figure 5: Impacts of locality on validation sets.\n",
       "\n",
       "confidence to determine when to invoke RAG, slow thinking, or model cascading.\n",
       "\n",
       "## 5.4 Locality Impacts Uncertainty Performance\n",
       "\n",
       "We conduct experiments for two scenarios: (1) Efficient RAG. Basically, the internal confidence can serve as a signal of the knowledge gaps of a model. If the score is greater than a threshold, the model is confidence to address the query. Otherwise, it requires the call of RAG. We use the TriviaQA dataset for evaluation. This dataset provides web search results for a query, which can be used as retrieved contexts for RAG. (2) Model Cascading. This task aims to achieve cost-performance trade-offs by coordinating small and large models (Dohan et al., 2022; Gupta et al., 2024). Smaller models is responsible for easy missions. If they are aware that the mission is hard to complete, it invokes a larger model. We use a two-model cascade setting with Phi-3.8B and Llama-8B on the TriviaQA dataset. Likewise, if the internal confidence of the smaller model is high, we do not invoke the larger model. Otherwise, the hard query is deferred to the larger model.\n",
       "\n",
       "Figure 4 shows the results of efficient RAG and model cascading. The trade-off region means that we can carefully select a threshold to control the call of external services, which helps strike a balance between efficiency and performance. The benefit region indicates scenarios where the use of additional resources can be reduced without compromising performance. Results across the two tasks further confirm the effectiveness of Internal Confidence in identifying knowledge gaps. Our method offers practical benefits by reducing inference overhead, which is correlated with computation time and monetary cost.\n",
       "\n",
       "We introduce attenuated encodings to aggregate probabilities centering around a decision point. The locality of the encoding may impact the performance of estimated uncertainties. To study the influence of the locality, we vary the w in Equation 4 to obtain encoding with different localities and observe how they can impact the estimations. Figure 5 shows the AUC across different datasets and models. We can observe that the locality is correlated with task types and model architecture. For example, Phi-3.8B prefers an extreme locality (1.0) while Qwen-14B has a certain optimal value around 0.8. Regarding different datasets, the influence of locality values displays slightly different behaviors. Although we may need to search an optimal locality for a specific task, we show that an empirical value with ( w = 1 0 . , Locality=0.72) can achieve competitive performances across models and datasets.\n",
       "\n",
       "## 6 Conclusion\n",
       "\n",
       "In this work, we propose a new concept called query-level uncertainty, which aims to assess whether a model can address a query without generating any tokens. To this end, we propose the approach, internal confidence, which leverages latent self-evaluation to identify the boundary of a model's knowledge. Experimental results verify the effectiveness of our approach in factual QA and mathematical reasoning. Furthermore, we apply internal confidence to two practical scenarios of adaptive inference, efficient RAG and model cascading. Our findings reveal that our method can identify two regions: a trade-off region and a benefit region. The former means that users can strike a balance between cost and quality by carefully selecting a threshold of confidence scores. The latter means that users can reduce inference overhead without compromising performance. Although our method can serve as a strong baseline for estimating querylevel uncertainty, there is still considerable room for improvement. We hope this study can stimulate future studies in this area.\n",
       "\n",
       "## References\n",
       "\n",
       "Marah Abdin, Jyoti Aneja, Hany Awadalla, Ahmed Awadallah, Ammar Ahmad Awan, Nguyen Bach, Amit Bahree, Arash Bakhtiari, Jianmin Bao, Harkirat Behl, and 1 others. 2024. Phi-3 technical report: A highly capable language model locally on your phone. arXiv preprint arXiv:2404.14219 .\n",
       "\n",
       "Alfonso Amayuelas, Kyle Wong, Liangming Pan, Wenhu Chen, and William Yang Wang. 2024. Knowledge of knowledge: Exploring known-unknowns uncertainty with large language models. In Findings of the Association for Computational Linguistics ACL 2024 , pages 6416-6432.\n",
       "\n",
       "Amos Azaria and Tom Mitchell. 2023. The internal state of an llm knows when it's lying. In Findings of the Association for Computational Linguistics: EMNLP 2023 , pages 967-976.\n",
       "\n",
       "Collin Burns, Haotian Ye, Dan Klein, and Jacob Steinhardt. 2022. Discovering latent knowledge in language models without supervision. In The Eleventh International Conference on Learning Representations .\n",
       "\n",
       "Chao Chen, Kai Liu, Ze Chen, Yi Gu, Yue Wu, Mingyuan Tao, Zhihang Fu, and Jieping Ye. 2024a. Inside: Llms' internal states retain the power of hallucination detection. In ICLR .\n",
       "\n",
       "Lihu Chen, Alexandre Perez-Lebel, Fabian Suchanek, and Gaël Varoquaux. 2024b. Reconfidencing llms from the grouping loss perspective. In Findings of the Association for Computational Linguistics: EMNLP 2024 , pages 1567-1581.\n",
       "\n",
       "Lihu Chen, Gael Varoquaux, and Fabian Suchanek. 2023. The locality and symmetry of positional encodings. In Findings of the Association for Computational Linguistics: EMNLP 2023 , pages 1431314331.\n",
       "\n",
       "Yung-Sung Chuang, Yujia Xie, Hongyin Luo, Yoon Kim, James R Glass, and Pengcheng He. 2023. Dola: Decoding by contrasting layers improves factuality in large language models. In The Twelfth International Conference on Learning Representations .\n",
       "\n",
       "Karl Cobbe, Vineet Kosaraju, Mohammad Bavarian, Mark Chen, Heewoo Jun, Lukasz Kaiser, Matthias Plappert, Jerry Tworek, Jacob Hilton, Reiichiro Nakano, and 1 others. 2021. Training verifiers to solve math word problems. arXiv preprint arXiv:2110.14168 .\n",
       "\n",
       "Roi Cohen, Konstantin Dobler, Eden Biran, and Gerard de Melo. 2024. I don't know: Explicit modeling of uncertainty with an [idk] token. Advances in Neural Information Processing Systems , 37:10935-10958.\n",
       "\n",
       "Armen Der Kiureghian and Ove Ditlevsen. 2009. Aleatory or epistemic? does it matter? Structural safety , 31(2):105-112.\n",
       "\n",
       "David Dohan, Winnie Xu, Aitor Lewkowycz, Jacob Austin, David Bieber, Raphael Gontijo Lopes, Yuhuai Wu, Henryk Michalewski, Rif A Saurous, Jascha Sohl-Dickstein, and 1 others. 2022. Language model cascades. arXiv preprint arXiv:2207.10342 .\n",
       "\n",
       "Jinhao Duan, Hao Cheng, Shiqi Wang, Alex Zavalny, Chenan Wang, Renjing Xu, Bhavya Kailkhura, and Kaidi Xu. 2024. Shifting attention to relevance: Towards the predictive uncertainty quantification of freeform large language models. In Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers) , pages 5050-5063.\n",
       "\n",
       "Marina Fomicheva, Shuo Sun, Lisa Yankovskaya, Frédéric Blain, Francisco Guzmán, Mark Fishel, Nikolaos Aletras, Vishrav Chaudhary, and Lucia Specia. 2020. Unsupervised quality estimation for neural machine translation. Transactions of the Association for Computational Linguistics , 8:539-555.\n",
       "\n",
       "Jiahui Geng, Fengyu Cai, Yuxia Wang, Heinz Koeppl, Preslav Nakov, and Iryna Gurevych. 2024. A survey of confidence estimation and calibration in large language models. In Proceedings of the 2024 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (Volume 1: Long Papers) , pages 6577-6595.\n",
       "\n",
       "Daniela Gottesman and Mor Geva. 2024. Estimating knowledge in large language models without generating a single token. In Proceedings of the 2024 Conference on Empirical Methods in Natural Language Processing , pages 3994-4019.\n",
       "\n",
       "Aaron Grattafiori, Abhimanyu Dubey, Abhinav Jauhri, Abhinav Pandey, Abhishek Kadian, Ahmad AlDahle, Aiesha Letman, Akhil Mathur, Alan Schelten, Alex Vaughan, and 1 others. 2024. The llama 3 herd of models. arXiv preprint arXiv:2407.21783 .\n",
       "\n",
       "Neha Gupta, Harikrishna Narasimhan, Wittawat Jitkrittum, Ankit Singh Rawat, Aditya Krishna Menon, and Sanjiv Kumar. 2024. Language model cascades: Token-level uncertainty and beyond. In The Twelfth International Conference on Learning Representations .\n",
       "\n",
       "Stephen C Hora. 1996. Aleatory and epistemic uncertainty in probability elicitation with an example from hazardous waste management. Reliability Engineering &amp; System Safety , 54(2-3):217-223.\n",
       "\n",
       "Eyke Hüllermeier and Willem Waegeman. 2021. Aleatoric and epistemic uncertainty in machine learning: An introduction to concepts and methods. Machine learning , 110(3):457-506.\n",
       "\n",
       "Mandar Joshi, Eunsol Choi, Daniel S Weld, and Luke Zettlemoyer. 2017. Triviaqa: A large scale distantly supervised challenge dataset for reading comprehension. In Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers) , pages 1601-1611.\n",
       "\n",
       "Saurav Kadavath, Tom Conerly, Amanda Askell, Tom Henighan, Dawn Drain, Ethan Perez, Nicholas Schiefer, Zac Hatfield-Dodds, Nova DasSarma, Eli Tran-Johnson, and 1 others. 2022. Language models (mostly) know what they know. arXiv preprint arXiv:2207.05221 .\n",
       "\n",
       "Sanyam Kapoor, Nate Gruver, Manley Roberts, Katherine M Collins, Arka Pal, Umang Bhatt, Adrian Weller, Samuel Dooley, Micah Goldblum, and Andrew Gordon Wilson. 2024. Large language models must be taught to know what they don't know. In The Thirtyeighth Annual Conference on Neural Information Processing Systems .\n",
       "\n",
       "Jannik Kossen, Jiatong Han, Muhammed Razzak, Lisa Schut, Shreshth Malik, and Yarin Gal. 2024. Semantic entropy probes: Robust and cheap hallucination detection in llms. arXiv preprint arXiv:2406.15927 .\n",
       "\n",
       "Lorenz Kuhn, Yarin Gal, and Sebastian Farquhar. 2023. Semantic uncertainty: Linguistic invariances for uncertainty estimation in natural language generation. In The Eleventh International Conference on Learning Representations .\n",
       "\n",
       "Patrick Lewis, Ethan Perez, Aleksandra Piktus, Fabio Petroni, Vladimir Karpukhin, Naman Goyal, Heinrich Küttler, Mike Lewis, Wen-tau Yih, Tim Rocktäschel, and 1 others. 2020. Retrieval-augmented generation for knowledge-intensive nlp tasks. Advances in neural information processing systems , 33:94599474.\n",
       "\n",
       "Moxin Li, Yong Zhao, Yang Deng, Wenxuan Zhang, Shuaiyi Li, Wenya Xie, See-Kiong Ng, and Tat-Seng Chua. 2024. Knowledge boundary of large language models: A survey. arXiv preprint arXiv:2412.12472 .\n",
       "\n",
       "Chin-Yew Lin and Franz Josef Och. 2004. Automatic evaluation of machine translation quality using longest common subsequence and skip-bigram statistics. In Proceedings of the 42nd annual meeting of the association for computational linguistics (ACL04) , pages 605-612.\n",
       "\n",
       "Zhen Lin, Shubhendu Trivedi, and Jimeng Sun. 2023. Generating with confidence: Uncertainty quantification for black-box large language models. Transactions on Machine Learning Research .\n",
       "\n",
       "Andrey Malinin and Mark Gales. 2021. Uncertainty estimation in autoregressive structured prediction. In International Conference on Learning Representations .\n",
       "\n",
       "Andrey Malinin, Anton Ragni, Kate Knill, and Mark Gales. 2017. Incorporating uncertainty into deep learning for spoken language assessment. In Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers) , pages 45-50.\n",
       "\n",
       "Potsawee Manakul, Adian Liusie, and Mark Gales. 2023. Selfcheckgpt: Zero-resource black-box hallucination detection for generative large language models. In Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing , pages 9004-9017.\n",
       "\n",
       "MistralAI. 2024. Mistral large: A general-purpose language model. https://mistral.ai/news/ mistral-large-2407/ .\n",
       "\n",
       "Ruiyang Ren, Yuhao Wang, Yingqi Qu, Wayne Xin Zhao, Jing Liu, Hua Wu, Ji-Rong Wen, and Haifeng Wang. 2025. Investigating the factual knowledge boundary of large language models with retrieval augmentation. In Proceedings of the 31st International Conference on Computational Linguistics , pages 3697-3715.\n",
       "\n",
       "Timo Schick, Jane Dwivedi-Yu, Roberto Dessì, Roberta Raileanu, Maria Lomeli, Eric Hambro, Luke Zettlemoyer, Nicola Cancedda, and Thomas Scialom. 2023. Toolformer: Language models can teach themselves to use tools. Advances in Neural Information Processing Systems , 36:68539-68551.\n",
       "\n",
       "Weijia Shi, Anirudh Ajith, Mengzhou Xia, Yangsibo Huang, Daogao Liu, Terra Blevins, Danqi Chen, and Luke Zettlemoyer. 2024. Detecting pretraining data from large language models. In The Twelfth International Conference on Learning Representations .\n",
       "\n",
       "Ola Shorinwa, Zhiting Mei, Justin Lidard, Allen Z Ren, and Anirudha Majumdar. 2024. A survey on uncertainty quantification of large language models: Taxonomy, open research challenges, and future directions. arXiv preprint arXiv:2412.05563 .\n",
       "\n",
       "Charlie Snell, Jaehoon Lee, Kelvin Xu, and Aviral Kumar. 2024. Scaling llm test-time compute optimally can be more effective than scaling model parameters. arXiv preprint arXiv:2408.03314 .\n",
       "\n",
       "Yifan Song, Guoyin Wang, Sujian Li, and Bill Yuchen Lin. 2024. The good, the bad, and the greedy: Evaluation of llms should not ignore non-determinism. arXiv preprint arXiv:2407.10457 .\n",
       "\n",
       "Asa Cooper Stickland and Iain Murray. 2020. Diverse ensembles improve calibration. arXiv preprint arXiv:2007.04206 .\n",
       "\n",
       "Qwen Team. 2024. Qwen2.5: A party of foundation models.\n",
       "\n",
       "Katherine Tian, Eric Mitchell, Allan Zhou, Archit Sharma, Rafael Rafailov, Huaxiu Yao, Chelsea Finn, and Christopher D Manning. 2023. Just ask for calibration: Strategies for eliciting calibrated confidence scores from language models fine-tuned with human feedback. In Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing , pages 5433-5442.\n",
       "\n",
       "Christian Tomani, Kamalika Chaudhuri, Ivan Evtimov, Daniel Cremers, and Mark Ibrahim. 2024. Uncertainty-based abstention in llms improves safety and reduces hallucinations. arXiv preprint arXiv:2404.10960 .\n",
       "\n",
       "Roman Vashurin, Ekaterina Fadeeva, Artem Vazhentsev, Lyudmila Rvanova, Daniil Vasilev, Akim Tsvigun, Sergey Petrakov, Rui Xing, Abdelrahman Sadallah, Kirill Grishchenkov, and 1 others. 2025. Benchmarking uncertainty quantification methods for large language models with lm-polygraph. Transactions of the Association for Computational Linguistics , 13:220-248.\n",
       "\n",
       "Hongru Wang, Boyang Xue, Baohang Zhou, Tianhua Zhang, Cunxiang Wang, Huimin Wang, Guanhua Chen, and Kam-fai Wong. 2024. Self-dc: When to reason and when to act? self divide-and-conquer for compositional unknown questions. arXiv preprint arXiv:2402.13514 .\n",
       "\n",
       "Johannes Welbl, Nelson F Liu, and Matt Gardner. 2017. Crowdsourcing multiple choice science questions. In Proceedings of the 3rd Workshop on Noisy Usergenerated Text , pages 94-106.\n",
       "\n",
       "Bingbing Wen, Jihan Yao, Shangbin Feng, Chenjun Xu, Yulia Tsvetkov, Bill Howe, and Lucy Lu Wang. 2024. Know your limits: A survey of abstention in large language models. arXiv preprint arXiv:2407.18418 .\n",
       "\n",
       "Zhihui Xie, Jizhou Guo, Tong Yu, and Shuai Li. 2024. Calibrating reasoning in language models with internal consistency. In The Thirty-eighth Annual Conference on Neural Information Processing Systems .\n",
       "\n",
       "Miao Xiong, Zhiyuan Hu, Xinyang Lu, YIFEI LI, Jie Fu, Junxian He, and Bryan Hooi. 2024. Can llms express their uncertainty? an empirical evaluation of confidence elicitation in llms. In The Twelfth International Conference on Learning Representations .\n",
       "\n",
       "Xunjian Yin, Xu Zhang, Jie Ruan, and Xiaojun Wan. 2024. Benchmarking knowledge boundary for large language models: A different perspective on model evaluation. In Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers) , pages 2270-2286.\n",
       "\n",
       "Hanning Zhang, Shizhe Diao, Yong Lin, Yi Fung, Qing Lian, Xingyao Wang, Yangyi Chen, Heng Ji, and Tong Zhang. 2024a. R-tuning: Instructing large language models to say 'i don't know'. In Proceedings of the 2024 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (Volume 1: Long Papers) , pages 7106-7132.\n",
       "\n",
       "Jize Zhang, Bhavya Kailkhura, and T Yong-Jin Han. 2020. Mix-n-match: Ensemble and compositional methods for uncertainty calibration in deep learning. In International conference on machine learning , pages 11117-11128. PMLR.\n",
       "\n",
       "Mozhi Zhang, Mianqiu Huang, Rundong Shi, Linsen Guo, Chong Peng, Peng Yan, Yaqian Zhou, and Xipeng Qiu. 2024b. Calibrating the confidence of large language models by eliciting fidelity. In Proceedings of the 2024 Conference on Empirical Methods in Natural Language Processing , pages 29592979.\n",
       "\n",
       "Qiyuan Zhang, Fuyuan Lyu, Zexu Sun, Lei Wang, Weixu Zhang, Wenyue Hua, Haolun Wu, Zhihan Guo, Yufei Wang, Niklas Muennighoff, and 1 others. 2025. A survey on test-time scaling in large language models: What, how, where, and how well? arXiv preprint arXiv:2503.24235 .\n",
       "\n",
       "## A Example Appendix\n",
       "\n",
       "This is an appendix."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print(docs[0].page_content)\n",
    "from IPython.display import Markdown\n",
    "\n",
    "Markdown(docs[0].page_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76d0d3eb-8af4-432f-a207-728ff62358ee",
   "metadata": {},
   "source": [
    "### UnstructuredLoader\n",
    "- 다양한 비정형 문서들을 읽어 오는 Unstrctured 를 사용해, 다양한 형식의 문서들을 load 해 RAG, 모델 파인튜닝에 적용할 수있게 한다.\n",
    "  - 지원 파일 형식: \"csv\", \"doc\", \"docx\", \"epub\", \"image\", \"md\", \"msg\", \"odt\", \"org\", \"pdf\", \"ppt\", \"pptx\", \"rtf\", \"rst\", \"tsv\", \"xlsx\"\n",
    "- **다양한 형식의 파일로 부터 text를 로딩**해야 할 경우 유용하다. \n",
    "- Local에 library를 설치해서 사용하거나,  Unstructured 가 제공하는 API service를 사용할 수 있다.\n",
    "  - https://docs.unstructured.io\n",
    "- 텍스트 파일, PDF, 이미지, HTML, XML, ms-office(word, ppt), epub 등 다양한 비정형 데이터 파일을 처리할 수 있다.\n",
    "  - 설치, 지원 문서: https://docs.unstructured.io/open-source/installation/full-installation\n",
    "  - Langchain 문서: https://python.langchain.com/docs/integrations/document_loaders/unstructured_file\n",
    "\n",
    "> - UnstructuredLoader PDF Load 시 Document 분할 기준\n",
    ">     -  문서의 구조와 콘텐츠를 기반으로 텍스트를 분할해 Document에 넣는다.\n",
    ">     -  분할 기준\n",
    ">        - 헤더(Header): 문서의 제목이나 섹션 제목 등\n",
    ">        - 본문 텍스트(NarrativeText): 일반적인 문단이나 설명문\n",
    ">        - 표(Table): 데이터가 표 형식으로 구성된 부분\n",
    ">        - 리스트(List): 순서가 있거나 없는 목록\n",
    ">        - 이미지(Image): 사진이나 그래픽 요소"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b87686d9-03d9-401a-9573-d57a2aacf965",
   "metadata": {},
   "source": [
    "#### 설치할 프로그램\n",
    "- poppler\n",
    "  - pdf 파일을 text로 변환하기 위해 필요한 프로그램\n",
    "  - windows: https://github.com/oschwartz10612/poppler-windows/releases/ 에서 최신 버전 다운로드 후 압축 풀어서 설치.\n",
    "    - 환경변수 Path에 \"설치경로\\Library\\bin\" 을 추가. (설치 후 IDE를 다시 시작한다.)\n",
    "  - macOS: `brew install poppler`\n",
    "  - Linux: `sudo apt-get install poppler-utils`\n",
    "- tesseract-ocr\n",
    "  - OCR 라이브러리로 pdf 이미지를 text로 변환하기 위해 필요한 프로그램 \n",
    "  - windows: https://github.com/UB-Mannheim/tesseract/wiki 에서 다운받아 설치. \n",
    "    - 환경변수 Path에 설치 경로(\"C:\\Program Files\\Tesseract-OCR\") 추가 한다. (설치 후 IDE를 다시 시작한다.)\n",
    "  - macOS: `brew install tesseract`\n",
    "  - linux(unbuntu): `sudo apt install tesseract-ocr`\n",
    "- 설치 할 패키지\n",
    "  - **libmagic 설치**\n",
    "      - windows: `pip install python-magic-bin -qU`\n",
    "      - macOS: `brew install libmagic`\n",
    "      - linux(ubuntu): `sudo apt-get install libmagic-dev`\n",
    "  - `pip install \"unstructured[pdf]\" -qU`\n",
    "      - 문서 형식별로 sub module을 설치한다. (pdf, docx ..)\n",
    "      - 모든 sub module 설치: `pip install unstructured[all-docs]`\n",
    "      - https://docs.unstructured.io/open-source/installation/full-installation\n",
    "  - `pip install langchain-unstructured -qU`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d98a32d3-b64c-427f-8663-86e00ee88f38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain-unstructured\n",
      "  Downloading langchain_unstructured-0.1.6-py3-none-any.whl.metadata (3.3 kB)\n",
      "Requirement already satisfied: langchain-core<0.4.0,>=0.3.6 in c:\\users\\tjddm\\miniconda3\\envs\\lang_env\\lib\\site-packages (from langchain-unstructured) (0.3.64)\n",
      "Collecting onnxruntime<=1.19.2,>=1.17.0 (from langchain-unstructured)\n",
      "  Downloading onnxruntime-1.19.2-cp312-cp312-win_amd64.whl.metadata (4.7 kB)\n",
      "Collecting unstructured-client<1,>=0.27.0 (from langchain-unstructured)\n",
      "  Downloading unstructured_client-0.36.0-py3-none-any.whl.metadata (21 kB)\n",
      "Requirement already satisfied: langsmith<0.4,>=0.3.45 in c:\\users\\tjddm\\miniconda3\\envs\\lang_env\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.6->langchain-unstructured) (0.3.45)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in c:\\users\\tjddm\\miniconda3\\envs\\lang_env\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.6->langchain-unstructured) (9.1.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\tjddm\\miniconda3\\envs\\lang_env\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.6->langchain-unstructured) (1.33)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\tjddm\\miniconda3\\envs\\lang_env\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.6->langchain-unstructured) (6.0.2)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in c:\\users\\tjddm\\miniconda3\\envs\\lang_env\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.6->langchain-unstructured) (24.2)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in c:\\users\\tjddm\\miniconda3\\envs\\lang_env\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.6->langchain-unstructured) (4.14.0)\n",
      "Requirement already satisfied: pydantic>=2.7.4 in c:\\users\\tjddm\\miniconda3\\envs\\lang_env\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.6->langchain-unstructured) (2.11.5)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\tjddm\\miniconda3\\envs\\lang_env\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.6->langchain-unstructured) (3.0.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\tjddm\\miniconda3\\envs\\lang_env\\lib\\site-packages (from langsmith<0.4,>=0.3.45->langchain-core<0.4.0,>=0.3.6->langchain-unstructured) (0.28.1)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in c:\\users\\tjddm\\miniconda3\\envs\\lang_env\\lib\\site-packages (from langsmith<0.4,>=0.3.45->langchain-core<0.4.0,>=0.3.6->langchain-unstructured) (3.10.18)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\tjddm\\miniconda3\\envs\\lang_env\\lib\\site-packages (from langsmith<0.4,>=0.3.45->langchain-core<0.4.0,>=0.3.6->langchain-unstructured) (2.32.3)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in c:\\users\\tjddm\\miniconda3\\envs\\lang_env\\lib\\site-packages (from langsmith<0.4,>=0.3.45->langchain-core<0.4.0,>=0.3.6->langchain-unstructured) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in c:\\users\\tjddm\\miniconda3\\envs\\lang_env\\lib\\site-packages (from langsmith<0.4,>=0.3.45->langchain-core<0.4.0,>=0.3.6->langchain-unstructured) (0.23.0)\n",
      "Requirement already satisfied: anyio in c:\\users\\tjddm\\miniconda3\\envs\\lang_env\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.3.45->langchain-core<0.4.0,>=0.3.6->langchain-unstructured) (4.9.0)\n",
      "Requirement already satisfied: certifi in c:\\users\\tjddm\\miniconda3\\envs\\lang_env\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.3.45->langchain-core<0.4.0,>=0.3.6->langchain-unstructured) (2025.4.26)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\tjddm\\miniconda3\\envs\\lang_env\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.3.45->langchain-core<0.4.0,>=0.3.6->langchain-unstructured) (1.0.9)\n",
      "Requirement already satisfied: idna in c:\\users\\tjddm\\miniconda3\\envs\\lang_env\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.3.45->langchain-core<0.4.0,>=0.3.6->langchain-unstructured) (3.10)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\users\\tjddm\\miniconda3\\envs\\lang_env\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.3.45->langchain-core<0.4.0,>=0.3.6->langchain-unstructured) (0.16.0)\n",
      "Collecting coloredlogs (from onnxruntime<=1.19.2,>=1.17.0->langchain-unstructured)\n",
      "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
      "Collecting flatbuffers (from onnxruntime<=1.19.2,>=1.17.0->langchain-unstructured)\n",
      "  Downloading flatbuffers-25.2.10-py2.py3-none-any.whl.metadata (875 bytes)\n",
      "Requirement already satisfied: numpy>=1.21.6 in c:\\users\\tjddm\\miniconda3\\envs\\lang_env\\lib\\site-packages (from onnxruntime<=1.19.2,>=1.17.0->langchain-unstructured) (2.3.0)\n",
      "Requirement already satisfied: protobuf in c:\\users\\tjddm\\miniconda3\\envs\\lang_env\\lib\\site-packages (from onnxruntime<=1.19.2,>=1.17.0->langchain-unstructured) (6.31.1)\n",
      "Collecting sympy (from onnxruntime<=1.19.2,>=1.17.0->langchain-unstructured)\n",
      "  Using cached sympy-1.14.0-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\tjddm\\miniconda3\\envs\\lang_env\\lib\\site-packages (from pydantic>=2.7.4->langchain-core<0.4.0,>=0.3.6->langchain-unstructured) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in c:\\users\\tjddm\\miniconda3\\envs\\lang_env\\lib\\site-packages (from pydantic>=2.7.4->langchain-core<0.4.0,>=0.3.6->langchain-unstructured) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\users\\tjddm\\miniconda3\\envs\\lang_env\\lib\\site-packages (from pydantic>=2.7.4->langchain-core<0.4.0,>=0.3.6->langchain-unstructured) (0.4.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\tjddm\\miniconda3\\envs\\lang_env\\lib\\site-packages (from requests<3,>=2->langsmith<0.4,>=0.3.45->langchain-core<0.4.0,>=0.3.6->langchain-unstructured) (3.4.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\tjddm\\miniconda3\\envs\\lang_env\\lib\\site-packages (from requests<3,>=2->langsmith<0.4,>=0.3.45->langchain-core<0.4.0,>=0.3.6->langchain-unstructured) (2.4.0)\n",
      "Collecting aiofiles>=24.1.0 (from unstructured-client<1,>=0.27.0->langchain-unstructured)\n",
      "  Downloading aiofiles-24.1.0-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting cryptography>=3.1 (from unstructured-client<1,>=0.27.0->langchain-unstructured)\n",
      "  Downloading cryptography-45.0.4-cp311-abi3-win_amd64.whl.metadata (5.7 kB)\n",
      "Requirement already satisfied: nest-asyncio>=1.6.0 in c:\\users\\tjddm\\miniconda3\\envs\\lang_env\\lib\\site-packages (from unstructured-client<1,>=0.27.0->langchain-unstructured) (1.6.0)\n",
      "Collecting pypdf>=4.0 (from unstructured-client<1,>=0.27.0->langchain-unstructured)\n",
      "  Downloading pypdf-5.6.0-py3-none-any.whl.metadata (7.2 kB)\n",
      "Collecting cffi>=1.14 (from cryptography>=3.1->unstructured-client<1,>=0.27.0->langchain-unstructured)\n",
      "  Using cached cffi-1.17.1-cp312-cp312-win_amd64.whl.metadata (1.6 kB)\n",
      "Collecting pycparser (from cffi>=1.14->cryptography>=3.1->unstructured-client<1,>=0.27.0->langchain-unstructured)\n",
      "  Using cached pycparser-2.22-py3-none-any.whl.metadata (943 bytes)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\tjddm\\miniconda3\\envs\\lang_env\\lib\\site-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.3.45->langchain-core<0.4.0,>=0.3.6->langchain-unstructured) (1.3.1)\n",
      "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime<=1.19.2,>=1.17.0->langchain-unstructured)\n",
      "  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
      "Collecting pyreadline3 (from humanfriendly>=9.1->coloredlogs->onnxruntime<=1.19.2,>=1.17.0->langchain-unstructured)\n",
      "  Downloading pyreadline3-3.5.4-py3-none-any.whl.metadata (4.7 kB)\n",
      "Collecting mpmath<1.4,>=1.1.0 (from sympy->onnxruntime<=1.19.2,>=1.17.0->langchain-unstructured)\n",
      "  Using cached mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
      "Downloading langchain_unstructured-0.1.6-py3-none-any.whl (7.0 kB)\n",
      "Downloading onnxruntime-1.19.2-cp312-cp312-win_amd64.whl (11.1 MB)\n",
      "   ---------------------------------------- 0.0/11.1 MB ? eta -:--:--\n",
      "   ---- ----------------------------------- 1.3/11.1 MB 7.4 MB/s eta 0:00:02\n",
      "   ------------------ --------------------- 5.2/11.1 MB 12.7 MB/s eta 0:00:01\n",
      "   -------------------- ------------------- 5.8/11.1 MB 9.3 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 7.3/11.1 MB 8.7 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 7.9/11.1 MB 7.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 11.1/11.1 MB 9.1 MB/s eta 0:00:00\n",
      "Downloading unstructured_client-0.36.0-py3-none-any.whl (195 kB)\n",
      "Downloading aiofiles-24.1.0-py3-none-any.whl (15 kB)\n",
      "Downloading cryptography-45.0.4-cp311-abi3-win_amd64.whl (3.4 MB)\n",
      "   ---------------------------------------- 0.0/3.4 MB ? eta -:--:--\n",
      "   ------------------------------ --------- 2.6/3.4 MB 11.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 3.4/3.4 MB 9.2 MB/s eta 0:00:00\n",
      "Using cached cffi-1.17.1-cp312-cp312-win_amd64.whl (181 kB)\n",
      "Downloading pypdf-5.6.0-py3-none-any.whl (304 kB)\n",
      "Downloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
      "Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
      "Downloading flatbuffers-25.2.10-py2.py3-none-any.whl (30 kB)\n",
      "Using cached pycparser-2.22-py3-none-any.whl (117 kB)\n",
      "Downloading pyreadline3-3.5.4-py3-none-any.whl (83 kB)\n",
      "Using cached sympy-1.14.0-py3-none-any.whl (6.3 MB)\n",
      "Using cached mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "Installing collected packages: mpmath, flatbuffers, sympy, pyreadline3, pypdf, pycparser, aiofiles, humanfriendly, cffi, cryptography, coloredlogs, unstructured-client, onnxruntime, langchain-unstructured\n",
      "\n",
      "   ----------------------------------------  0/14 [mpmath]\n",
      "   ----------------------------------------  0/14 [mpmath]\n",
      "   ----------------------------------------  0/14 [mpmath]\n",
      "   ----------------------------------------  0/14 [mpmath]\n",
      "   ----- ----------------------------------  2/14 [sympy]\n",
      "   ----- ----------------------------------  2/14 [sympy]\n",
      "   ----- ----------------------------------  2/14 [sympy]\n",
      "   ----- ----------------------------------  2/14 [sympy]\n",
      "   ----- ----------------------------------  2/14 [sympy]\n",
      "   ----- ----------------------------------  2/14 [sympy]\n",
      "   ----- ----------------------------------  2/14 [sympy]\n",
      "   ----- ----------------------------------  2/14 [sympy]\n",
      "   ----- ----------------------------------  2/14 [sympy]\n",
      "   ----- ----------------------------------  2/14 [sympy]\n",
      "   ----- ----------------------------------  2/14 [sympy]\n",
      "   ----- ----------------------------------  2/14 [sympy]\n",
      "   ----- ----------------------------------  2/14 [sympy]\n",
      "   ----- ----------------------------------  2/14 [sympy]\n",
      "   ----- ----------------------------------  2/14 [sympy]\n",
      "   ----- ----------------------------------  2/14 [sympy]\n",
      "   ----- ----------------------------------  2/14 [sympy]\n",
      "   ----- ----------------------------------  2/14 [sympy]\n",
      "   ----- ----------------------------------  2/14 [sympy]\n",
      "   ----- ----------------------------------  2/14 [sympy]\n",
      "   ----- ----------------------------------  2/14 [sympy]\n",
      "   ----- ----------------------------------  2/14 [sympy]\n",
      "   ----- ----------------------------------  2/14 [sympy]\n",
      "   ----- ----------------------------------  2/14 [sympy]\n",
      "   ----- ----------------------------------  2/14 [sympy]\n",
      "   ----- ----------------------------------  2/14 [sympy]\n",
      "   ----- ----------------------------------  2/14 [sympy]\n",
      "   ----- ----------------------------------  2/14 [sympy]\n",
      "   ----- ----------------------------------  2/14 [sympy]\n",
      "   ----- ----------------------------------  2/14 [sympy]\n",
      "   ----- ----------------------------------  2/14 [sympy]\n",
      "   ----- ----------------------------------  2/14 [sympy]\n",
      "   ----- ----------------------------------  2/14 [sympy]\n",
      "   ----- ----------------------------------  2/14 [sympy]\n",
      "   ----- ----------------------------------  2/14 [sympy]\n",
      "   ----- ----------------------------------  2/14 [sympy]\n",
      "   ----- ----------------------------------  2/14 [sympy]\n",
      "   ----- ----------------------------------  2/14 [sympy]\n",
      "   ----- ----------------------------------  2/14 [sympy]\n",
      "   ----- ----------------------------------  2/14 [sympy]\n",
      "   ----- ----------------------------------  2/14 [sympy]\n",
      "   ----- ----------------------------------  2/14 [sympy]\n",
      "   ----- ----------------------------------  2/14 [sympy]\n",
      "   ----- ----------------------------------  2/14 [sympy]\n",
      "   ----- ----------------------------------  2/14 [sympy]\n",
      "   ----- ----------------------------------  2/14 [sympy]\n",
      "   ----- ----------------------------------  2/14 [sympy]\n",
      "   ----- ----------------------------------  2/14 [sympy]\n",
      "   ----- ----------------------------------  2/14 [sympy]\n",
      "   ----- ----------------------------------  2/14 [sympy]\n",
      "   ----- ----------------------------------  2/14 [sympy]\n",
      "   ----- ----------------------------------  2/14 [sympy]\n",
      "   ----- ----------------------------------  2/14 [sympy]\n",
      "   ----- ----------------------------------  2/14 [sympy]\n",
      "   ----- ----------------------------------  2/14 [sympy]\n",
      "   ----- ----------------------------------  2/14 [sympy]\n",
      "   ----- ----------------------------------  2/14 [sympy]\n",
      "   ----- ----------------------------------  2/14 [sympy]\n",
      "   ----- ----------------------------------  2/14 [sympy]\n",
      "   ----- ----------------------------------  2/14 [sympy]\n",
      "   ----- ----------------------------------  2/14 [sympy]\n",
      "   ----- ----------------------------------  2/14 [sympy]\n",
      "   ----- ----------------------------------  2/14 [sympy]\n",
      "   ----- ----------------------------------  2/14 [sympy]\n",
      "   ----- ----------------------------------  2/14 [sympy]\n",
      "   ----- ----------------------------------  2/14 [sympy]\n",
      "   ----- ----------------------------------  2/14 [sympy]\n",
      "   ----- ----------------------------------  2/14 [sympy]\n",
      "   -------- -------------------------------  3/14 [pyreadline3]\n",
      "   -------- -------------------------------  3/14 [pyreadline3]\n",
      "   ----------- ----------------------------  4/14 [pypdf]\n",
      "   ----------- ----------------------------  4/14 [pypdf]\n",
      "   -------------- -------------------------  5/14 [pycparser]\n",
      "   -------------------- -------------------  7/14 [humanfriendly]\n",
      "   ---------------------- -----------------  8/14 [cffi]\n",
      "   ------------------------- --------------  9/14 [cryptography]\n",
      "   ------------------------- --------------  9/14 [cryptography]\n",
      "   ---------------------------- ----------- 10/14 [coloredlogs]\n",
      "   ------------------------------- -------- 11/14 [unstructured-client]\n",
      "   ------------------------------- -------- 11/14 [unstructured-client]\n",
      "   ------------------------------- -------- 11/14 [unstructured-client]\n",
      "   ------------------------------- -------- 11/14 [unstructured-client]\n",
      "   ---------------------------------- ----- 12/14 [onnxruntime]\n",
      "   ---------------------------------- ----- 12/14 [onnxruntime]\n",
      "   ---------------------------------- ----- 12/14 [onnxruntime]\n",
      "   ---------------------------------- ----- 12/14 [onnxruntime]\n",
      "   ---------------------------------- ----- 12/14 [onnxruntime]\n",
      "   ---------------------------------- ----- 12/14 [onnxruntime]\n",
      "   ---------------------------------- ----- 12/14 [onnxruntime]\n",
      "   ---------------------------------- ----- 12/14 [onnxruntime]\n",
      "   ---------------------------------- ----- 12/14 [onnxruntime]\n",
      "   ------------------------------------- -- 13/14 [langchain-unstructured]\n",
      "   ---------------------------------------- 14/14 [langchain-unstructured]\n",
      "\n",
      "Successfully installed aiofiles-24.1.0 cffi-1.17.1 coloredlogs-15.0.1 cryptography-45.0.4 flatbuffers-25.2.10 humanfriendly-10.0 langchain-unstructured-0.1.6 mpmath-1.3.0 onnxruntime-1.19.2 pycparser-2.22 pypdf-5.6.0 pyreadline3-3.5.4 sympy-1.14.0 unstructured-client-0.36.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install langchain-unstructured"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "324e4182",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a51647fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: pikepdf C++ to Python logger bridge initialized\n"
     ]
    }
   ],
   "source": [
    "from langchain_unstructured import UnstructuredLoader\n",
    "# path = \"data/olympic.txt\"\n",
    "# path = \"papers/1.pdf\"\n",
    "path = [\"data/olympic.txt\", \"papers/1.pdf\"]\n",
    "loader = UnstructuredLoader(path)\n",
    "docs = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b20ea58f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "465"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ef294226",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'source': 'papers/1.pdf',\n",
       " 'coordinates': {'points': ((70.866, 338.5113216),\n",
       "   (70.866, 403.26892159999994),\n",
       "   (290.7855161390001, 403.26892159999994),\n",
       "   (290.7855161390001, 338.5113216)),\n",
       "  'system': 'PixelSpace',\n",
       "  'layout_width': 595.276,\n",
       "  'layout_height': 841.89},\n",
       " 'file_directory': 'papers',\n",
       " 'filename': '1.pdf',\n",
       " 'languages': ['eng'],\n",
       " 'last_modified': '2025-06-13T08:54:45',\n",
       " 'page_number': 10,\n",
       " 'parent_id': 'c0ff9d37ae73259855ed24d509a77b06',\n",
       " 'filetype': 'application/pdf',\n",
       " 'category': 'NarrativeText',\n",
       " 'element_id': 'e1d2951b77c3895facdfdac2c0f93dec'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs[300].metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5bc7e7e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'각 올림픽 종목들은 IOC로부터 승인을 받은 국제경기연맹의 관리를 받는다. 35개의 연맹이 IOC에서 승인을 받았으며, 승인을 받았지만 현재 정식종목이 아닌 종목을 감독하는 연맹도 있다. IOC의 승인을 받았지만 올림픽 종목이 아닌 스포츠들은 올림픽 종목으로 고려되지는 않으나, 올림픽이 끝난 후 처음으로 열리는 IOC총회 때마다 정식종목이 되도록 신청을 할 수는 있다. IOC 총회 때 정식종목 선정은 총회에 참석중인 IOC위원들의 투표를 통해 이루어지며, 재적 위원 수의 과반수 이상 찬성표를 얻어야 정식종목으로 인정을 받는다. IOC의 승인을 받은 스포츠이나 찬성표를 받지 못해 정식종목이 되지 못한 스포츠로는 체스와 서핑과 같은 것이 있다.'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs[10].page_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e8efaff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4acfcbe1-cc26-4e87-8c41-d6fa7d461701",
   "metadata": {},
   "source": [
    "### Directory 내의 문서파일들 로딩\n",
    "- DirectoryLoader 이용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1b8eb4d8-3c1d-418d-a499-ee181d54b759",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_community.document_loaders import DirectoryLoader\n",
    "\n",
    "loader = DirectoryLoader(\n",
    "    \"data\", # 읽어들일 문서들이 있는 디렉토리.\n",
    "    recursive=True, # 하위디렉토리까지 검색할지 여부.\n",
    ")\n",
    "docs = loader.load()\n",
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "10ebc232-48ae-4cd2-ab3a-f6e26bd95ac9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "올림픽 올림픽(영어: Olympic Games, 프랑스어: Jeux olympiques)은 전 세계 각 대륙 각국에서 모인 수천 명의 선수가 참가해 여름과 겨울에 스포츠 경기를 하는 국제적인 대회이다. 전 세계에서 가장 큰 지구촌 최대의 스포츠 축제인 올림픽은 세계에서 가장 인지도있는 국제 행사이다. 올림픽은 2년마다 하계 올림픽과 동계 올림픽이 번갈아 열리며, 국제 올림픽 위원회(IOC)가 감독하고 있다. 또한 오늘날의 올림픽은 기원전 8세기부터 서기 5세기에 이르기까지 고대 그리스 올림피아에서 열렸던 올림피아 제전에서 비롯되었다. 그리고 19세기 말에 피에르 드 쿠베르탱 남작이 고대 올림피아 제전에서 영감을 얻어, 근대 올림픽을 부활시켰다. 이를 위해 쿠베르탱 남작은 1894년에 IOC를 창설했으며, 2년 뒤인 1896년에 그리스 아테네에서 제 1회 올림픽이 열렸다. 이때부터 IOC는 올림픽 운동의 감독 기구가 되었으며, 조직과 활동은 올림픽 헌장을 따른다. 오늘날 전 세계 대부분의 국가에서 올림픽 메달은 매우 큰 영예이며, 특히 올림픽 금메달리스트는 국가 영웅급의 대우를 받으며 스포츠 스타가 된다. 국가별로 올림픽 메달리스트들에게 지급하는 포상금도 크다. 대부분의 인기있는 종목들이나 일상에서 쉽게 접하고 즐길 수 있는 생활스포츠 종목들이 올림픽이라는 한 대회에서 동시에 열리고, 전 세계 대부분의 국가 출신의 선수들이 참여하는 만큼 전 세계 스포츠 팬들이 가장 많이 시청하는 이벤트이다. 2008 베이징 올림픽의 모든 종목 누적 시청자 수만 47억 명에 달하며, 이는 인류 역사상 가장 많은 수의 인구가 시청한 이벤트였다. 또한 20세기에 올림픽 운동이 발전함에 따라, IOC는 변화하는 세계의 사회 환경에 적응해야 했다. 이러한 변화의 예로는 얼음과 눈을 이용한 경기 종목을 다루는 동계 올림픽, 장애인이 참여하는 패럴림픽, 스페셜 올림픽, 데플림픽, 10대 선수들이 참여하는 유스 올림픽 등을 들 수 있다. 그 뿐만 아니라 IOC는 20세기의 변화하는 경제, 정치, 기술 환경에도 적응해야 했다. 그리하여 올림픽은 피에르 드 쿠베르탱이 기대했던 순수한 아마추어 정신에서 벗어나서, 프로 선수도 참가할 수 있게 되었다. 올림픽은 점차 대중 매체의 중요성이 커짐에 따라 올림픽의 상업화와 기업 후원을 놓고도 논란이 생겨났다. 또한 올림픽을 치르며 발생한 보이콧, 도핑, 심판 매수, 테러와 같은 수많은 일들은 올림픽이 더욱 굳건히 성장할 수 있는 원동력이 되었다. 올림픽은 국제경기연맹(IF), 국가 올림픽 위원회(NOC), 각 올림픽의 위원회(예-벤쿠버동계올림픽조직위원회)로 구성된다. 의사 결정 기구인 IOC는 올림픽 개최 도시를 선정하며, 각 올림픽 대회마다 열리는 올림픽 종목도 IOC에서 결정한다. 올림픽 경기 개최 도시는 경기 축하 의식이 올림픽 헌장에 부합하도록 조직하고 기금을 마련해야 한다. 올림픽 축하 행사로는 여러 의식과 상징을 들 수 있는데 올림픽기나 성화가 그 예이다. 올림픽은 거의 모든 국가가 참여할 정도로 규모가 커졌다. 하계 올림픽은 33개의 종목과 약 400개의 세부종목에서 13,000명이 넘는 선수들이 겨루고 그중 각 종목별 1, 2, 3위는 각각 금/은/동을 수여받는다. 전 세계 언론에서 각각 4년마다 열리는 올림픽 경기를 중계하기 때문에 이름 없는 선수가 개인적, 국가적, 세계적으로 명성을 얻을 수 있는 기회가 된다. 이와 더불어 올림픽 경기는 개최지와 개최국에게도 전 세계에 그 이름을 널리 알리는 좋은 기회가 된다.\n",
      "\n",
      "고대올림픽 고대의 올림픽 경기(올림피아 경기)는 고대 그리스의 여러 도시 국가의 대표선수들이 모여 벌인 일련의 시합이었으며, 육상 경기가 주 종목이지만 격투기와 전차 경기도 열렸다. 그리고 패배하면 죽기도 하였다. 고대 올림픽의 유래는 수수께끼로 남아있다. 잘 알려진 신화로는 헤라클레스와 그의 아버지인 제우스가 올림픽의 창시자였다는 것이다. 전설에 따르면 이 경기를 최초로 '올림픽'이라고 부르고, 4년마다 대회를 개최하는 관례를 만든 사람이 헤라클레스라고 한다. 어떤 전설에서는 헤라클레스가 이른바 헤라클레스의 12업을 달성한 뒤에 제우스를 기리고자 올림픽 경기장을 지었다고 한다. 경기장이 완성되자 헤라클레스는 일직선으로 200 걸음을 걸었으며, 이 거리를 \"스타디온\"이라 불렀는데, 후에 이것이 길이 단위인 '스타디온'(그리스어: στάδιον → 라틴어: 영어: stadium)이 되었다. 또 다른 설로는 '올림픽 휴전'(그리스어: ἐκεχειρία 에케케이리아[*])이라는 고대 그리스의 관념이 최초의 올림피아 경기와 관련이 있다고 한다. '올림픽 휴전'이란 어느 도시 국가라도 올림피아 경기 기간 중에 다른 나라를 침범하면 그에 대한 응징을 받을 수 있다는 뜻으로, \"올림픽 기간에는 전쟁하지 말 것\"으로 요약할 수 있다. 고대 올림피아 경기가 처음 열린 시점은 보통 기원전 776년으로 인정되고 있는데, 이 연대는 그리스 올림피아에서 발견된 비문에 근거를 둔 것이다. 이 비문의 내용은 달리기 경주 승자 목록이며 기원전 776년부터 4년 이후 올림피아 경기 마다의 기록이 남겨져 있다. 고대 올림픽의 종목으로는 육상, 5종 경기(원반던지기, 창던지기, 달리기, 레슬링, 멀리뛰기), 복싱, 레슬링, 승마 경기가 있었다. 전설에 따르면 엘리스의 코로이보스가 최초로 올림피아 경기에서 우승한 사람이라고 한다. 고대 올림피아 경기는 근본적으로 종교적인 중요성을 띄고 있었는데, 스포츠 경기를 할 때는 제우스(올림피아의 제우스 신전에는 페이디아스가 만든 제우스 상이 있음)와 펠롭스를 기리기 위하여 제물 봉헌 의식을 치렀다. 펠롭스는 올림피아의 전설상의 임금이었던 피사티스의 오이노마오스 왕과 전차 경주를 겨룬 영웅으로 유명한 인물이다. 올림피아 경기의 승자는 시와 조각상으로 칭송받았다. 올림피아 경기는 4년마다 열렸으며, 이 기간을 '올림피아드'(Olympiad)라고 했는데, 그리스인들은 이를 시간 단위로 이용하였다. 올림피아 경기는 고대 그리스에서 정기적으로 열렸던 범그리스 대회의 순환 대회 가운데 하나였다. 올림피아 경기는 기원전 6세기~기원전 5세기에 절정에 이르렀으나, 그 후 로마가 패권을 잡은 뒤 그리스에 영향력을 행사하면서 서서히 쇠퇴하게 된다. 고대 올림픽이 공식적으로 끝난 해는 확실히 알 수 없으나, 대부분 테오도시우스 1세 황제가 모든 이단 숭배 및 예배를 금지했던 393년을 고대 올림픽의 마지막이라고 추정한다. 다른 설에 따르면 테오도시우스의 후계자인 테오도시우스 2세가 모든 그리스 신전을 파괴하라고 명령한 426년이라고도 한다. 이렇게 올림픽이 사라진 이후로 이보다 한참 뒤인 19세기에 이르러서야 비로소 다시 올림픽 경기가 열리게 된다.\n",
      "\n",
      "근대올림픽 고대 올림피아 경기를 제대로 구현한 최초의 시도는 혁명 시대의 프랑스에서 1796년부터 1798년까지 3년동안 실시했던 프랑스 국내 올림픽인 '공화국 올림픽'(L'Olympiade de la République)이었다. 이 대회의 종목 중에는 고대 그리스 올림피아 경기 때 행한 일부 종목도 있었다. 특히 1798년 공화국 올림픽 대회는 미터법을 최초로 스포츠에 도입시킨 대회이기도 하다. 이후 52년뒤인 1850년에는 잉글랜드 슈롭셔주의 웬록에서 올림픽급의 대회가 열리기 시작하였다. 이 대회는 1859년에 아테네에서 열렸을 때 웬록 올림픽으로 명칭이 변경되었으며 지금도 열리고 있다. 브룩스 박사는 1859년에 아테네에서 열린 올림픽 경기의 내용을 이후 경기에 채택하였다. 1866년 런던의 수정궁에서는 윌리엄 페니 브룩스가 영국의 국가 올림픽 대회를 만들었다. 1821년 그리스에서는 오스만 제국의 지배에 반기를 들고 독립 전쟁이 일어나면서, 이때부터 올림픽 부활에 대한 관심이 생겨났다. 시인이자 신문 편집자였던 파나요티스 수초스(Παναγιώτης Σούτσος)는 1833년에 출간한 자신의 시 '망자(亡者)의 대화'에서 최초로 올림픽 부활에 대한 제안을 내놓았다. 그리스의 부유한 박애주의자였던 에방겔리스 자파스(Ευαγγέλης Ζάππας)는 1859년에 아테네 시 광장에서 열린 \"올림픽 경기(일명 자파스 올림픽)\"를 후원하였다. 이 경기에는 그리스와 오스만 제국 출신의 선수들이 참가하였다. 에방겔리스 자파스는 이후에도 올림픽 경기를 개최할 수 있도록 고대의 경기장이었던 파나티네코 경기장을 복원하는 데도 돈을 썼다. 파나티네코 경기장에서 1870년과 1875년에 자파스 올림픽을 개최했으며, 현대 올림픽인 2004년 하계 올림픽 때는 양궁 경기장으로도 쓰였다. 역사학자였던 쿠베르탱은 프로이센-프랑스 전쟁(1870–1871)에서 프랑스의 패배 원인을 분석하면서 군사들이 체계적인 체력 훈련을 받지 않았기 때문에 전쟁에서 패배했다고 말한 인물이다. 1890년 웬록 올림픽에 참석한 쿠베르탱은 그 이후부터 올림픽을 대규모로 부활시킬 수 있으리라 생각했다. 쿠베르탱은 웬록 올림픽과 자파스 올림픽을 토대로 하여 올림픽 경기를 국제적으로 시행하기 위해 나라별로 올림픽을 번갈아가며 개최하는 방식을 생각해냈다. 그는 이 방안을 새로 설립된 국제 올림픽 위원회(IOC)의 첫 올림픽 의회 기간 중에 언급했다. 총회는 파리의 소르본 대학교에서 1894년 6월 16일부터 6월 23일까지 7일간 지속되었으며, 총회 마지막날, 2년 후인 1896년에 아테네에서 국제적 규모의 올림픽 대회를 열기로 결정되었다. IOC는 올림픽을 조직하는 데에 모든 책임을 졌으며, 초대 위원장으로는 그리스의 작가였던 디미트리오스 비켈라스(Δημήτριος Βικέλας)가 선출되었다.\n",
      "\n",
      "하계올림픽 1859년 자파스 올림픽에 참가한 선수의 수는 250명을 넘지 못했다. 에방겔리스 자파스는 \"지난 자파스 올림픽을 포함, 1896년에 개최될 2번째 올림픽을 위해 파나티네코 경기장을 보수해야 한다.\"라는 충고를 하지만, 그리스 정부는 그의 말을 듣지 않았고 결국 1896년 아테네 올림픽 준비를 위해 파나티네코 경기장은 두 번이나 정비해야 했다. 1회 대회 정식종목으로는 9종목이 있었는데 육상, 사이클, 펜싱, 체조, 사격, 수영, 테니스, 역도, 레슬링이 있었으며, 조정도 정식종목이었으나 매우 나쁜 날씨로 인해 조정 경기는 취소되었다. 펜싱 경기는 역사적 건물인 자피온(에반젤리스 자파스의 이름을 딴 것이다)에서 열렸다. 그리스의 관리들과 국민들은 올림픽 경기 개최에 열광적이었다. 많은 선수들이 이에 동감하면서 앞으로도 올림픽 대회를 아테네에서 영구히 개최해야 한다고 요구하기까지 하였다. 그러나 국제올림픽위원회(IOC)는 근대 올림픽은 순환 개최로 열리는 세계적인 행사가 되어야 한다고 생각했다. 결국 2회 올림픽은 프랑스 파리에서 열기로 결정되었다. 1896년 올림픽 대회의 성공을 이어서 개최된 두 번째 올림픽인 1900년 올림픽에서는 올림픽의 존폐여부를 위협받는 지경에 이르게 되었다. 1900년에 파리와 1904년에 세인트루이스에서 열린 올림픽은 하필이면 엑스포와 시간과 장소가 겹치는 바람에 빛을 바래게 된다. 1904년 대회를 예로 들면 650명의 선수단이 참가했지만 그중 580명은 미국국적을 가진 사람이었다. 1900년과 1904년의 두 올림픽 대회는 역대 올림픽중에 최저점을 기록한다. 올림픽은 1906년 올림픽이 아테네에서 개최되었을 때 다시 일어서게 된다. 또 다른 성공적인 올림픽은 그리스 올림픽 협회가 조직했으며 세 차례나 올림픽을 치른 경기장에서 개최되었다. 이 경기는 비공식 올림픽이긴 했지만 세계적으로 상당한 참가자들을 불러 모았으며 대중들에게 큰 재미를 갖다주었다. 이 때를 시작으로 올림픽의 인기와 번영이 시작되었다.\n",
      "\n",
      "동계올림픽 동계 올림픽은 눈과 얼음을 이용하는 스포츠들을 모아 이루어졌으며 하계 올림픽 때 실행하기 불가능한 종목들로 구성되어 있다. 피겨스케이팅, 아이스하키는 각각 1908년과 1920년에 하계올림픽 종목으로 들어가 있었다. IOC는 다른 동계 스포츠로 구성된 새로운 대회를 만들고 싶어 했고, 로잔에서 열린 1921년 올림픽 의회에서 겨울판 올림픽을 열기로 합의했다. 1회 동계올림픽은 1924년, 프랑스의 샤모니에서 11일간 진행되었고, 16개 종목의 경기가 치러졌다. IOC는 동계 올림픽이 4년 주기로 하계 올림픽과 같은 년도에 열리도록 했다. 이 전통은 프랑스의 알베르빌에서 열린 1992년 올림픽 때까지 지속되었으나, 노르웨이의 릴레함메르에서 열린 1994년 올림픽부터 동계 올림픽은 하계 올림픽이 끝난지 2년후에 개최하였다.\n",
      "\n",
      "패럴림픽 패럴림픽(Paralympic)은 신체·감각 장애가 있는운동 선수가 참가하는 국제 스포츠 대회로, 장애인 올림픽으로 불린다. 1948년에 루드비히 구트만 경(Sir Ludwig Guttman)은 제2차 세계대전에 참전한 군인들의 사회 복귀를 위한 일환으로 1948년 런던 올림픽과 동시에 몇몇 병원들을 연합해서 여러 경기를 펼쳤다. 구트만의 세계 휠체어, 신체부자유자대회(World Wheelchair and Amputee Games)로 알려진 이 대회는 매년 열리는 스포츠대회가 되었다. 12년이 넘도록 구트만과 다른 사람들은 스포츠를 상처를 치료하는 방법 중 하나로써 계속 대회 개최에 노력을 기울였다. 로마에서 열린 1960년 하계 올림픽때 구트만은 400명의 선수들을 \"Parallel Olympics\"에 참가시켰으며 이것이 곧 1회 패럴림픽으로 알려지게 되었다. 그 때부터 패럴림픽은 하계 올림픽이 열린 년도에 열리게 되었다. 서울에서 열린 1988년 하계 올림픽부터는 하계 올림픽을 개최한 도시는 패럴림픽도 같이 개최하기로 한다.\n",
      "\n",
      "오늘날의 올림픽 1896년 대회때는 14개국에서 241명의 선수단이 참가했지만 2008년 하계 올림픽때는 204개국에서 10,500명의 선수가 참가하는 등 세계적인 대회로 변모했다. 동계 올림픽의 규모는 하계 올림픽 규모보다 작다. 예를 들면 2006 토리노 동계 대회때는 80개국에서 2,508명의 선수가 참가했으며 82개 세부종목이 있었고, 2008 베이징 하계 대회때는 204개국, 11,508명의 선수, 302개의 세부종목이 있었다. 올림픽이 진행되는 동안 선수와 임직원들은 올림픽 선수촌에서 지낸다. 올림픽 선수촌에는 선수들을 위한 개인실이 있으며 카페테리아, 헬스 클리닉, 종교적인 시설 등 최상의 편의를 위한 시설들이 있다. 올림픽에 참가하는 나라는 UN에 등록된 국가의 수 193개보다 많다. 다른 국제조직이 개최하는 대회들은 정치적 주권국으로 참가를 제한하는 반면, IOC는 그에 상관없이 올림픽에 모든 공동체들이 참가할 수 있도록 한다. 이는 연합체나 공동체에서 국가올림픽위원회(NOC)를 만드는 것을 허용한다는 의미이다. 예를 들면 푸에르토리코, 버뮤다, 홍콩과 같은 곳도 올림픽에서 다른 나라와 스포츠 경쟁을 합법적으로 할 수 있다.\n",
      "\n",
      "국제 올림픽 위원회 올림픽 활동이란 많은 수의 국가, 국제 경기 연맹과 협회 • 미디어 파트너를 맺기 • 선수, 직원, 심판, 모든 사람과 기관이 올림픽 헌장을 지키는 것을 말한다. 국제올림픽위원회(IOC)는 모든 올림픽 활동을 통솔하는 단체로서, 올림픽 개최 도시 선정, 계획 감독, 종목 변경, 스폰서 및 방송권 계약 체결 등의 권리가 있다. 올림픽 활동은 크게 세 가지로 구성된다. - 국제경기연맹(IF)은 국제적인 규모의 경기를 관리, 감독하는 기구이다. 예를 들어서 국제 축구 연맹(FIFA)는 축구를 주관하며, 국제 배구 연맹(FIVB)은 배구를 주관하는 기구이다. 올림픽에는 현재 35개의 국제경기연맹이 있고 각 종목을 대표한다. (이 중에는 올림픽 종목은 아니지만 IOC의 승인을 받은 연맹도 있다.) - 국가 올림픽 위원회(NOC)는 각국의 올림픽 활동을 감독하는 기구이다. 예를 들어서 대한 올림픽 위원회(KOC)는 대한민국의 국가 올림픽 위원회이다. 현재 IOC에 소속된 국가 올림픽 위원회는 205개이다. - 올림픽 조직 위원회(OCOG)는 임시적인 조직으로 올림픽의 총체적인 것(개막식, 페막식 등)을 책임지기 위해 구성된 조직이다. 올림픽 조직 위원회는 올림픽이 끝나면 해산되며 최종보고서를 IOC에 제출한다. 올림픽의 공식언어는 프랑스어와 영어와 개최국의 공용어이다. 모든 선언(예를 들어서 개막식 때 각국 소개를 할 때)들은 세 언어가 모두 나오거나 영어나 프랑스어 중에서 한 언어로만 말하기도 한다. 개최국의 공용어가 영어나 프랑스어가 아닐 때는 당연히 그 나라의 공용어도 함께 나온다.\n",
      "\n",
      "국제 올림픽 위원회(이하 IOC로 지칭)는 몇몇 위원들이 한 행위에 대해서 비판을 받고 있다. 그 예로 IOC 위원장이었던 에이버리 브런디지와 후안 안토니오 사마란치가 대표적인 사람이다. 브런디지는 20년 넘게 IOC 위원장직을 맡았고 임기 중에 올림픽을 정치적으로 휘말려들지 않게 하기 위해 보호했다. 그러나 그는 남아프리카 공화국 대표단에게 아파르트헤이트와 관련된 이슈를 건드리고 반유대정책을 함으로써 비난을 받았다. 사마란치 위원장 시기 때는 족벌 정치와 부패로 비난받았다. 사마란치가 스페인에서 프랑코 정권에 협력했다는 것도 비판의 이유가 되었다. 1998년에 몇몇 IOC위원들이 2002년 솔트레이크 시티 동계 올림픽 유치 과정에서 미국에게 미국을 올림픽 개최지로 뽑아달라는 뇌물청탁을 받았다는 것이 폭로되었다. 이에 IOC는 사퇴한 IOC위원 4명과 강제 퇴출된 6명에 대한 조사를 했다. 이 스캔들은 이후에 개최지 선정에서 이와 같은 불미스러운 일이 일어나지 않게 하기 위해서 IOC가 개혁에 착수하도록 하는 긍정적인 역할을 하기도 했다. BBC 다큐멘터리인 '파노라마'에서는 '매수된 올림픽'이란 주제로 2004년 8월에 방송을 내보내기도 했다. 이때 이 프로그램에서는 2012년 하계 올림픽의 개최지 선정과 관련된 뇌물에 대해서 조사했다. 이 다큐멘터리에서는 특정 후보 도시가 IOC 위원들에게 뇌물수수하는 것이 가능했다고 주장했으며, 특히 파리 시장이었던 베르트랑 들라노에(Bertrand Delanoë)는 영국의 총리인 토니 블레어와 런던올림픽유치위원회가 입후보 규정을 위반했다고 비난했다. 그는 당시 프랑스 대통령이었던 자크 시라크를 목격자로 내세웠지만 시라크 대통령은 이 분쟁에 휘말려드는 것을 주의했으며 인터뷰를 삼갔다. 결국 베르트랑 들라노에의 주장에 대한 조사는 체계적으로 이루어지지는 않았다. 2006년 동계 올림픽을 유치했던 토리노도 이 논쟁에서 빠져나갈 수 없었다. 이번에는 스위스 국적의 IOC위원 마크 호들러(Marc Hodler)가 이 논쟁의 중심이 되었는데, 이 위원은 스위스 시온의 경쟁 도시였던 토리노가 IOC위원들에게 뇌물수수를 했다고 말했고, 이 발언으로 광범위한 조사가 이루어졌다. 이 언행이 많은 IOC위원들이 시온에 대해 언짢게 생각하게 되고 토리노가 개최지로 선정되도록 도와주는 역할을 했을 가능성도 제기되고 있다.\n",
      "\n",
      "올림픽 경기 종목 올림픽 경기 종목은 총 33개부문 52개 종목에서 약 400개의 경기로 이루어져있다. 예를 들어서 하계 올림픽 부문인 레슬링은 자유형과 그레코로만형의 두 종목으로 나뉜다. 여기에서 10경기는 남자부, 4경기는 여자부로 열리며 분류기준은 체중이다. 하계 올림픽은 26개, 동계 올림픽은 7개 부문으로 이루어져있다. 하계 올림픽에서는 육상, 수영, 펜싱, 체조가 1회 대회때부터 한번도 빠짐없이 정식종목이었으며, 동계 올림픽에서는 크로스컨트리, 피겨 스케이팅, 아이스 하키, 노르딕 복합, 스키 점프, 스피드 스케이팅이 1924년 동계 올림픽부터 빠짐없이 정식종목이었다. 배드민턴, 농구, 배구와 같은 정식종목들은 처음에는 시범종목이었으며 그 후에 정식종목으로 승인 되었다. 야구처럼 예전에는 정식종목 이었지만 지금은 정식 종목에서 빠진 종목도 있다.\n",
      "\n",
      "각 올림픽 종목들은 IOC로부터 승인을 받은 국제경기연맹의 관리를 받는다. 35개의 연맹이 IOC에서 승인을 받았으며, 승인을 받았지만 현재 정식종목이 아닌 종목을 감독하는 연맹도 있다. IOC의 승인을 받았지만 올림픽 종목이 아닌 스포츠들은 올림픽 종목으로 고려되지는 않으나, 올림픽이 끝난 후 처음으로 열리는 IOC총회 때마다 정식종목이 되도록 신청을 할 수는 있다. IOC 총회 때 정식종목 선정은 총회에 참석중인 IOC위원들의 투표를 통해 이루어지며, 재적 위원 수의 과반수 이상 찬성표를 얻어야 정식종목으로 인정을 받는다. IOC의 승인을 받은 스포츠이나 찬성표를 받지 못해 정식종목이 되지 못한 스포츠로는 체스와 서핑과 같은 것이 있다.\n",
      "\n",
      "2004년 10월과 11월에 IOC는 '올림픽 프로그램 위원회'(Olympic Programme Commission)를 설립했다. 여기서는 올림픽 종목과 올림픽 종목이 아닌 스포츠를 모두 재검토하는 일을 한다. 이 위원회의 목표는 올림픽 종목에 더 체계적으로 다가가는 것이다. 위원회에서는 우선적으로 올림픽 종목으로 포함되기 위해서는 7개의 기준을 충족시켜야 한다고 말한다. 이 7개의 기준은 역사, 전통, 보편성, 인기도와 잠재성, 선수의 건강, 연맹의 스포츠를 관리할만한 능력, 스포츠를 여는 데에 필요한 비용이다. 예를 들면 2012년 하계 올림픽의 정식종목 후보에 7개 조건을 포함한 비(非)올림픽 스포츠가 올랐고 그 내용은, 골프, 가라테, 럭비, 인라인 스케이팅, 스쿼시였다. 이 스포츠들은 IOC 상임이사회에서 재검토되어 2005년 7월에 열린 싱가포르 총회에서 최종 결정하기로 했다. 결국 5개 중 2개(가라테와 스쿼시) 가 최종 후보로 올라왔으나 가라테와 스쿼시 둘 다 2/3의 미만의 찬성표로 정식종목이 되지는 못한다. 그 후 2016년 올림픽 정식종목에는 7개의 스포츠가 정식종목 신청을 했는데, 내용은 가라테, 골프, 스쿼시, 야구, 소프트볼, 7인제 럭비, 인라인 스케이팅이었다. 2009년 8월 13일, 신청된 7개의 스포츠 중 단 2개만 최종후보로 선정되었는데, 이는 7인제 럭비와 골프였다. 같은해인 2009년 10월에 열린 IOC 총회에서 골프와 럭비는 과반수 이상의 득표를 얻어서 2016년 하계 올림픽과 2020년 하계 올림픽의 정식종목으로 채택되었다. 2002년에 열린 제114차 IOC 총회에서는 하계 올림픽 종목은 최대 28부문 301개 경기에 10,500명이 참가하는 것으로 제한하기로 결정했다.그 후 3년 뒤인 제117차 IOC 총회에서는 정식종목이었던 야구와 소프트볼을 정식 종목에서 제외시킨다. 이 결과에 대한 이견이 없었으므로 2012년 올림픽 때는 26개부문에서 경기가 열린다. 2016년과 2020년 올림픽 때는 럭비와 골프가 추가되어 다시 28개부문에서 경기가 열린다. 프로 NHL선수들은 1998년부터 아이스 하키종목에 출전할 수 있게 되었다. (나가노 올림픽 결승전 러시아 vs 체코). 영국 명문 공립 학교의 이념은 쿠베르탱에게 큰 영향을 끼쳤다. 영국 공립 학교는 스포츠를 교육의 중요한 부분이라 생각해서 '건전한 신체에 건전한 정신을'이라는 의미를 가진 라틴어 mens sana in corpore sano를 표어로 삼았다. 이 이념에 의하면 신사들은 특정한 분야에서만 우수해서는 안되고 모든 분야에서 고르게 잘해야 하고, 공정한 결과에는 승복해야 하며, 연습이나 훈련은 속이는 것과 마찬가지로 여겼다. 전문적으로 스포츠를 연습한 사람은 취미로 연습한 사람에 비해 공평하지 않다고 생각한 것이다.\n",
      "\n",
      "현대 올림픽에서는 프로 선수의 참가 불허가 많은 분쟁을 가져왔다. 1912년 하계 올림픽의 근대 5종 경기와 10종 경기에서 우승한 짐 소프는 올림픽에 나가기 전에 준프로야구선수로 활동했다는 게 나중에 밝혀져 메달이 박탈되었다. 소프는 후에 동정적 여론의 힘을 업고 1983년에 메달을 돌려받게 된다. 1936년 동계 올림픽 때 스위스와 오스트리아 스키선수들은 돈을 벌기 위해 스포츠를 했는데 이러한 행동이 아마추어 정신에 위배된다고 결정되어 그들은 스키종목에 참가할 수 없었다. 20세기에 이르러서 계급구조가 붕괴되면서 이른바 귀족적인 신사라는 아마추어 선수에 대한 정의는 시대에 뒤처지는 말이 되게 된다. 일부 국가들은 '정식 아마추어 선수'를 '키워서' 순수한 아마추어 정신을 벗어나고 있었고, 자신이 내는 비용으로 연습하는 선수들의 불리함에 대한 목소리가 나오기 시작했다. 하지만 IOC는 아마추어 정신에 관한 입장을 고수했다. 1970년대 초에는 아마추어 정신이 올림픽헌장에서 폐지되어야 한다는 말이 나오기 시작했다. 결국 프로선수들의 출전은 국제경기연맹(IF)에서 결정짓도록 되었다. 2008년 기준으로 아마추어 선수만 출전하고 있는 올림픽 종목은 복싱이 유일하며 남자 축구에서는 나이가 23세 이상인 선수를 3명까지만 선발할 수 있다. 이는 아마추어 정신을 지키기 위한 일환으로 볼 수 있다.\n",
      "\n",
      "논란 올림픽에서 첫 번째 보이콧은 1956년 하계 올림픽에서 시작되었다. 네덜란드, 스페인, 스위스는 소련의 헝가리 침공에 항의해 참가를 거부했다. 캄보디아, 이집트, 이라크, 레바논은 제2차 중동 전쟁 때문에 보이콧했다. 1972년과 1976년 올림픽에는 많은 아프리카의 국가들이 남아프리카 공화국과 로디지아에서 일어나는 인종 차별정권에 대한 항의의 표시로 올림픽 참가를 거부했다. 이 보이콧에는 뉴질랜드도 관계가 되어있는데, 뉴질랜드 럭비 국가 대표팀이 당시 아파르트헤이트정책을 쓰던 남아프리카 공화국과 경기를 했음에도 불구하고 뉴질랜드의 올림픽 참가가 허용되었기 때문이었다. 국제 올림픽 위원회는 이 두 보이콧에 대해 심각하게 고민했으나 후자의 뉴질랜드의 경우는 럭비가 올림픽 종목이 아니라는 이유를 내세워 뉴질랜드의 올림픽 참가 금지 요청을 거부했다. 당시 아프리카에 속해 있던 20개국과 가이아나, 이라크는 경기를 끝낸 선수들이 있었지만 탄자니아가 이끄는 올림픽 보이콧에 가세했다. 중화민국(타이완)도 1976년 몬트리올 올림픽 참가를 보이콧했는데, 그 이유는 중화인민공화국(중국)이 몬트리올 올림픽 조직위원회에게 타이완을 '중화민국'의 이름으로 참가하지 못하도록 압박을 가했기 때문이다. 타이완은 이것에 반발해서 중화민국의 국기와 중화민국의 국가를 계속 쓸 것이라고 밝혔다. 타이완은 1984년까지 올림픽에 참가하지 않았으며 그 후 참가할 때는 중화 타이베이 올림픽기와 특별한 찬가를 사용한다. 1980년과 1984년 올림픽 때는 냉전의 당사국들이 각각 반대진영에서 개최된 올림픽에 불참했다. 1980년에 열린 모스크바 올림픽 때는 소련의 아프가니스탄 침공에 대한 항의의 표시로 미국을 비롯한 65개국이 불참해서 1956년 이후 가장 적은 국가의 수인 81개국만 참가하는 대회가 되었다. 1984년에 열린 L.A 올림픽때는 루마니아와 유고슬라비아를 제외한 소련과 동구권의 14개 국가가 자국 선수들의 안전을 보장받지 못한다는 이유로 올림픽에 불참했다. 소련의 한 관계자는 그들이 올림픽 보이콧을 한 것에 대해 다음과 같은 발언을 통해 지지했다. \"미국에서 광적인 애국심과 반소련 세력이 점점 늘어나고 있다.\" 동구권에서 보이콧을 한 국가들은 올림픽을 대신할 대회로 프렌드십 게임을 7월과 8월에 했다. 2008년에는 티베트와 다르푸르에 관한 중국의 인권문제를 두고 그에 대한 항의 표시로 중국산 물품의 불매운동과 2008 올림픽 불참에 대한 요구가 컸으나 보이콧을 한 나라는 없었다. 2008년 8월, 조지아 정부는 러시아가 2008년 남오세티야 전쟁에 참전한 것과 관련하여 러시아의 소치에서 열릴 2014년 동계 올림픽을 보이콧하자고 요청했다. 이에 대해 국제 올림픽 위원회는 \"앞으로 개최될 때까지 6년이나 남았는데 시작하기도 전에 섣불리 이른 판단을 하는 것은 옳지 않다.\"라고 말했다.\n",
      "\n",
      "쿠베르탱이 말했던 원래 이념과는 반대로 올림픽이 정치 혹은 체제 선전의 장으로 이용되는 경우가 있었다. 1936년 하계 올림픽을 개최할 때 당시의 나치독일은 나치는 자비롭고 평화를 위한다는 것을 설명하고 싶어했다. 또 이 올림픽에서 아리안족의 우월함을 보여줄 생각이었으나 이는 흑인이었던 제시 오언스가 금메달을 4개나 따내면서 실현되지는 못했다. 소련은 헬싱키에서 열린 1952년 하계 올림픽 때 처음으로 참가했다. 그 전에는 소련이 조직한 스파르타키아다라는 대회에 1928년부터 참가했었다. 다른 공산주의 국가들은 1920년대와 1930년대의 전쟁 기간 사이에 노동자 올림픽(Socialist Workers' Sport International)을 조직했는데, 이는 올림픽을 자본가와 귀족들의 대회로 여기고 그에 대한 대안으로 고안된 대회였다. 그 이후 소련은 1956년 하계 올림픽부터 1988년 하계 올림픽까지 엄청난 스포츠강국의 면모를 보여주며 올림픽에서의 명성을 드높였다. 선수 개인이 자신의 정치적 성향에 대해 표현하기도 했다. 멕시코 시티에서 열린 1968년 하계 올림픽의 육상부문 200m 경기에서 각각 1위와 3위를 한 미국의 토미 스미스와 존 카를로스는 시상식 때 블랙 파워 설루트(Black Power salute , 흑인 차별 반대 행위)를 선보였으며 2위를 한 피터 노먼도 상황을 깨닫고 스미스와 카를로스의 행위를 지지한다는 뜻에서 급하게 인권을 위한 올림픽 프로젝트(OPHR) 배지를 달았다. 이 사건에 대해서 IOC 위원장이었던 에이버리 브런디지는 미국 올림픽 위원회에 이 두 선수를 미국으로 돌려보내거나 미국 육상팀 전부를 돌려보내는 둘 중 하나의 선택을 하게 했고, 미국 올림픽 위원회는 두 선수를 미국으로 돌려 보낸다. 현재 이란 정부는 이스라엘과의 어떤 경기 경쟁이든 피하고 있다. 2008년 하계 올림픽 때 이란의 수영 선수는 이스라엘 수영 선수와 같이 경기한다는 이유로 경기를 포기했으며, 2004년 하계 올림픽에서도 이란의 유도 선수는 이스라엘 선수와 경기한다는 일정이 잡혔을 때 경기를 포기했다. 이 선수는 공식적으로는 시합전에 계체량을 재서 체중이 초과되어 실격 되었으나 이란정부로부터 125,000달러나 되는 돈을 받았다고 한다.\n",
      "\n",
      "20세기 초반, 많은 운동 선수들은 기록향상을 위해 약물을 복용하기 시작했다. 예를 들어 1904년 하계 올림픽 마라톤에서 우승한 미국 선수 토머스 J. 힉스는 코치에게서 스트리크닌과 브랜디를 받았다. 올림픽에서 약물을 과다 복용으로 사망한 사례도 한 번 있었다. 1960년 로마 대회 때 사이클 개인도로 경기 중에 덴마크 선수인 크누드 에네마르크 옌센이 자전거에서 떨어져서 사망했다. 검시관들의 조사에 의하면 그의 죽음의 원인은 암페타민 과다 복용이라고 했다. 이에 1960년대 중반부터 각 경기 연맹은 약물 복용을 금지하기 시작했으며 1967년에는 IOC도 약물 복용 금지에 동참했다. 올림픽에서 약물 복용 양성 반응이 나와서 메달을 박탈당한 첫 번째 사례로는 1968년 하계 올림픽의 근대 5종 경기에 출전해 동메달을 딴 한스 군나르 리렌바르가 있다. 그는 경기 후 도핑검사 결과 알코올을 복용한 것으로 확인되어 메달을 박탈당했다. 도핑 양성 반응으로 메달을 박탈당한 것으로 가장 유명한 사람은 1988년 하계 올림픽 육상 100m 경기에서 금메달을 땄으나 도핑 검사 결과 스타노졸롤을 복용한 것으로 확인돼 금메달을 박탈당한 캐나다 선수인 벤 존슨이 있다. 이에 따라 금메달은 2위를 했던 칼 루이스가 대신 받았다. 1990년대 후반, 여러 뜻있는 사람들이 도핑과의 전쟁을 선포하면서 1999년에 세계반도핑기구(WADA)를 설립한다. 2000년 하계 올림픽과 2002년 동계 올림픽 때는 약물 양성 반응을 보인 선수들이 급격히 증가했고, 역도와 크로스컨트리에서는 몇몇 선수들이 도핑 테스트에 걸려서 실격되기도 했다. 2006년 동계 올림픽 때는 메달리스트 한 명이 양성반응을 보여 메달을 반납해야 했다. IOC가 만든 약물 반응 판정(현재 올림픽 도핑테스트의 기준이 됨)은 인정을 받게 되었고 이제는 다른 경기 연맹에서도 벤치마킹을 할 정도가 되었다. 2008년 베이징 올림픽 기간중에는 3,667명의 선수들이 세계반도핑기구의 검사를 받았으며 소변과 혈액 검사로 약물 복용 검사를 했다. 몇몇 선수들은 국가 올림픽 위원회(NOC)에 의해 올림픽이 시작되기 전에 출전금지 조치를 당했고, 올림픽 기간중에는 단 3명만이 도핑 검사에 걸렸다. 쿠베르탱의 생각과는 달리, 올림픽이 세계에 완벽한 평화를 가져다주지는 못했다. 실제로 제1차 세계대전으로 인해 독일 베를린에서 열리기로 했던 제6회 1916년 하계 올림픽이 취소되었고, 제2차 세계대전 때는 일본 도쿄에서 열리기로 했던 제12회 1940년 하계 올림픽, 삿포로에서 열리기로 했던 1940년 동계 올림픽, 영국 런던에서 열리기로 했던 제13회 1944년 하계 올림픽, 이탈리아 코르티나담페초에서 열릴 예정인 1944년 동계 올림픽이 취소되었다. 베이징에서 열린 2008년 하계 올림픽 개막식날 조지아와 러시아 간의 2008년 남오세티아 전쟁이 일어나기도 했다. 부시 대통령과 푸틴 대통령이 이 올림픽을 보러 왔으며 중국 주석인 후진타오가 주최한 오찬에 참석해서 이 현안에 대해 논의하기도 했다. 조지아 대표인 니노 살루크바체와 러시아 대표인 나탈리야 파데리나가 여자 10m 공기권총 경기에서 각각 동메달과 은메달을 땄을 때 이 일은 베이징 올림픽의 유명한 사건 중 하나로 남게 되었다. 살루크바체와 파데리나는 시상식이 끝난 뒤 서로 포옹을 하며 국적에 상관없이 기쁨을 나누었다. 테러도 올림픽에서 공포의 대상이었다. 뮌헨 참사로 알려진 1972년에 서독 바이에른의 뮌헨에서 열린 하계 올림픽때의 사건은 테러리스트인 검은 9월단이 일으킨 사건으로서 이스라엘 선수 11명을 인질로 붙잡았다가 전원이 사망한 사건이다. 당시 미숙한 진압으로 인해 인질 9명(선수 1명과 코치 1명은 인질로 잡기 이전에 살해), 테러범 5명, 독일 경찰관 1명이 사망했으며 이 진압 작전 이전에는 인질들은 단 한 명도 죽지 않았다. 애틀란타에서 열린 1996년 하계 올림픽 때는 센테니얼 올림픽 공원(Centennial Olympic Park)에서 폭발 사건이 일어나 2명이 죽고 111명이 다치는 사건이 발생했다. 이 사건의 주모자 에릭 로버트 루돌프는 종신형을 선고받았다. 참고로 마라톤 역시 전쟁에서 유래한 것이다.\n",
      "\n",
      "개최지 선정 올림픽 개최지는 해당 올림픽 개최 7년 전에 IOC 위원들의 투표로 결정된다. 개최지 선정에는 약 2년이 걸린다. 유치를 희망하는 도시는 우선 자국의 올림픽 위원회에 신청을 해야 한다. 만약 한 국가에서 두 도시 이상이 유치를 희망한다면, 한 국가당 한 도시만 후보가 될 수 있다는 규칙에 따라 내부적으로 후보 도시를 결정해야 한다. 후보 도시가 결정되면 후보 도시가 소속된 국가의 올림픽 위원회는 IOC에 개최 신청을 하고, 신청 후에는 올림픽 개최에 대한 질의 응답서를 보내야 한다. 이 질의응답서에서 신청한 도시는 올림픽 헌장을 준수하며 IOC 상임이사회에 의한 다른 규정들을 지킬 것이라는 확신을 주어야 한다. 이 질의응답서는 전문가들이 검토하여 신청 도시들의 잠재성과 계획을 평가한다. 이 전문적인 평가를 바탕으로 IOC 상임이사회에서는 신청도시 중에서 후보도시를 고른다. 후보도시로 선택되면 그 도시들은 IOC에 보내는 후보도시에 관한 문서에 그들의 계획을 더욱 상세하고 방대한 양으로 적어서 보내야 한다. 평가조사단들이 이 후보도시들을 평가한다. 평가조사단은 후보도시들을 방문해서 지역 관계자들과 회견을 갖고 경기장 시설을 세심하게 조사한 뒤 개최지 투표를 하기 한달전에 조사를 바탕으로 한 공식 보고를 한다. 회견을 하는 동안에도 후보도시들은 자신들이 올림픽을 개최하는 데 충분한 자금이 조달될 수 있는지 등을 입증할 수 있어야 한다. 평가조사단의 업무가 끝나면 후보지의 국가 위원들은 IOC 정기총회에 참석한다. 이 총회에서 IOC 위원들은 올림픽 개최지를 선정하게 되며 후보지의 국가에 소속된 위원들은 자국의 후보지가 탈락하지 않는 이상 투표를 할 수 없다. 투표가 끝난후에 개최지로 선정된 곳의 유치위원회가 IOC와 개최도시 계약서에 서명을 하면 공식적으로 올림픽 개최도시(개최국)으로 인정된다. 2016년까지 올림픽은 23개국 44개 도시에서 열렸으며 유럽과 북아메리카대륙 이외의 대륙에서는 고작 8번 밖에 개최하지 못했다. 1988년 하계 올림픽이 대한민국의 서울에서 열린것을 시작으로 그 후 아시아와 오세아니아 대륙에서 올림픽이 4번이나 열렸으며, 이는 그 이전의 현대 올림픽사와 비교해보면 엄청나게 늘어난 수치였다. 2016년 하계 올림픽이 개최된 브라질의 리우데자네이루는 남미에서 열리는 첫 번째 올림픽이다. 아직 아프리카에서는 올림픽이 한 번도 개최되지 않았다. 2008년 하계 올림픽 때 가장 많은 선수가 참여한 나라는 중국으로 639명이 참가했으며 그 다음은 미국과 러시아로 각각 596명과 455명이 참가했다. 미국은 5번의 하계 올림픽과 4번의 동계 올림픽을 개최하면서 최다 올림픽을 개최한 나라이다. 영국은 2012년에 3번째 올림픽을 개최하였다. 독일, 오스트레일리아, 그리스는 하계 올림픽을 2번 개최한 국가이다. 동계 올림픽에서는 이탈리아가 2026년 밀라노-코르티나담페초 개최지로 선정되어 3번 개최될 예정이다. 또한 프랑스가 3번을 개최했으며 2024년 하계올림픽 개최예정으로 영국에 이번 두 번째로 한 도시에서 3번 올림픽 개최하며 하계올림픽3번 개최하였다. 프랑스는 동계, 하계 올림픽 각 3번씩 총 6번 개최로 9번으로 최다개최국인 미국 다음으로 두 번째로 많이 개최한 국가가 된다. 스위스, 오스트리아, 노르웨이, 일본, 이탈리아는 2번씩 개최했다. 일본은 하계,동계 각 2번씩 총 4번으로 미국, 프랑스 다음 세번째로 많이 개최한 국가이다. 2010년에 밴쿠버에서 열린 2010년 동계 올림픽은 캐나다에서 열리는 두 번째 동계 올림픽이고, 동/하계 올림픽을 합쳐 캐나다에서 3번째로 개최되는 올림픽이다.\n",
      "\n",
      "우승자와 메달리스트 개인 혹은 팀으로 경기에 출전해서 1위, 2위, 3위를 한 선수는 메달을 받는다. 1912년까지는 우승자에게 순금으로 된 금메달을 주었으며 그 후에는 도금된 금메달을 준다. 하지만, 2010 동계 올림픽에서는 전자제품 부속품을 녹여서 넣었다. 이러한 경우처럼 순금 외에 다른 물질을 넣을 경우에는 순금이 반드시 6g 이상을 함유하고 있어야 한다. 2위를 한 선수는 은메달을, 3위를 한 선수는 동메달을 받는다. 토너먼트로 진행되는 종목의 경우에는(복싱, 태권도 등) 3위를 구분하지 않고 준결승에서 패해서 3/4위전으로 간 선수들에게 모두 동메달을 수여한다. 1896년 하계 올림픽에서는 메달이 2개만 수여됐는데 1위에게 은메달을 주었고 2위에게 동메달을 주었다. 이때 3위에게는 아무것도 없었다. 현재의 메달 수여 방식은 1904년 하계 올림픽 때부터 시작되었다. 1948년부터는 4, 5, 6위를 한 선수에게는 인증서를 수여했다. 1984년 대회부터는 7, 8위를 한 선수에게도 인증서를 수여했다. 아테네에서 열린 2004년 하계 올림픽 때는 1, 2, 3위 선수에게 메달과 함께 올리브 화환도 같이 수여했다. 국가 올림픽 위원회(NOC)와 방송사에서는 자국의 메달 현황을 실시간으로 전달하기도 한다.\n"
     ]
    }
   ],
   "source": [
    "idx = 0\n",
    "print(docs[idx].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "04a1e8eb-2569-43f3-a458-dd020a322c56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loader = DirectoryLoader(\n",
    "    \"data\", # 읽어들일 문서들이 있는 디렉토리.\n",
    "    glob=[\"*.txt\"],   # 읽을 파일들의 확장자를 지정.\n",
    "    recursive=False, # 하위디렉토리까지 검색할지 여부.\n",
    ")\n",
    "docs = loader.load()\n",
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "606579fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d910f155",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'source': 'data\\\\restaurant_wine.txt'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs[2].metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "300bddc2",
   "metadata": {},
   "source": [
    "# Chunking (문서 분할)\n",
    "\n",
    "![rag_split](figures/rag_split.png)\n",
    "\n",
    "- Load 한 문서를 지정한 기준의 덩어리(chunk)로 나누는 작업을 진행한다.\n",
    "\n",
    "## 나누는 이유\n",
    "1. **임베딩 모델의 컨텍스트 길이 제한**\n",
    "    - 대부분의 언어 모델은 한 번에 처리할 수 있는 토큰 수에 제한이 있다. 전체 문서를 통째로 입력하면 이 제한을 초과할 수 있어 처리가 불가능해진다.\n",
    "2. **검색 정확도 향상**\n",
    "    - 큰 문서 전체보다는 특정 주제나 내용을 다루는 작은 chunk가 사용자 질문과 더 정확하게 매칭된다. 예를 들어, 100페이지 매뉴얼에서 특정 기능에 대한 질문이 있을 때, 해당 기능을 설명하는 몇 개의 문단만 검색되는 것이 더 효과적이다.\n",
    "    - 사용자 질문에 대해 문서의 모든 내용이 다 관련있는 것은 아니다. Chunking을 통해 가장 관련성 높은 부분만 선별적으로 활용할 수 있어 답변의 품질이 향상된다.\n",
    "    - 전체 문서에는 질문과 무관한 내용들이 많이 포함되어 있어 모델이 혼란을 겪을 수 있다. 적절한 크기의 chunk는 이런 노이즈를 줄여준다.\n",
    "3. **계산 효율성**\n",
    "    - 벡터 유사도 계산, 임베딩 생성 등의 작업이 작은 chunk 단위로 수행될 때 더 빠르고 효율적이다. 메모리 사용량도 줄일 수 있다.\n",
    "\n",
    "## 주요 Spliter\n",
    "- https://api.python.langchain.com/en/latest/text_splitters_api_reference.html\n",
    "\n",
    "### CharacterTextSplitter\n",
    "가장  기본적인 Text spliter\n",
    "- 한개의 구분자를 기준으로 분리한다. (default: \"\\n\\n\")\n",
    "    - 분리된 조각이 chunk size 보다 작으면 다음 조각과 합칠 수 있다.\n",
    "        - 합쳤을때 chuck_size 보다 크면 안 합친다. chuck_size 이내면 합친다.\n",
    "    - 나누는 기준은 구분자이기 때문에 chunk_size 보다 글자수가 많을 수 있다.\n",
    "- chunk size: 분리된 문서(chunk) 글자수 이내에서 분리되도록 한다.\n",
    "    -  구분자를 기준으로 분리한다. 구분자를 기준으로 분리한 문서 조각이 chunk size 보다 크더라도 그대로 유지한다. 즉 chunk_size가 우선이 아니라 **seperator** 가 우선이다.\n",
    "- 주요 파라미터\n",
    "    - chunk_size: 각 조각의 최대 길이를 지정.\n",
    "    - seperator: 구분 문자열을 지정. (default: '\\n\\n')\n",
    "- CharacterTextSplitter는 단순 스플리터로 overlap기능을 지원하지는 않는다. 단 seperator가 빈문자열(\"\") 일 경우에는 overlap 기능을 지원한다. overlap이란 각 이전 청크의 뒷부분의 문자열을 앞에 붙여 문맥을 유지하는 것을 말한다.\n",
    "  \n",
    "### RecursiveCharacterTextSplitter\n",
    "- RecursiveCharacterTextSplitter는 **긴 텍스트를 지정된 최대 길이(chunk_size) 이하로 나누는 데 효과적인 텍스트 분할기**(splitter)이다.\n",
    "- 여러 **구분자(separators)를 순차적으로 적용**하여, 가능한 한 자연스러운 문단/문장/단어 단위로 분할하고, 최종적으로는 크기 제한을 만족시킨다.\n",
    "- 분할 기준 문자\n",
    "    1. 두 개의 줄바꿈 문자 (\"\\n\\n\")\n",
    "    2. 한 개의 줄바꿈 문자 (\"\\n\")\n",
    "    3. 공백 문자 (\" \")\n",
    "    4. 빈 문자열 (\"\")\n",
    "- 작동 방식\n",
    "    1. 먼저 가장 높은 우선순위의 구분자(\"\\n\\n\")로 분할을 시도한다.\n",
    "    2. 분할된 조각 중 **chunk_size를 초과하는 조각**에 대해 다음 우선순위 구분자(\"\\n\" → \" \" → \"\")로 재귀적으로 재분할한다.\n",
    "    3. 이 과정을 통해 모든 조각(chunk)이 chunk_size를 초과하지 않도록 만든다.  \n",
    "- 주요 파라미터\n",
    "    - chunk_size: 각 조각의 최대 길이를 지정.\n",
    "    - chunk_overlap: 연속된 청크들 간의 겹치는 문자 수를 설정. 새로운 청크 생성 시 이전 청크의 마지막 부분에서 지정된 수만큼의 문자를 가져와서 새 청크의 앞부분에 포함시켜, 청크 경계에서 문맥의 연속성을 유지한다.\n",
    "      - 구분자에 의해 청크가 나눠지면 정상적인 분리이므로 overlap이 적용되지 않는다.\n",
    "      - 정상적 구분자로 나눌 수 없어 chunk_size에 맞춰 잘라진 경우 문맥의 연결성을 위애 overlap을 적용한다.\n",
    "    - separators(list): 구분자를 지정한다. 지정하면 기본 구분자가 지정한 것으로 변경된다.\n",
    "\n",
    "#### 메소드\n",
    "- `split_documents(Iterable[Document]) : List[Document]`\n",
    "    - Document 목록을 받아 split 처리한다.\n",
    "- `split_text(str) : List[str]`\n",
    "    - string text를 받아서 split 처리한다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "35a08d3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"가각간갇갈갉갊감갑값갓갔강갖갗같갚갛개객갠갤갬갭갯갰\n",
    "\n",
    "aadlskfjadklsfjakldfjadklsjadfskl갸갹갼걀걋걍걔걘걜거걱건걷걸걺검겁것겉겊겋게겐\n",
    "\n",
    "띱띳띵라락란랄람랍랏랐\n",
    "\n",
    "랑랒랖랗래랙랜랠램랩랫랬랭랴략랸럇량러럭런럴럼럽럿렀렁렇레렉렌렐렘렙렛렝나낙낚ASDFFGHJJKKLLLQWE\n",
    "\n",
    "멨멩며 \n",
    "\n",
    "멱면멸몃몄명몇몌모목몫몬몰몲몸몹못몽뫄뫈뫘뫙뫼묀묄묍묏묑묘묜묠묩묫무묵묶문묻물묽묾뭄뭅뭇뭉뭍뭏ABCDEFGHIJ\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3725f8d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_text_splitters import CharacterTextSplitter, RecursiveCharacterTextSplitter\n",
    "\n",
    "splitter = CharacterTextSplitter(\n",
    "    chunk_size = 60,\n",
    "    chunk_overlap = 10, # chunk_size 보다 chunk_overlap은 작아야함.\n",
    "    separator = \"\"\n",
    ")\n",
    "\n",
    "docs = splitter.split_text(text)\n",
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fe66b0ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60||가각간갇갈갉갊감갑값갓갔강갖갗같갚갛개객갠갤갬갭갯갰\n",
      "\n",
      "aadlskfjadklsfjakldfjadklsjadfsk\n",
      "------------------------------\n",
      "60||dklsjadfskl갸갹갼걀걋걍걔걘걜거걱건걷걸걺검겁것겉겊겋게겐\n",
      "\n",
      "띱띳띵라락란랄람랍랏랐\n",
      "\n",
      "랑랒랖랗래랙랜랠램랩랫\n",
      "------------------------------\n",
      "60||랒랖랗래랙랜랠램랩랫랬랭랴략랸럇량러럭런럴럼럽럿렀렁렇레렉렌렐렘렙렛렝나낙낚ASDFFGHJJKKLLLQWE\n",
      "\n",
      "멨멩며\n",
      "------------------------------\n",
      "60||LLQWE\n",
      "\n",
      "멨멩며 \n",
      "\n",
      "멱면멸몃몄명몇몌모목몫몬몰몲몸몹못몽뫄뫈뫘뫙뫼묀묄묍묏묑묘묜묠묩묫무묵묶문묻물묽묾뭄뭅뭇뭉뭍뭏\n",
      "------------------------------\n",
      "20||묻물묽묾뭄뭅뭇뭉뭍뭏ABCDEFGHIJ\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "for doc in docs:\n",
    "    print(len(doc), doc, sep=\"||\")\n",
    "    print(\"-\"* 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ee0c8840",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.documents import Document\n",
    "\n",
    "document = Document(page_content=text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ed5b25cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'> 9\n"
     ]
    }
   ],
   "source": [
    "splitter2 = RecursiveCharacterTextSplitter(\n",
    "    chunk_size = 50,\n",
    "    chunk_overlap = 10,\n",
    "    # separators =[\"첫번째구분자\", \"두번쨰 구분자\", \"세번째 구분자\", ...]\n",
    "    # default : [\"\\n\\n\", \"\\n\", \" \", \"\"]\n",
    ")\n",
    "\n",
    "result = splitter2.split_text(text)\n",
    "print(type(result), len(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "eb96813e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26||가각간갇갈갉갊감갑값갓갔강갖갗같갚갛개객갠갤갬갭갯갰\n",
      "======================================================================\n",
      "49||aadlskfjadklsfjakldfjadklsjadfskl갸갹갼걀걋걍걔걘걜거걱건걷걸걺검\n",
      "======================================================================\n",
      "17||걔걘걜거걱건걷걸걺검겁것겉겊겋게겐\n",
      "======================================================================\n",
      "11||띱띳띵라락란랄람랍랏랐\n",
      "======================================================================\n",
      "49||랑랒랖랗래랙랜랠램랩랫랬랭랴략랸럇량러럭런럴럼럽럿렀렁렇레렉렌렐렘렙렛렝나낙낚ASDFFGHJJK\n",
      "======================================================================\n",
      "17||ASDFFGHJJKKLLLQWE\n",
      "======================================================================\n",
      "3||멨멩며\n",
      "======================================================================\n",
      "49||멱면멸몃몄명몇몌모목몫몬몰몲몸몹못몽뫄뫈뫘뫙뫼묀묄묍묏묑묘묜묠묩묫무묵묶문묻물묽묾뭄뭅뭇뭉뭍뭏AB\n",
      "======================================================================\n",
      "18||묽묾뭄뭅뭇뭉뭍뭏ABCDEFGHIJ\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "for r in result:\n",
    "    print(len(r), r, sep=\"||\")\n",
    "    print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5cd8206f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={}, page_content='가각간갇갈갉갊감갑값갓갔강갖갗같갚갛개객갠갤갬갭갯갰'),\n",
       " Document(metadata={}, page_content='aadlskfjadklsfjakldfjadklsjadfskl갸갹갼걀걋걍걔걘걜거걱건걷걸걺검'),\n",
       " Document(metadata={}, page_content='걔걘걜거걱건걷걸걺검겁것겉겊겋게겐'),\n",
       " Document(metadata={}, page_content='띱띳띵라락란랄람랍랏랐'),\n",
       " Document(metadata={}, page_content='랑랒랖랗래랙랜랠램랩랫랬랭랴략랸럇량러럭런럴럼럽럿렀렁렇레렉렌렐렘렙렛렝나낙낚ASDFFGHJJK'),\n",
       " Document(metadata={}, page_content='ASDFFGHJJKKLLLQWE'),\n",
       " Document(metadata={}, page_content='멨멩며'),\n",
       " Document(metadata={}, page_content='멱면멸몃몄명몇몌모목몫몬몰몲몸몹못몽뫄뫈뫘뫙뫼묀묄묍묏묑묘묜묠묩묫무묵묶문묻물묽묾뭄뭅뭇뭉뭍뭏AB'),\n",
       " Document(metadata={}, page_content='묽묾뭄뭅뭇뭉뭍뭏ABCDEFGHIJ')]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result2 = splitter2.split_documents([document])\n",
    "result2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6a152b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "61\n"
     ]
    }
   ],
   "source": [
    "####################################\n",
    "# olympic.txt 를 읽어서 split처리\n",
    "####################################\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "# 1. 문서 load\n",
    "path = \"data/olympic.txt\"\n",
    "loader = TextLoader(path, encoding=\"utf-8\")\n",
    "docs = loader.load() # docs : list[Document]\n",
    "\n",
    "# 2. load 한 문서를 split\n",
    "splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=100)\n",
    "split_docs = splitter.split_documents(docs)\n",
    " \n",
    "print(len(split_docs)) # list[Document]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "83e7a0fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "len_list = [len(d.page_content) for d in split_docs] # split된 문서들의 글자수\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "59091c0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "올림픽(영어: Olympic Games, 프랑스어: Jeux olympiques)은 전 세계 각 대륙 각국에서 모인 수천 명의 선수가 참가해 여름과 겨울에 스포츠 경기를 하는 국제적인 대회이다. 전 세계에서 가장 큰 지구촌 최대의 스포츠 축제인 올림픽은 세계에서 가장 인지도있는 국제 행사이다. 올림픽은 2년마다 하계 올림픽과 동계 올림픽이 번갈아 열리며, 국제 올림픽 위원회(IOC)가 감독하고 있다. 또한 오늘날의 올림픽은 기원전 8세기부터 서기 5세기에 이르기까지 고대 그리스 올림피아에서 열렸던 올림피아 제전에서 비롯되었다. 그리고 19세기 말에 피에르 드 쿠베르탱 남작이 고대 올림피아 제전에서 영감을 얻어, 근대 올림픽을 부활시켰다. 이를 위해 쿠베르탱 남작은 1894년에 IOC를 창설했으며, 2년 뒤인 1896년에 그리스 아테네에서 제 1회 올림픽이 열렸다. 이때부터 IOC는 올림픽 운동의 감독 기구가 되었으며, 조직과 활동은 올림픽 헌장을 따른다. 오늘날 전 세계 대부분의\n"
     ]
    }
   ],
   "source": [
    "idx = 1\n",
    "print(split_docs[idx].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "700e8dc8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "\n",
    "path = \"data/novel/메밀꽃_필_무렵_이효석.pdf\"\n",
    "loader = PyPDFLoader(path)\n",
    "\n",
    "docs = loader.load()\n",
    "\n",
    "split_docs = splitter.split_documents(docs)\n",
    "len(split_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a7cdf072",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "491 2 \n",
      "여 름장이란  애 시당초에  글러서 , 해는  아 직  중천에  있건만  장\n",
      "판은  벌써  쓸쓸하고  더운  햇발이  벌여 놓은  전  휘장  밑으로\n",
      "등줄기를  훅훅  볶는다 . 마을  사람들은  거지  반  돌아 간  뒤요 ,\n",
      "팔리지  못한  나무꾼  패가  길거리에  궁싯거리고들  있으나  석\n",
      "유병이나  받고  고깃마리나  사면  족할  이  축들을  바라고  언 제\n",
      "까지든지  버티고  있을  법은  없 다 . 춥춥스럽게  날아 드는  파리\n",
      "떼도  장난꾼  각다귀[1]들도  귀치않다 .[2] 얽 둑배기요  왼손잡\n",
      "이인  드팀전[3]의  허  생원은  기어 코  동업 의  조  선달에 게  나꾸\n",
      "어  보았 다 .[4]\n",
      "“ 그만  거둘까 ?”\n",
      "“ 잘  생각했네 . 봉평[5] 장에 서  한번이나  흐붓하게[6] 사본  일\n",
      "있을까해 . 내일  대화  장에 서가  한몫  벌어 야 겠네 .”\n",
      "“ 오 늘  밤은  밤을  새서  걸어 야  될걸 ?”\n",
      "“ 달이  뜨렷다 ?”\n"
     ]
    }
   ],
   "source": [
    "idx = 1\n",
    "print(len(split_docs[idx].page_content), split_docs[idx].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b593a54e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 문서 load와 split을 동시에 처리.\n",
    "\n",
    "split_docs = loader.load_and_split(splitter)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed87439d",
   "metadata": {},
   "source": [
    "## Token 수 기준으로 나누기\n",
    "\n",
    "- LLM 언어 모델들은 입력 토큰 수 제한이 있어서 요청시 제한 토큰수 이상의 프롬프트는 전송할 수 없다.\n",
    "- 따라서 텍스트를 chunk로 분할할 때는 글자수 보다 **토큰 수를 기준으로 크기를 지정하는 것**이 좋다.  \n",
    "- 토큰기반 분할은 텍스트의 의미를 유지하면서 분할하는 방식이므로 문자 기반 분할과 같이 단어가 중간잘리는 것들을 방지할 수 있다. \n",
    "- 토큰 수 계산할 때는 사용하는 언어 모델에 사용된 것과 동일한 tokenizer를 사용하는 것이 좋다.\n",
    "  - 예를 들어 OpenAI의 GPT 모델을 사용할 경우 tiktoken 라이브러리를 활용하여 토큰 수를 정확하게 계산할 수 있다.\n",
    "\n",
    "### [tiktoken](https://github.com/openai/tiktoken) tokenizer 기반 분할\n",
    "- OpenAI에서 GPT 모델을 학습할 때 사용한 `BPE` 방식의 tokenizer. **OpenAI 언어모델을 사용할 경우 이것을 사용하는 것이 좀 더 정확하게  토큰dmf 계산할 수 있다.**\n",
    "- Splitter.from_tiktoken_encoder() 메소드를 이용해 생성\n",
    "  - `RecursiveCharacterTextSplitter.from_tiktoken_encoder()`\n",
    "  - `CharacterTextSplitter.from_tiktoken_encoder()`\n",
    "- 파라미터\n",
    "  - encode_name: 인코딩 방식(토큰화 규칙)을 지정. OpenAI는 GPT 모델들 마다 다른 방식을 사용했다. 그래서 사용하려는 모델에 맞는 인코딩 방식을 지정해야 한다.\n",
    "    - `cl100k_base`: GPT-4 및 GPT-3.5-Turbo 모델에서 사용된 방식.\n",
    "    - `r50k_base:` GPT-3 모델에서 사용된 방식 \n",
    "  - chunk_size, chunk_overlap, separators 파라미터 (위와 동일)\n",
    "- tiktoken 설치\n",
    "  - `pip install tiktoken`\n",
    "\n",
    "### HuggingFace Tokenizer\n",
    "- HuggingFace 모델을 사용할 경우 그 모델이 사용한 tokenizer를 이용해 토큰 기반으로 분할 한다.\n",
    "  - 다른 tokenizer를 이용해 분할 할 경우 토큰 수 계산이 다르게 될 수있다.\n",
    "- `from_huggingface_tokenizer()` 메소드를 이용.\n",
    "  - 파라미터\n",
    "    - tokenizer: HuggingFace tokenizer 객체\n",
    "    - chunk_size, chunk_overlap, separators 파라미터 (위와 동일)\n",
    "- `transformers` 라이브러리를 설치해야 한다.\n",
    "  - `pip install transformers` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "dbf9ddbb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(\n",
    "    model_name=\"gpt-4o-mini\", # 지정한 모델을 학습할때 사용한 토크나이저를 사용. -> 모델에 데이터 넣을떄 규격맞추기 위함.\n",
    "    chunk_size = 200, # token 수 기준.\n",
    "    chunk_overlap = 0,\n",
    ")\n",
    "\n",
    "docs = loader.load_and_split(splitter)\n",
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ac271d8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 \n",
      "메밀꽃  필  무렵\n",
      "Exported from Wikisource on 2024 년  11 월  24 일\n"
     ]
    }
   ],
   "source": [
    "idx = 0\n",
    "print(docs[idx].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "ae775c06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hugging face tokenizer\n",
    "\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "model_id = \"beomi/kcbert-base\" # 사용할 LLM 모델의 ID\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "a2010c27",
   "metadata": {},
   "outputs": [],
   "source": [
    "splitter = RecursiveCharacterTextSplitter.from_huggingface_tokenizer(\n",
    "    tokenizer=tokenizer,\n",
    "    chunk_size = 500,\n",
    "    chunk_overlap = 0\n",
    ")\n",
    "docs = loader.load_and_split(splitter)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "9a165a2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 1 \n",
      "조그만  전방이나  하나  벌이구  식구들을  부르겠어 . 사시장천\n",
      "[20] 뚜벅뚜벅  걷기란  여 간이래야 지 .”\n",
      "“ 옛  처녀나  만나면  같이나  살까 - 난  꺼꾸러질  때까지  이  길\n",
      "걷고  저  달  볼  테야 .”\n",
      "산길을  벗어 나니  큰길로  틔어 졌다 . 꽁무니의  동이도  앞 으로\n",
      "나서  나귀들은  가로  늘어 섰다 .\n",
      "“ 총각두  젊겠다 , 지금이  한창  시절이렸다 . 충주집에 서는  그\n",
      "만  실수를  해서  그  꼴이  되었 으나  설게  생각  말게 .”\n",
      "“ 처 , 천만에 요 . 되려  부끄러워요 . 계집이란  지금  웬  제격인가\n",
      "요 . 자나깨나  어 머니  생각뿐인데요 .”\n",
      "허  생원의  이야 기로  실심해  한  끝이라  동이의  어 조는  한풀\n",
      "수그러진  것이었 다 .\n",
      "“ 아 비  어 미란  말에  가슴이  터지는  것도  같았 으나  제겐  아 버\n",
      "지가  없 어 요 . 피붙이라고는  어 머니  하나뿐인  걸요 .”\n",
      "“ 돌아 가셨나 ?”\n",
      "“ 당초부터  없 어 요 .”\n",
      "“ 그런  법이  세상에 …”\n",
      "생원과  선달이  야 단스럽게  껄껄들  웃으니 , 동이는  정색하고\n",
      "우길  수밖에 는  없 었 다 .\n"
     ]
    }
   ],
   "source": [
    "idx = 10\n",
    "print(docs[idx].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f53f8b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain.text_splitter import "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lang_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
