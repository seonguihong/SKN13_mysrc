{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d3fa1505-5df4-415a-b490-73573300ae62",
   "metadata": {},
   "source": [
    "# Gensim 패키지\n",
    "- Python으로 작성된 오픈 소스 라이브러리로, 자연어 처리와 관련된 다양한 기능을 제공한다.\n",
    "- 주요 기능\n",
    "    - **Word Embeddings**\n",
    "        - word2vec, fastext, doc2vec 등 다양한 word embedding 모델을 제공\n",
    "    - **토픽 모델링 (Topic Modeling)**\n",
    "        - LDA등 문장의 주제를 파악하는 모델 제공\n",
    "    - **텍스트/word 유사도 계산**\n",
    "    - **문서 군집화**\n",
    "        - 비슷한 주제의 문서들을 군집화.\n",
    "    - 다양한 dataset과 pretrained model 제공\n",
    "        - https://github.com/piskvorky/gensim-data\n",
    "- https://radimrehurek.com/gensim/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fb22fe8-39a2-493b-90d1-6eb59884bfbe",
   "metadata": {},
   "source": [
    "## 설치\n",
    "- `pip install gensim`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b0a0edea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting gensim\n",
      "  Downloading gensim-4.3.3-cp312-cp312-win_amd64.whl.metadata (8.2 kB)\n",
      "Collecting numpy<2.0,>=1.18.5 (from gensim)\n",
      "  Downloading numpy-1.26.4-cp312-cp312-win_amd64.whl.metadata (61 kB)\n",
      "Collecting scipy<1.14.0,>=1.7.0 (from gensim)\n",
      "  Downloading scipy-1.13.1-cp312-cp312-win_amd64.whl.metadata (60 kB)\n",
      "Collecting smart-open>=1.8.1 (from gensim)\n",
      "  Downloading smart_open-7.1.0-py3-none-any.whl.metadata (24 kB)\n",
      "Collecting wrapt (from smart-open>=1.8.1->gensim)\n",
      "  Downloading wrapt-1.17.2-cp312-cp312-win_amd64.whl.metadata (6.5 kB)\n",
      "Downloading gensim-4.3.3-cp312-cp312-win_amd64.whl (24.0 MB)\n",
      "   ---------------------------------------- 0.0/24.0 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.5/24.0 MB 2.8 MB/s eta 0:00:09\n",
      "   ---- ----------------------------------- 2.6/24.0 MB 7.6 MB/s eta 0:00:03\n",
      "   ------------ --------------------------- 7.3/24.0 MB 13.3 MB/s eta 0:00:02\n",
      "   -------------------- ------------------- 12.6/24.0 MB 16.4 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 18.9/24.0 MB 19.5 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 19.4/24.0 MB 16.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  23.9/24.0 MB 17.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 24.0/24.0 MB 16.7 MB/s eta 0:00:00\n",
      "Downloading numpy-1.26.4-cp312-cp312-win_amd64.whl (15.5 MB)\n",
      "   ---------------------------------------- 0.0/15.5 MB ? eta -:--:--\n",
      "   ----------------- ---------------------- 6.8/15.5 MB 32.3 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 13.4/15.5 MB 31.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 15.5/15.5 MB 29.6 MB/s eta 0:00:00\n",
      "Downloading scipy-1.13.1-cp312-cp312-win_amd64.whl (45.9 MB)\n",
      "   ---------------------------------------- 0.0/45.9 MB ? eta -:--:--\n",
      "    --------------------------------------- 1.0/45.9 MB 7.1 MB/s eta 0:00:07\n",
      "   -- ------------------------------------- 3.1/45.9 MB 8.8 MB/s eta 0:00:05\n",
      "   ------- -------------------------------- 9.2/45.9 MB 16.3 MB/s eta 0:00:03\n",
      "   ----------- ---------------------------- 12.8/45.9 MB 17.1 MB/s eta 0:00:02\n",
      "   -------------- ------------------------- 16.8/45.9 MB 16.8 MB/s eta 0:00:02\n",
      "   --------------------- ------------------ 24.1/45.9 MB 19.8 MB/s eta 0:00:02\n",
      "   ---------------------------- ----------- 32.2/45.9 MB 22.5 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 40.4/45.9 MB 24.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------  45.9/45.9 MB 25.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 45.9/45.9 MB 24.0 MB/s eta 0:00:00\n",
      "Downloading smart_open-7.1.0-py3-none-any.whl (61 kB)\n",
      "Downloading wrapt-1.17.2-cp312-cp312-win_amd64.whl (38 kB)\n",
      "Installing collected packages: wrapt, numpy, smart-open, scipy, gensim\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 2.2.5\n",
      "    Uninstalling numpy-2.2.5:\n",
      "      Successfully uninstalled numpy-2.2.5\n",
      "  Attempting uninstall: scipy\n",
      "    Found existing installation: scipy 1.15.3\n",
      "    Uninstalling scipy-1.15.3:\n",
      "      Successfully uninstalled scipy-1.15.3\n",
      "Successfully installed gensim-4.3.3 numpy-1.26.4 scipy-1.13.1 smart-open-7.1.0 wrapt-1.17.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: Failed to remove contents in a temporary directory 'C:\\Users\\tjddm\\miniconda3\\envs\\dl\\Lib\\site-packages\\~umpy.libs'.\n",
      "  You can safely remove it manually.\n",
      "  WARNING: Failed to remove contents in a temporary directory 'C:\\Users\\tjddm\\miniconda3\\envs\\dl\\Lib\\site-packages\\~umpy'.\n",
      "  You can safely remove it manually.\n",
      "  WARNING: Failed to remove contents in a temporary directory 'C:\\Users\\tjddm\\miniconda3\\envs\\dl\\Lib\\site-packages\\~cipy.libs'.\n",
      "  You can safely remove it manually.\n",
      "  WARNING: Failed to remove contents in a temporary directory 'C:\\Users\\tjddm\\miniconda3\\envs\\dl\\Lib\\site-packages\\~cipy'.\n",
      "  You can safely remove it manually.\n"
     ]
    }
   ],
   "source": [
    "%pip install gensim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f22013f4-94ed-4cba-8d86-31836ba16af1",
   "metadata": {},
   "source": [
    "# Word2Vec 학습\n",
    "\n",
    "- gensim.models.Word2Vec\n",
    "- 주요 파라미터\n",
    "    - sentences\n",
    "        -  학습에 사용할 문서의 리스트. 각 문서의 단어들을 리스트로 묶고 그 문서들을 리스트로 묶은 중첩 리스트.\n",
    "        - 예시: \\[\\['word1', 'word2', 'word3'], \\['word4', 'word5']]\n",
    "    - vector_size\n",
    "        -  embedding vector 크기. 기본값: 100\n",
    "    - window\n",
    "        -  context window 크기. 중심단어를 기준으로 좌우 몇개의 단어를 확인하는지 크기. 기본값: 5\n",
    "    - min_count\n",
    "        - 이 설정보다 낮은 빈도로 등장하는 단어는 무시한다. 데이터 노이즈를 줄이는데 도움이된다. 기본값: 5\n",
    "    - sg\n",
    "        - 모델 아키텍처 결정.\n",
    "        - `0`: CBOW, `1`: Skip-gram. 기본값: 0\n",
    "    - epochs\n",
    "        - epochs 수 설정. 기본값: 5\n",
    "    - alpha\n",
    "        - initial leaning rate. 기본값: 0.025\n",
    "    - min_alpha\n",
    "        - 최소 learning rate. 기본값: 0.0001\n",
    "        - epoch 마다 learning rate를 alpha 에서 min_alpha 까지 선형적으로 줄여나간다.\n",
    "    - workers\n",
    "        -  사용 Thread 수. 기본값: 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f350467-b0c2-46fa-b1f7-e2c57a4bf439",
   "metadata": {},
   "source": [
    "## 학습(Train)\n",
    "1. Word2Vec 의 initializer에 sentences를 넣어 한번에 학습한다.\n",
    "2. Word2Vec 클래스에 학습 설정을 하고 `train()` 메소드를 이용해 학습한다.\n",
    "    - epoch 단위로 작업을 할 경우 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7a02a4e9-2d24-4ede-8395-0482661809a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 샘플 텍스트 데이터\n",
    "sentences = [\n",
    "    \"Natural language processing is an exciting field of study\",\n",
    "    \"Word embeddings are a type of word representation\",\n",
    "    \"Gensim is a powerful library for text processing\",\n",
    "    \"Word2Vec creates vector representations of words\", \n",
    "    \"Gensim runs on Linux, Windows and OS X, as well as any other platform that supports Python and NumPy.\"\n",
    "    \"All Gensim source code is hosted on Github under the GNU LGPL license, maintained by its open source community.\",\n",
    "    \"For commercial arrangements, see Business Support.\",\n",
    "    \"Gensim can process arbitrarily large corpora, using data-streamed algorithms.\",\n",
    "    \"There are no \\\"dataset must fit in RAM\\\" limitations.\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5b455f3f-def9-487e-a3a4-f9563562e26a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import nltk\n",
    "def tokenizer(docs):\n",
    "    # 소문자로 모두 변환.\n",
    "    # 알파벳, 숫자, _를 제외한 모든 문자들을 제거\n",
    "    # 단어(어절)단위 토크화화\n",
    "    return [nltk.word_tokenize(re.sub(r\"[^\\w\\s]\", \"\", doc.lower())) for doc in docs]\n",
    "            \n",
    "# [^\\w]  - \\w\\s(공백문자들) 를 제외한 나머지(^)들을 찾아라."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0f3a73dc-943f-4baa-a072-c9b30ea482e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "tokens = tokenizer(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e296ada9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os \n",
    "os.cpu_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4e6e770f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train\n",
    "## Word2Vec 객체를 생성: 학습데이터, epoch -> 객체 생성할 때 모델을 학습. 학습결과 모델을 반환.\n",
    "from gensim.models import Word2Vec\n",
    "import os\n",
    "model1 = Word2Vec(\n",
    "    sentences=tokens, # 학습 시킬 데이터.\n",
    "    vector_size=10,   # embedding vector의 차원(한개 단어에서 몇개 feature를 추출할지.)\n",
    "    window=2,         # window size 설정. 주변단어의 개수.\n",
    "    min_count=1,      # 최소 출연 빈도수. \n",
    "    epochs=10,\n",
    "    workers=os.cpu_count()         # 병렬처리 개수. \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b97620e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 epoch loss: 1449.962646484375\n",
      "1 epoch loss: 1368.042236328125\n",
      "2 epoch loss: 1291.6473388671875\n",
      "3 epoch loss: 1328.950439453125\n",
      "4 epoch loss: 1373.55517578125\n",
      "5 epoch loss: 1295.62939453125\n",
      "6 epoch loss: 1308.69287109375\n",
      "7 epoch loss: 1341.904541015625\n",
      "8 epoch loss: 1299.2216796875\n",
      "9 epoch loss: 1398.2099609375\n"
     ]
    }
   ],
   "source": [
    "# 학습데이터, epoch을 설정하지 않음. => 학습안된 모델을 반환.\n",
    "model2 = Word2Vec(vector_size=10, window=2, min_count=1, workers=os.cpu_count())\n",
    "# model에 vocab을 설정.\n",
    "model2.build_vocab(tokens)\n",
    "# 학습\n",
    "epoch=10\n",
    "for e in range(epoch):\n",
    "    model2.train(\n",
    "        tokens,  # 학습데이터\n",
    "        total_examples=model2.corpus_count, # 학습데이터(문서) 개수\n",
    "        epochs=1,\n",
    "        compute_loss=True    # 학습이 끝나면 loss를 계산.\n",
    "    )\n",
    "    loss = model2.get_latest_training_loss() # train() 시 계산된 loss를 조회.\n",
    "    print(f\"{e} epoch loss: {loss}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad7fe805-022b-4e1a-b0ea-8e5bc692fa75",
   "metadata": {},
   "source": [
    "## 학습 후 결과 조회\n",
    "\n",
    "- **KeyedVectors 조회**\n",
    "    - KeyedVectors는 단어와 vector를 매핑한 객체로 embedding vector를 이용한 다양한 조회를 지원한다.\n",
    "    - model.wv 로 조회해서 사용.\n",
    "- **Embedding Vector 조회**\n",
    "  - model.wv.vectors\n",
    "- **단어 목록 조회**\n",
    "    - model.wv.index_to_key, model.wv.key_to_index\n",
    "- **단어 벡터 조회**\n",
    "    - model.wv[word]: 특정 단어의 vector반환\n",
    "- **Vocab에 대상 단어가 있는지 확인**\n",
    "    - \"대상단어\" in model.wv\n",
    "- **유사단어들 찾기**\n",
    "    - model.wv.most_similar(word)\n",
    "- **단어간 유사도 비교**\n",
    "    - model.wv.similarity(word1, word2)\n",
    "- 유사도를 계산할 때 **코사인 유사도(Cosine Similarity)** 를 사용한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba473d91",
   "metadata": {},
   "source": [
    "> # 코사인 유사도\n",
    "> - 두 벡터 간의 유사성을 측정하는 중요한 방법 중 하나.\n",
    "> - 코사인 유사도는 두 벡터 간의 코사인 각도를 이용하여 유사도를 계산한다. 이때 벡터의 **크기는 결과에 영향을 미치지 않고, 오직 방향만이 중요**하다.\n",
    "> ## 공식\n",
    "> \n",
    "> $$ similarity = cos(\\theta) = \\frac{A⋅B}{||A||\\ ||B||} = \\frac{\\sum_{i=1}^{n}{A_i×B_i}}{\\sqrt{\\sum_{i=1}^{n}(A_i)^2}×\\sqrt{\\sum_{i=1}^{n}(B_i)^2}} $$\n",
    "> \n",
    "> ## 결과 해석\n",
    "> \n",
    "> - **값의 범위**: -1에서 1 사이의 값을 가집니다\n",
    ">   - 1: 두 벡터가 완전히 동일한 방향 (0도의 cosine 값)\n",
    ">   - 0: 두 벡터가 직교 (90도의 cosine 값)\n",
    ">   - -1: 두 벡터가 정반대 방향 (180도의 cosine 값)\n",
    "> \n",
    "> ![cosine_similarity](figures/gensim_consin_sim.png)\n",
    ">\n",
    "> ## Python 코사인 유사도 계산\n",
    "> ```python\n",
    "> from numpy import dot\n",
    "> from numpy.linalg import norm\n",
    "> \n",
    "> def cosine_similarity(A, B):\n",
    ">     return dot(A, B)/(norm(A)*norm(B))\n",
    "> ```\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0c5d0e0b-0d18-40ac-91c4-11e9114acbc5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<gensim.models.keyedvectors.KeyedVectors at 0x1ea9a81d8b0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.wv  # KeyedVectors -> 토큰-embedding vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "36df1892-1804-4f23-a396-b52f82238d99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['gensim',\n",
       " 'is',\n",
       " 'of',\n",
       " 'for',\n",
       " 'processing',\n",
       " 'source',\n",
       " 'as',\n",
       " 'on',\n",
       " 'word',\n",
       " 'are',\n",
       " 'a',\n",
       " 'and',\n",
       " 'words',\n",
       " 'runs',\n",
       " 'linux',\n",
       " 'os',\n",
       " 'windows',\n",
       " 'vector',\n",
       " 'x',\n",
       " 'well',\n",
       " 'any',\n",
       " 'representations',\n",
       " 'limitations',\n",
       " 'creates',\n",
       " 'word2vec',\n",
       " 'text',\n",
       " 'platform',\n",
       " 'library',\n",
       " 'powerful',\n",
       " 'representation',\n",
       " 'type',\n",
       " 'embeddings',\n",
       " 'study',\n",
       " 'field',\n",
       " 'exciting',\n",
       " 'an',\n",
       " 'language',\n",
       " 'other',\n",
       " 'that',\n",
       " 'ram',\n",
       " 'see',\n",
       " 'support',\n",
       " 'can',\n",
       " 'process',\n",
       " 'arbitrarily',\n",
       " 'large',\n",
       " 'corpora',\n",
       " 'using',\n",
       " 'datastreamed',\n",
       " 'algorithms',\n",
       " 'there',\n",
       " 'no',\n",
       " 'dataset',\n",
       " 'must',\n",
       " 'fit',\n",
       " 'in',\n",
       " 'business',\n",
       " 'arrangements',\n",
       " 'supports',\n",
       " 'commercial',\n",
       " 'python',\n",
       " 'numpyall',\n",
       " 'code',\n",
       " 'hosted',\n",
       " 'github',\n",
       " 'under',\n",
       " 'the',\n",
       " 'gnu',\n",
       " 'lgpl',\n",
       " 'license',\n",
       " 'maintained',\n",
       " 'by',\n",
       " 'its',\n",
       " 'open',\n",
       " 'community',\n",
       " 'natural']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.wv.index_to_key # vocab: token_id -> token(단어)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9607cc94-67cf-4a87-8a42-ab88683cd514",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'gensim': 0,\n",
       " 'is': 1,\n",
       " 'of': 2,\n",
       " 'for': 3,\n",
       " 'processing': 4,\n",
       " 'source': 5,\n",
       " 'as': 6,\n",
       " 'on': 7,\n",
       " 'word': 8,\n",
       " 'are': 9,\n",
       " 'a': 10,\n",
       " 'and': 11,\n",
       " 'words': 12,\n",
       " 'runs': 13,\n",
       " 'linux': 14,\n",
       " 'os': 15,\n",
       " 'windows': 16,\n",
       " 'vector': 17,\n",
       " 'x': 18,\n",
       " 'well': 19,\n",
       " 'any': 20,\n",
       " 'representations': 21,\n",
       " 'limitations': 22,\n",
       " 'creates': 23,\n",
       " 'word2vec': 24,\n",
       " 'text': 25,\n",
       " 'platform': 26,\n",
       " 'library': 27,\n",
       " 'powerful': 28,\n",
       " 'representation': 29,\n",
       " 'type': 30,\n",
       " 'embeddings': 31,\n",
       " 'study': 32,\n",
       " 'field': 33,\n",
       " 'exciting': 34,\n",
       " 'an': 35,\n",
       " 'language': 36,\n",
       " 'other': 37,\n",
       " 'that': 38,\n",
       " 'ram': 39,\n",
       " 'see': 40,\n",
       " 'support': 41,\n",
       " 'can': 42,\n",
       " 'process': 43,\n",
       " 'arbitrarily': 44,\n",
       " 'large': 45,\n",
       " 'corpora': 46,\n",
       " 'using': 47,\n",
       " 'datastreamed': 48,\n",
       " 'algorithms': 49,\n",
       " 'there': 50,\n",
       " 'no': 51,\n",
       " 'dataset': 52,\n",
       " 'must': 53,\n",
       " 'fit': 54,\n",
       " 'in': 55,\n",
       " 'business': 56,\n",
       " 'arrangements': 57,\n",
       " 'supports': 58,\n",
       " 'commercial': 59,\n",
       " 'python': 60,\n",
       " 'numpyall': 61,\n",
       " 'code': 62,\n",
       " 'hosted': 63,\n",
       " 'github': 64,\n",
       " 'under': 65,\n",
       " 'the': 66,\n",
       " 'gnu': 67,\n",
       " 'lgpl': 68,\n",
       " 'license': 69,\n",
       " 'maintained': 70,\n",
       " 'by': 71,\n",
       " 'its': 72,\n",
       " 'open': 73,\n",
       " 'community': 74,\n",
       " 'natural': 75}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.wv.key_to_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "be1f8793",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.00530078,  0.00215998,  0.0511257 ,  0.08994552, -0.0929675 ,\n",
       "       -0.07124555,  0.06510045,  0.08978292, -0.05092729, -0.0380263 ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 특정 단어의 embedding vector 를 조회\n",
    "model1.wv['gensim']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "253a80a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(False, True)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model1.wv['안녕'] - vocab에 특정 단어가 있는지 여부\n",
    "'안녕' in model1.wv , 'gensim' in model1.wv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "783928f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.05893448  0.01508251 -0.00718124  0.09339169 -0.04917641 -0.00835453\n",
      "  0.09189787  0.06754155  0.01489585 -0.08890103]\n"
     ]
    }
   ],
   "source": [
    "word = '안녕'\n",
    "word = \"numpyall\"\n",
    "if word in model1.wv:\n",
    "    print(model1.wv[word])\n",
    "else:\n",
    "    print(\"없는 단어\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cce5ed5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('numpyall', 0.7189714908599854),\n",
       " ('study', 0.713896632194519),\n",
       " ('that', 0.6710396409034729),\n",
       " ('can', 0.641579270362854),\n",
       " ('datastreamed', 0.5988761782646179),\n",
       " ('is', 0.5452057123184204),\n",
       " ('other', 0.5355265140533447),\n",
       " ('maintained', 0.5195193886756897),\n",
       " ('representations', 0.5130788087844849),\n",
       " ('in', 0.5079874396324158)]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 유사도 검사.\n",
    "model1.wv.most_similar(\"gensim\")  # gensim과 가장 유사한 단어를 순서대로 10개를 반환.\n",
    "#(단어, 유사도) 유사도 -1 ~ 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "aa24aacb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('numpyall', 0.7189714908599854),\n",
       " ('study', 0.713896632194519),\n",
       " ('that', 0.6710396409034729)]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.wv.most_similar(\"gensim\", topn=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7acad28e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7138967"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 단어간의 유사도\n",
    "model1.wv.similarity(\"gensim\", \"study\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c3c06ac-5bb3-4a2f-b0ac-d1aa0c747f80",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "52de32ef-2dc7-49a6-b829-68b14f797267",
   "metadata": {},
   "source": [
    "## 모델 저장 및 로딩\n",
    "\n",
    "### 모델 저장, 로딩\n",
    "- `model.save('저장파일 경로')`\n",
    "  - gensim 자체 포맷으로 저장된다.\n",
    "- `gensim.models.Word2Vec.load('저장파일 경로')`\n",
    "  - `model.save()`로 저장된 모델을 Loading한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6b9517b7-ee62-4313-a78e-42d5240cb276",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.makedirs(\"saved_models\", exist_ok=True)\n",
    "model1.save(\"saved_models/w2v_model.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b1f55800-3dd3-4054-9c07-d48961518099",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_model = Word2Vec.load(\"saved_models/w2v_model.model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34742583-58b5-40c8-b3ab-a641147cdd07",
   "metadata": {},
   "source": [
    "### Word Embedding Vector만 저장 및 로드\n",
    "- `KeyedVectors` 를 이용해 저장한다.\n",
    "    - `model.wv.save_word2vec_format('저장경로', binary=True|False)`\n",
    "        - binary=True: binary 파일로 저장한다. 용량이 작은 대신 내용확인이 안된다.\n",
    "        - binary=False: csv(공백구분자) 형식 text로 저장한다. 내용을 확인할 수있지만 파일용량이 크다.\n",
    "- `KeyedVectors.load_word2vec_format(\"저장경로\", binary=True|False)`\n",
    "    - 저장시 binary에 맞춰 읽는다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a9dfab01-5ed0-4749-a585-fb26ba817495",
   "metadata": {},
   "outputs": [],
   "source": [
    "model1.wv.save_word2vec_format(\"saved_models/keyedvector.bin\", binary=True)\n",
    "model1.wv.save_word2vec_format(\"saved_models/keyedvector.csv\", binary=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "114fe1da-cf7d-411d-a46a-8d69045df1ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "load_wv_bin = KeyedVectors.load_word2vec_format(\"saved_models/keyedvector.bin\", binary=True)\n",
    "load_wv_csv = KeyedVectors.load_word2vec_format(\"saved_models/keyedvector.csv\", binary=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a72063a1-afa5-4c69-b271-982d1f185843",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('numpyall', 0.7189716696739197),\n",
       " ('study', 0.7138967514038086),\n",
       " ('that', 0.6710396409034729),\n",
       " ('can', 0.6415793299674988),\n",
       " ('datastreamed', 0.5988761186599731),\n",
       " ('is', 0.5452057123184204),\n",
       " ('other', 0.5355265140533447),\n",
       " ('maintained', 0.5195195078849792),\n",
       " ('representations', 0.5130788087844849),\n",
       " ('in', 0.507987380027771)]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_wv_bin.most_similar(\"gensim\")\n",
    "load_wv_csv.most_similar(\"gensim\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d66b7152-2745-4e30-bc6f-5e417ab25f00",
   "metadata": {},
   "source": [
    "## Pretrained 모델 사용하기\n",
    "- https://github.com/Kyubyong/wordvectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bc4f7b0a-8620-4c34-b463-3c186a70c107",
   "metadata": {},
   "outputs": [],
   "source": [
    "from zipfile import ZipFile\n",
    "with ZipFile(\"ko_new.zip\") as zf: # 압축풀 파일경로\n",
    "    zf.extractall(\"saved_models\") # extract -> 개별파일 풀때 사용 / extractall 모든파일 풀때 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "52eab43d-4df0-44b6-a531-83f66c427996",
   "metadata": {},
   "outputs": [],
   "source": [
    "ko_wv = KeyedVectors.load_word2vec_format(\n",
    "    \"saved_models/ko_new.txt\",\n",
    "    binary=False,\n",
    "    encoding=\"utf-8\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7907d09e-8fd1-4462-9679-ca182617e1c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('아침', 0.8432559967041016), ('밤', 0.7863156795501709), ('새벽', 0.7520349025726318)]\n",
      "[('코끼리', 0.7047041654586792), ('표범', 0.6993285417556763), ('멧돼지', 0.6985809803009033)]\n"
     ]
    }
   ],
   "source": [
    "word = \"저녁\"\n",
    "result = ko_wv.most_similar(word, topn=3)\n",
    "print(result)\n",
    "word = \"호랑이\"\n",
    "result = ko_wv.most_similar(word, topn=3)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "68ed3530",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.3842834 , -0.356262  ,  0.55099374, -0.12755577, -0.8897868 ,\n",
       "       -0.01085023,  0.4051852 , -0.00849318,  0.7922764 ,  0.61044914,\n",
       "       -0.21740127,  0.7326123 ,  0.00975952,  1.2224952 ,  1.7374074 ,\n",
       "        0.550102  , -0.04433551,  0.46078685,  0.7088423 , -0.12447739,\n",
       "        0.26103678, -1.7141577 ,  1.1090391 , -0.06266715,  0.5393867 ,\n",
       "       -0.5670158 ,  2.8203938 ,  1.4095887 ,  0.25168103, -0.36968148,\n",
       "        0.23580536,  0.0387576 , -0.11112779, -0.6910354 ,  1.0538206 ,\n",
       "       -1.4043067 ,  0.25224012,  2.213298  , -0.8007955 ,  0.09763678,\n",
       "       -0.6443904 ,  0.8280104 , -0.8043615 , -2.3739452 , -0.1739332 ,\n",
       "       -0.8374608 ,  0.48010096,  1.5835998 , -1.7894523 ,  1.0660172 ,\n",
       "        0.9587638 ,  0.20674476,  0.53526455,  0.16311654, -1.6024637 ,\n",
       "       -0.39326617, -0.903832  , -0.63576716,  0.10457885, -0.9901898 ,\n",
       "        0.44487828, -0.01300097, -0.6176418 , -0.94335663,  0.8662551 ,\n",
       "       -0.7614388 ,  0.42271316, -1.0146952 , -0.12537627, -0.02076967,\n",
       "       -0.3231959 , -0.27907687, -0.5862871 ,  0.3955772 ,  1.2961242 ,\n",
       "       -0.3403088 ,  0.03785289,  0.750193  ,  0.01206644,  0.12868665,\n",
       "        2.3940837 ,  0.67070574,  0.51355964, -1.628212  , -1.4412365 ,\n",
       "        0.5588509 , -0.13284922,  0.31805214, -0.20865473,  1.0146854 ,\n",
       "       -0.10398719, -1.2259699 ,  0.02638595, -0.52085274, -0.3035808 ,\n",
       "        0.9761939 ,  1.3153589 ,  1.1108624 ,  0.73234755, -0.6640282 ,\n",
       "        0.51963854, -0.22835545,  1.3084681 , -0.31699237, -1.0617325 ,\n",
       "       -1.2837436 ,  0.42070362, -0.29535964, -0.44504195,  0.3306401 ,\n",
       "        0.38063264, -0.45310465, -0.19471693, -0.32083383, -0.73754597,\n",
       "       -1.0837078 ,  0.4098977 , -0.02822146,  1.4314046 ,  1.0631841 ,\n",
       "       -0.10916689,  0.23737633, -1.230618  , -1.227019  ,  1.4246451 ,\n",
       "        0.16312194, -1.021059  , -1.1616907 , -0.57975847,  0.52865976,\n",
       "        0.8191993 , -0.21302274,  0.74192166,  0.57503784,  0.55224407,\n",
       "       -0.18047062,  0.6618583 , -0.51932347,  0.30508813,  0.20054683,\n",
       "       -0.11804479, -0.5995174 ,  1.626027  , -0.55273926,  1.337157  ,\n",
       "        0.6663139 ,  0.45550284, -0.95358264, -0.59171885, -0.54657453,\n",
       "       -1.0728854 ,  0.35340992,  0.6932437 , -0.11004893,  0.93903995,\n",
       "       -0.45867637,  0.43867353, -0.88802725, -0.37047374, -0.3433066 ,\n",
       "       -1.0864652 , -0.8810704 ,  0.05599649, -1.0346124 , -1.1303799 ,\n",
       "       -1.1655362 ,  0.6277178 , -0.77939814, -0.15477394,  0.36235294,\n",
       "       -0.98144054,  0.01473746, -0.2531179 ,  1.4802116 , -1.289686  ,\n",
       "       -0.5019453 ,  0.09698924, -0.79416543, -1.3293544 , -0.4218704 ,\n",
       "       -0.0777145 ,  0.88491136, -0.15683138,  0.09657332,  0.15171647,\n",
       "        1.395335  , -0.10186347,  0.07764352,  0.06773152,  1.3534831 ,\n",
       "       -0.14967933,  0.6152984 ,  0.0602353 , -1.0905067 , -0.90046275,\n",
       "        1.037931  , -0.07647705,  0.14619811, -1.2305502 , -0.5836446 ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ko_wv[word]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecb37baa",
   "metadata": {},
   "source": [
    "# 빅카인즈 뉴스 데이터를 이용한 Word2Vec 학습\n",
    "- 빅카인즈\n",
    "    - 한국언론진흥재단에서 운영하는 뉴스빅데이터 분석 서비스 사이트\n",
    "- 빅카인즈에서 특정 분야의 기사들을 수집해서 학습시킨다.\n",
    "    - https://www.bigkinds.or.kr/\n",
    "    - 회원가입 (구글, 네이버, 카카오 계정으로 가입 가능) 후 로그인\n",
    "    - 뉴스분석 > 뉴스검색$\\cdot$분석 클릭\n",
    "    ![word2vec_bigkinds1.png](figures/word2vec_bigkinds1.png)\n",
    "    - 기간, 언론사, 분류, 상세검색 등 검색 조건입력 후 조회\n",
    "    ![word2vec_bigkinds1.png](figures/word2vec_bigkinds2.png)\n",
    "    - 결과 다운로드\n",
    "        - step3 분석결과및 시각화 -> 맨 아래 `엑셀다운로드` 클릭 \n",
    "    ![word2vec_bigkinds1.png](figures/word2vec_bigkinds3.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a2a456a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 문서 : 개별 뉴스기사 (제목 + 본문)\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_excel(\"NewsResult.xlsx\")\n",
    "df = df[['제목','본문']]\n",
    "\n",
    "# 전처리 + 토큰화(소문자 통일, 형태소단위 토큰화)\n",
    "\n",
    "# gensim을 이용해서 embedding 모델 학습.\n",
    "\n",
    "# 결과 확인 -> 유사도 검사."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1af1ec6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "036f5656",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
